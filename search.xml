<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Transformer</title>
      <link href="/2025/11/13/Transformer/"/>
      <url>/2025/11/13/Transformer/</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" async    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">  </script><p>这是一篇关于Transformer以及变种Vision Transformer，Diffusion Transformer的粗浅解析文章，仅代表作者个人理解,可能存在很多谬误，还望理解。</p><hr><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>标准的 Transformer 由两大部分组成：</p><ol><li><p><strong>编码器 (Encoder)：</strong> 负责理解输入序列（如一句话的中文部分），将其转化为一个高级的、上下文丰富的<strong>语义表示（Semantic Representation）</strong>。它通常由 $N$ 个相同的编码器层堆叠而成。</p></li><li><p><strong>解码器 (Decoder)：</strong> 负责接收编码器的输出，并结合自身的前一个输出，逐步生成目标序列（如对应句子的英文部分）。它通常也由 $N$ 个相同的解码器层堆叠而成。</p></li></ol><hr><h3 id="核心组件：编码器层（Encoder-Layer）"><a href="#核心组件：编码器层（Encoder-Layer）" class="headerlink" title="核心组件：编码器层（Encoder Layer）"></a>核心组件：编码器层（Encoder Layer）</h3><p>每个编码器层（Encoder Block）的结构非常简洁，主要包含两个子层：</p><h4 id="1-多头自注意力机制（Multi-Head-Self-Attention-MHA）"><a href="#1-多头自注意力机制（Multi-Head-Self-Attention-MHA）" class="headerlink" title="1. 多头自注意力机制（Multi-Head Self-Attention, MHA）"></a>1. 多头自注意力机制（Multi-Head Self-Attention, MHA）</h4><p>这是 Transformer 的核心，负责计算序列中所有元素之间的依赖关系，并生成上下文向量。</p><h5 id="🔹-Q-K-V-的生成与计算"><a href="#🔹-Q-K-V-的生成与计算" class="headerlink" title="🔹 Q, K, V 的生成与计算"></a>🔹 Q, K, V 的生成与计算</h5><p>对于输入 $\mathbf{X}$：</p><ol><li><p>输入映射： 通过三个训练好的权重矩阵 $\mathbf{W}_Q, \mathbf{W}_K, \mathbf{W}_V$ 将输入 $\mathbf{X}$ 线性投影到 $Q$ (Query), $K$ (Key), $V$ (Value) 三个不同的特征空间。</p><script type="math/tex; mode=display">\mathbf{Q} = \mathbf{X} \mathbf{W}_Q, \quad \mathbf{K} = \mathbf{X} \mathbf{W}_K, \quad \mathbf{V} = \mathbf{X} \mathbf{W}_V</script></li></ol><ol><li><p><strong>注意力分数计算（Scaled Dot-Product Attention）：</strong></p><ul><li><p><strong>相关性得分：</strong> $\mathbf{Q}$ 与 $\mathbf{K}$ 的转置相乘，得到一个相关性得分矩阵。</p></li><li><p><strong>缩放：</strong> 除以 $\sqrt{d_k}$（$d_k$ 是 $K$ 的维度），防止点积结果过大导致 Softmax 梯度过小。</p></li><li><p><strong>归一化：</strong> 使用 Softmax 函数将得分转换为 $0 \sim 1$ 的权重（Attention Map）。</p></li><li><p><strong>加权求和：</strong> 用这些权重与 $\mathbf{V}$ 相乘，得到注意力输出 $\mathbf{Z}$。</p></li></ul><script type="math/tex; mode=display">\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{Softmax}\left(\frac{\mathbf{Q} \mathbf{K}^T}{\sqrt{d_k}}\right) \mathbf{V}</script></li></ol><h4 id="🔹-多头机制-Multi-Head"><a href="#🔹-多头机制-Multi-Head" class="headerlink" title="🔹 多头机制 (Multi-Head)"></a>🔹 多头机制 (Multi-Head)</h4><p>模型不是只进行一次注意力计算，而是并行地进行 $h$ 次独立的注意力计算（即 $h$ 个“头”）。</p><ol><li><p><strong>分割：</strong> $\mathbf{Q}, \mathbf{K}, \mathbf{V}$ 被分割成 $h$ 份（即 $h$ 个头）。</p></li><li><p><strong>并行计算：</strong> 每个头独立计算注意力输出 $\mathbf{Z}_i$。</p></li><li><p><strong>拼接与投影：</strong> 将所有 $\mathbf{Z}_i$ 拼接起来，并通过另一个训练好的权重矩阵 $\mathbf{W}_O$ 进行线性投影，得到最终的多头注意力输出。</p></li></ol><script type="math/tex; mode=display">\text{MultiHead}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{Concat}(\mathbf{Z}_1, \ldots, \mathbf{Z}_h) \mathbf{W}_O</script><h4 id="前馈网络（Feed-Forward-Network-FFN）"><a href="#前馈网络（Feed-Forward-Network-FFN）" class="headerlink" title="前馈网络（Feed-Forward Network, FFN）"></a>前馈网络（Feed-Forward Network, FFN）</h4><p>这是一个标准的两层全连接网络，对自注意力机制的输出 $\mathbf{Z}$ 中的<strong> 每一个位置（Token/Patch）</strong> 独立地进行非线性变换。</p><ul><li>公式：</li></ul><script type="math/tex; mode=display">\text{FFN}(\mathbf{x}) = \max(0, \mathbf{x} \mathbf{W}_1 + \mathbf{b}_1) \mathbf{W}_2 + \mathbf{b}_2</script><ul><li>FFN 通常使用 <strong>ReLU</strong> 激活函数，其内部维度通常会比输入输出维度 $d_{model}$ <strong>大四倍</strong>（如 $d_{ff} = 4 \cdot d_{model}$）。它负责对信息进行深度加工和特征提取。</li></ul><h4 id="残差连接与层归一化（Residual-Connection-amp-Layer-Normalization）"><a href="#残差连接与层归一化（Residual-Connection-amp-Layer-Normalization）" class="headerlink" title="残差连接与层归一化（Residual Connection &amp; Layer Normalization）"></a>残差连接与层归一化（Residual Connection &amp; Layer Normalization）</h4><p>为了确保信息在深层网络中稳定流动：</p><ul><li><p><strong>残差连接 (Residual Connection)：</strong> 将子层的输入 $\mathbf{x}$ 直接加到子层的输出 $\text{Sublayer}(\mathbf{x})$ 上，即 $\mathbf{x} + \text{Sublayer}(\mathbf{x})$。这有助于防止梯度消失，加速训练。</p></li><li><p><strong>层归一化 (Layer Normalization)：</strong> 在残差连接后，对<strong>序列维度</strong>（每个 Token 的特征维度）进行归一化。</p></li></ul><p>整个编码器层的最终输出为：</p><script type="math/tex; mode=display">\text{Output} = \text{LayerNorm}(\mathbf{x} + \text{FFN}(\text{LayerNorm}(\text{SelfAttention}(\mathbf{x}) + \mathbf{x})))</script><hr><h3 id="核心组件：解码器层（Decoder-Layer）"><a href="#核心组件：解码器层（Decoder-Layer）" class="headerlink" title="核心组件：解码器层（Decoder Layer）"></a>核心组件：解码器层（Decoder Layer）</h3><p>解码器层比编码器层多了一个<strong>交叉注意力机制</strong>，主要包含三个子层：</p><h4 id="1-掩码多头自注意力（Masked-Multi-Head-Self-Attention）"><a href="#1-掩码多头自注意力（Masked-Multi-Head-Self-Attention）" class="headerlink" title="1. 掩码多头自注意力（Masked Multi-Head Self-Attention）"></a>1. 掩码多头自注意力（Masked Multi-Head Self-Attention）</h4><p>功能与编码器的自注意力相同，但增加了一个<strong>掩码（Mask）</strong>机制：</p><ul><li><p>在 Softmax 之前，对当前 Token 之后的所有 Token 的得分设置为 $-\infty$（即权重为 0）。</p></li><li><p><strong>目的：</strong> 确保在生成第 $t$ 个 Token 时，模型<strong>只能看到</strong>第 $1$ 到 $t-1$ 个 Token，从而维持序列生成任务的因果性（Autoregressive）。</p></li></ul><h4 id="2-多头交叉注意力（Multi-Head-Cross-Attention）"><a href="#2-多头交叉注意力（Multi-Head-Cross-Attention）" class="headerlink" title="2. 多头交叉注意力（Multi-Head Cross-Attention）"></a>2. 多头交叉注意力（Multi-Head Cross-Attention）</h4><p>该层连接了编码器和解码器，负责从编码器的输出中提取相关信息。</p><ul><li><p><strong>Q 向量：</strong> 来自<strong>解码器</strong>前一层的输出（即解码器的自我理解）。</p></li><li><p><strong>K 和 V 向量：</strong> 来自<strong>编码器</strong>的最终输出（即输入序列的全局语义表示）。</p></li><li><p><strong>目的：</strong> 让解码器知道在生成当前词时，应该“关注”输入序列中的哪些部分。</p></li></ul><h4 id="3-前馈网络（FFN）与归一化"><a href="#3-前馈网络（FFN）与归一化" class="headerlink" title="3. 前馈网络（FFN）与归一化"></a>3. 前馈网络（FFN）与归一化</h4><p>结构与编码器层中的完全相同。</p><hr><h3 id="四、输入与输出：位置编码与线性层"><a href="#四、输入与输出：位置编码与线性层" class="headerlink" title="四、输入与输出：位置编码与线性层"></a>四、输入与输出：位置编码与线性层</h3><h4 id="1-词嵌入（Embedding）"><a href="#1-词嵌入（Embedding）" class="headerlink" title="1. 词嵌入（Embedding）"></a>1. 词嵌入（Embedding）</h4><p>输入序列的每个 Token（或 ViT 中的 Patch）被转换为一个 $d_{model}$ 维的向量。</p><h4 id="2-位置编码（Positional-Encoding-PE）"><a href="#2-位置编码（Positional-Encoding-PE）" class="headerlink" title="2. 位置编码（Positional Encoding, PE）"></a>2. 位置编码（Positional Encoding, PE）</h4><p>由于自注意力机制是并行计算，它<strong>无法感知</strong>序列中 Token 的<strong>位置信息</strong>。因此，Transformer 必须显式地加入位置编码。</p><ul><li>实现方式： 将位置编码向量 直接加到 词嵌入向量上。</li></ul><script type="math/tex; mode=display">\text{Input Embedding} = \text{Token Embedding} + \text{Positional Encoding}</script><ul><li><p><strong>编码方法：</strong> 原始论文使用<strong>固定的正弦和余弦函数</strong>来计算位置编码：</p><script type="math/tex; mode=display">PE_{(pos, 2i)} = \sin(pos / 10000^{2i/d_{model}}) \\ PE_{(pos, 2i+1)} = \cos(pos / 10000^{2i/d_{model}})</script></li></ul><ul><li>$pos$ 是位置索引，$i$ 是维度索引。这种编码能让模型学习到相对位置信息。</li></ul><h4 id="3-输出线性层与-Softmax"><a href="#3-输出线性层与-Softmax" class="headerlink" title="3. 输出线性层与 Softmax"></a>3. 输出线性层与 Softmax</h4><p>解码器最终的输出向量经过一个线性层（Linear Layer) 和一个 Softmax 层：</p><ol><li><p><strong>线性层：</strong> 将解码器的输出向量投影回词汇表的大小 $\mathbf{V}_{vocab}$。</p></li><li><p><strong>Softmax 层：</strong> 将线性层的输出转化为每个词汇的概率分布。</p></li></ol><div class="table-container"><table><thead><tr><th><strong>组件名称</strong></th><th><strong>所在层次</strong></th><th><strong>详细定位</strong></th><th><strong>核心功能</strong></th></tr></thead><tbody><tr><td><strong>词嵌入 (Embedding)</strong></td><td>输入层 / 输出层</td><td>编码器输入、解码器输入、解码器输出</td><td>将符号（Token）转化为数值向量</td></tr><tr><td><strong>位置编码 (PE)</strong></td><td>输入层 / 输出层</td><td>编码器输入、解码器输入</td><td>引入序列中元素的顺序信息</td></tr><tr><td><strong>编码器层 (Encoder Layer)</strong></td><td>编码器堆栈 ($N$ 个)</td><td>-</td><td>提取输入序列的上下文语义</td></tr><tr><td><strong>多头自注意力 (MHA)</strong></td><td>编码器层 / 解码器层</td><td>1. 编码器子层 2. 解码器第一个子层 (带掩码)</td><td>计算输入序列内部的依赖关系</td></tr><tr><td><strong>多头交叉注意力 (MHA)</strong></td><td>解码器层</td><td>解码器第二个子层</td><td>连接编码器和解码器，关注输入语义</td></tr><tr><td><strong>前馈网络 (FFN)</strong></td><td>编码器层 / 解码器层</td><td>编码器第二个子层、解码器第三个子层</td><td>对每个位置的特征进行非线性加工</td></tr><tr><td><strong>残差连接 &amp; LayerNorm</strong></td><td>贯穿始终</td><td>每个子层之后（注意力/FFN）</td><td>稳定信息流，防止梯度消失</td></tr><tr><td><strong>线性层 &amp; Softmax</strong></td><td>输出层</td><td>解码器末端</td><td>预测目标词汇的概率分布</td></tr></tbody></table></div><h2 id="Vision-Transformer"><a href="#Vision-Transformer" class="headerlink" title="Vision Transformer"></a>Vision Transformer</h2><p>ViT 是将 Transformer 架构从自然语言处理（NLP）领域成功引入计算机视觉（CV）领域的开创性工作。它证明了 Transformer 可以直接应用于图像分类任务，而无需依赖传统的卷积神经网络（CNN）。</p><p><strong>核心思想：</strong> 将一张图片视为一个序列，将图像的局部小块（Patch）视为序列中的一个个“词汇”（Token），然后将这个序列输入到标准的 Transformer 编码器中进行处理。</p><h3 id="一、宏观架构与数据流"><a href="#一、宏观架构与数据流" class="headerlink" title="一、宏观架构与数据流"></a>一、宏观架构与数据流</h3><p>ViT 的整体架构主要由三大部分组成：</p><ol><li><p><strong>输入处理（Embedding Layer）：</strong> 负责将原始图像转换为 Transformer 编码器所需的<strong>一维序列</strong>。</p></li><li><p><strong>Transformer 编码器（Encoder）：</strong> 由多个标准的 Transformer 编码器层堆叠而成，负责捕获 Patch 之间的<strong>全局依赖关系</strong>。</p></li><li><p><strong>分类头（Classification Head）：</strong> 位于编码器输出端，负责基于学习到的特征进行最终的<strong>分类预测</strong>。</p></li></ol><hr><h3 id="二、输入处理：将图像序列化"><a href="#二、输入处理：将图像序列化" class="headerlink" title="二、输入处理：将图像序列化"></a>二、输入处理：将图像序列化</h3><p>这是 ViT 与传统 Transformer 最主要的区别所在。</p><h4 id="1-图像分块（Patch-Embedding）"><a href="#1-图像分块（Patch-Embedding）" class="headerlink" title="1. 图像分块（Patch Embedding）"></a>1. 图像分块（Patch Embedding）</h4><ul><li><p><strong>操作：</strong> 将输入的 $H \times W \times C$（高 $\times$ 宽 $\times$ 通道）图像，分割成 $N$ 个不重叠的、固定大小的图像块（例如 $16 \times 16$ 像素）。</p><ul><li>如果图像大小是 $256 \times 256$，Patch 大小是 $16 \times 16$，则总共会得到 $N = (256/16) \times (256/16) = 16 \times 16 = 256$ 个 Patch。</li></ul></li><li><p><strong>展平（Flattening）：</strong> 每个 $P \times P \times C$ 的 Patch 被展平为一个长向量。</p></li><li><p><strong>线性投影（Linear Projection）：</strong> 展平后的向量通过一个可学习的线性层（类似全连接层），将其映射到 Transformer 的特征维度 $D$（例如 $D=768$）。</p></li></ul><h4 id="2-分类标记"><a href="#2-分类标记" class="headerlink" title="2. 分类标记"></a>2. 分类标记</h4><p>$CLS$ Token</p><ul><li><p><strong>操作：</strong> 在 Patch 序列的最前面，添加一个特殊的、可学习的向量，称为 <strong>Class Token</strong> 或<br>$CLS$   Token。</p></li><li><p><strong>功能：</strong> 这个 Token 不对应图像的任何部分，但它将通过自注意力机制<strong>与所有图像 Patch 交互</strong>，汇聚整个图像的全局信息。最终，模型将只使用这个 Class Token 的输出进行分类。</p></li></ul><h4 id="3-位置嵌入（Positional-Embedding）"><a href="#3-位置嵌入（Positional-Embedding）" class="headerlink" title="3. 位置嵌入（Positional Embedding）"></a>3. 位置嵌入（Positional Embedding）</h4><ul><li><p><strong>操作：</strong> 为序列中的每一个元素（包括$CLS$ Token 和所有 Patch ），添加一个<strong>可学习的</strong>位置编码向量。</p></li><li><p><strong>ViT 的特点：</strong> 与原始 Transformer 使用<strong>固定的正弦/余弦函数</strong>不同，ViT 通常使用<strong>可学习的</strong>位置嵌入。</p></li><li><p><strong>功能：</strong> 告诉模型每个 Patch 在原始图像中的<strong>空间位置</strong>。</p></li></ul><p><strong>至此，图像被转换成一个 $N+1$ 个向量组成的序列，维度为 $(N+1) \times D$，准备送入 Transformer 编码器。</strong></p><hr><h3 id="三、核心处理：Transformer-编码器"><a href="#三、核心处理：Transformer-编码器" class="headerlink" title="三、核心处理：Transformer 编码器"></a>三、核心处理：Transformer 编码器</h3><p>ViT 采用标准的 <strong>Transformer 编码器堆栈</strong>。</p><ul><li><p><strong>结构：</strong> 堆栈由 $L$ 个相同的编码器层组成。</p></li><li><p><strong>编码器层组成：</strong></p><ul><li><p><strong>多头自注意力（MHA）：</strong> 计算序列中 <strong>Patch 与 Patch 之间</strong> 的依赖关系。例如，它可以捕捉到图片中“狗的头” Patch 与“狗的身体” Patch 之间的关联。</p></li><li><p><strong>前馈网络（FFN）：</strong> 对 MHA 的输出进行非线性加工。</p></li><li><p><strong>残差连接和 LayerNorm：</strong> 保持信息稳定流动。</p></li></ul></li></ul><p><strong>与 NLP 的区别：</strong> 编码器处理的不再是词语间的语法和语义关系，而是<strong>图像局部区域（Patch）间的空间和特征关系</strong>。</p><hr><h3 id="四、输出与分类（Classification-Head）"><a href="#四、输出与分类（Classification-Head）" class="headerlink" title="四、输出与分类（Classification Head）"></a>四、输出与分类（Classification Head）</h3><h4 id="1-提取CLS-Token"><a href="#1-提取CLS-Token" class="headerlink" title="1. 提取CLS Token"></a>1. 提取CLS Token</h4><ul><li><strong>操作：</strong> 忽略所有 Patch 对应的输出向量，只提取<strong>最后一个编码器层</strong>中<br>$CLS$ Token 对应的输出向量  $$\mathbf{Z}_{CLS}$。</li></ul><h3 id="2-分类预测"><a href="#2-分类预测" class="headerlink" title="2. 分类预测"></a>2. 分类预测</h3><ul><li><strong>操作：</strong> $\mathbf{Z}_{CLS}$ 向量通常通过一个简单的 <strong>多层感知机（MLP）</strong> 分类头，进行最终的分类预测。</li></ul><script type="math/tex; mode=display">\text{Prediction} = \text{Softmax}(\text{MLP}(\mathbf{Z}_{CLS}))</script><hr><h3 id="总结-ViT-的创新点"><a href="#总结-ViT-的创新点" class="headerlink" title="总结 ViT 的创新点"></a>总结 ViT 的创新点</h3><div class="table-container"><table><thead><tr><th><strong>特点</strong></th><th><strong>描述</strong></th><th><strong>意义</strong></th></tr></thead><tbody><tr><td><strong>Patch 序列化</strong></td><td>将 2D 图像无缝转换为 1D 序列。</td><td>使图像数据能够直接利用 Transformer 强大的序列建模能力。</td></tr><tr><td><strong>全局自注意力</strong></td><td>通过 MHA 计算所有 Patch 之间的关系。</td><td>捕获<strong>长距离依赖</strong>，优于传统 CNN 的局部感受野。</td></tr><tr><td>CLS Token</td><td>引入一个特殊的 Token 汇聚全局信息。</td><td>提供一个简洁的分类接口，将所有 Patch 的上下文信息汇总到一点进行预测。</td></tr><tr><td><strong>可学习位置编码</strong></td><td>使用可学习的 PE 而非固定的 PE。</td><td>实验证明这在图像任务中表现更好，更能适应不同的输入分辨率。</td></tr></tbody></table></div><h2 id="Diffusion-Transformer"><a href="#Diffusion-Transformer" class="headerlink" title="Diffusion Transformer"></a>Diffusion Transformer</h2><p><strong>核心思想：</strong> DiT 的主要贡献在于，它用一个 <strong>ViT 骨干网络</strong> 替换了传统扩散模型中用于去噪的 <strong>U-Net 骨干网络</strong>，从而将 Transformer 强大的<strong>全局建模能力</strong>引入图像生成任务。</p><h3 id="一、DiT-的背景：潜扩散模型与去噪"><a href="#一、DiT-的背景：潜扩散模型与去噪" class="headerlink" title="一、DiT 的背景：潜扩散模型与去噪"></a>一、DiT 的背景：潜扩散模型与去噪</h3><p>DiT 并非直接作用于原始像素，而是通常用于<strong>潜在扩散模型 (Latent Diffusion Models, LDM)</strong> 中，如 Stable Diffusion。</p><ol><li><p><strong>潜在空间 (Latent Space)：</strong> 原始高分辨率图像首先通过一个编码器（Encoder）压缩成一个低维的、信息量更丰富的<strong>潜在表示 (Latent Representation)</strong>。DiT 在这个潜在空间中工作，大大提高了计算效率。</p></li><li><p>去噪任务： 扩散模型的核心任务是：给定一张带有噪声的潜在表示 $\mathbf{z}_t$ 和当前的时间步 $t$，模型必须预测并去除添加到图像中的噪声 $\epsilon$。</p><script type="math/tex; mode=display">\text{DiT}(\mathbf{z}_t, t, c) \rightarrow \text{Predicted Noise } \epsilon</script></li><li><p><strong>U-Net 的局限：</strong> 传统的扩散模型使用 U-Net 结构进行去噪。U-Net 擅长处理局部细节，但由于其卷积性质，难以有效地捕捉图像中<strong>大尺度、长距离的依赖关系</strong>。</p></li></ol><h3 id="二、DiT-的架构创新：ViT-作为骨干"><a href="#二、DiT-的架构创新：ViT-作为骨干" class="headerlink" title="二、DiT 的架构创新：ViT 作为骨干"></a>二、DiT 的架构创新：ViT 作为骨干</h3><p>DiT 的结构与 ViT 的编码器部分高度相似，但在输入和注意力机制中融入了<strong>条件信息（Conditioning）</strong>。</p><h3 id="1-输入处理（Patching-amp-Embedding）"><a href="#1-输入处理（Patching-amp-Embedding）" class="headerlink" title="1. 输入处理（Patching &amp; Embedding）"></a>1. 输入处理（Patching &amp; Embedding）</h3><ul><li><p><strong>输入：</strong> 带有噪声的潜在表示 $\mathbf{z}_t$。</p></li><li><p><strong>分块与嵌入：</strong> 与 ViT 完全相同，$\mathbf{z}_t$ 被分割成<strong>潜在 Patch</strong> 并通过<strong>线性层</strong>嵌入到 Transformer 维度 $D$。</p></li><li><p><strong>序列：</strong> 生成一个 Patch 序列 $\mathbf{X}$。（DiT 通常不使用CLS Token，因为它不是分类任务。）</p></li></ul><h3 id="2-条件化（Conditioning）"><a href="#2-条件化（Conditioning）" class="headerlink" title="2. 条件化（Conditioning）"></a>2. 条件化（Conditioning）</h3><p>DiT 的关键在于如何将扩散过程所需的额外信息（时间步 $t$ 和文本/类别条件 $c$）融入到 Transformer 块中。</p><ul><li><p><strong>时间步 $t$：</strong> 时间步 $t$（表示噪声程度）首先被编码成一个高维向量。</p></li><li><p><strong>条件信息 $c$：</strong> 文本提示 $c$ 通常通过一个独立的文本编码器（如 CLIP Text Encoder）转换为特征向量。</p></li><li><p><strong>自适应层归一化 (Adaptive Layer Normalization, AdaLN)：</strong> DiT 使用 AdaLN 将这些条件信息高效地注入每个 Transformer 块。</p><ul><li>在标准的 Layer Normalization 之后，DiT 通过时间步 $t$ 和条件 $c$ 计算出的参数来对特征进行<strong>仿射变换（Scaling $\gamma$ 和 Shifting $\beta$）</strong>。</li></ul><script type="math/tex; mode=display">\text{AdaLN}(\mathbf{x}) = \gamma(t, c) \cdot \text{LayerNorm}(\mathbf{x}) + \beta(t, c)</script></li></ul><ul><li><strong>定位：</strong> $\gamma$ 和 $\beta$ 参数被注入到 DiT 块中的 <strong>MHA 层和 FFN 层</strong> 的 Layer Normalization 之后。</li></ul><h3 id="3-DiT-块（Transformer-Encoder）"><a href="#3-DiT-块（Transformer-Encoder）" class="headerlink" title="3. DiT 块（Transformer Encoder）"></a>3. DiT 块（Transformer Encoder）</h3><p>DiT 的核心是基于 ViT 编码器修改而成的 DiT 块。</p><ul><li><p><strong>结构：</strong> 与 ViT 类似，由 MHA 和 FFN 组成，但两者都包含了 <strong>AdaLN</strong> 注入的条件信息。</p></li><li><p><strong>功能：</strong> 计算潜在 Patch 之间的<strong>全局注意力</strong>，同时受到当前噪声程度和文本提示的精确控制。</p></li></ul><h3 id="三、输出与重构"><a href="#三、输出与重构" class="headerlink" title="三、输出与重构"></a>三、输出与重构</h3><ol><li><p><strong>输出序列：</strong> 经过 $L$ 个 DiT 块后，模型输出一个与输入 $\mathbf{X}$ 相同维度的序列 $\mathbf{Y}$。</p></li><li><p><strong>逆向投影：</strong> $\mathbf{Y}$ 序列通过一个<strong>线性投影层</strong>，将特征维度 $D$ 逆向投影回潜在 Patch 的维度。</p></li><li><p><strong>重构潜在图：</strong> 这些潜在 Patch 被重新排列、组合，重构回二维的<strong>潜在噪声图</strong> $\epsilon$（或去噪后的潜在表示 $\mathbf{z}_{t-1}$）。</p></li><li><p><strong>去噪：</strong> 这个预测出的 $\epsilon$ 被用于扩散模型的采样步骤，逐步去除 $\mathbf{z}_t$ 中的噪声，最终生成清晰的潜在表示。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Others </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer </tag>
            
            <tag> ViT,DiT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BlenderProc API</title>
      <link href="/2025/10/18/BlenderProc-API/"/>
      <url>/2025/10/18/BlenderProc-API/</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" async  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><p>这是从Blender官方教程目录中系统整理的BlenderProc API核心用法指南，涵盖了场景搭建、材质应用、相机设置及渲染输出等关键步骤的代码示例与参数详解。</p><hr><h2 id="Loader"><a href="#Loader" class="headerlink" title="Loader"></a>Loader</h2><h3 id="CLI下载外部资源"><a href="#CLI下载外部资源" class="headerlink" title="CLI下载外部资源"></a>CLI下载外部资源</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">blenderproc download &lt;dataset&gt; &lt;output_dir&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>支持的外部资源有许多，包括blenderkit中CC0 许可的模型与材质、CC0textures的高质量PBR纹理、polyhaven的许多环境光与模型以及一些直接的数据集中的资源（matterport3d，pix3d，scenenet）等。注意有些单独的.blend文件是允许下载的，但是无法通过CLI来逐个下载，可能只能下载特定的数据集。</p><h3 id="加载3D模型"><a href="#加载3D模型" class="headerlink" title="加载3D模型"></a>加载3D模型</h3><p>所有加载函数都属于<strong>bproc.loader</strong>模块，返回类型是<strong>list[bproc.types.MeshObject]</strong>，通用的调用格式为：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">objects: list[MeshObject] &#x3D; bproc.loader.load_xxx(&lt;path_or_config&gt;)# bproc.loader.load_obj(file_path)# bproc.loader.load_blend(file_path)# 比如下载一个chair.obj文件objs &#x3D; bproc.loader.load_obj(&quot;&#x2F;assets&#x2F;chair.obj&quot;)chair &#x3D; objs[0]  # 获取第一个对象<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>还有一种是加载专用数据集的loaderAPI，具体用法如下，同时以BOP_obj为例（包括AMASS，pix3D，scung等都可以用）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.loader.load_&lt;dataset&gt;(dataset_features)bproc.loader.load_bop_objs(bop_dataset_path, model_type, category_ids)# 记载BOP中的T-LESS模型models &#x3D; bproc.loader.load_bop_objs(    bop_dataset_path&#x3D;&quot;&#x2F;data&#x2F;bop&#x2F;tless&quot;,    model_type&#x3D;&quot;cad&quot;,    category_ids&#x3D;[&quot;01&quot;, &quot;02&quot;])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="操作加载完成的模型对象"><a href="#操作加载完成的模型对象" class="headerlink" title="操作加载完成的模型对象"></a>操作加载完成的模型对象</h3><p>每个加再多物体都是一个MeshObject实例，可以实现位姿变换</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">obj.set_location([x,y,z])obj.set_rotation_euler([rx, ry, rz]) #这里是设置旋转角度，绕三个轴obj.set_local2world_mat(matrix_4x4) #设置局部空间到世界坐标的变换矩阵obj.apply_T(matrix_4x4) #在当前位姿基础上叠加变换import numpy as npobj.set_location([2.0, 0.0, 1.0])# 绕 X 轴旋转 180°obj.set_rotation_euler([np.pi, 0, 0])# 构建变换矩阵（从旋转矩阵R_3x3和平移矩阵T_3x1堆叠）T &#x3D; bproc.math.build_transformation_mat(    location&#x3D;[0, 0, 0.1],    rotation_euler&#x3D;[0, np.pi&#x2F;4, 0])obj.apply_T(T)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>给对象自定义属性，set和get方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">obj.set_cp(key: str, value: Any)obj.get_cp(key: str, default&#x3D;None) #键不存在则返回默认值# 以chair为例obj.set_cp(&quot;category&quot;, &quot;chair&quot;)obj.set_cp(&quot;instance_id&quot;, 42)obj.set_cp(&quot;is_target&quot;, True)# 读取标签cat &#x3D; obj.get_cp(&quot;category&quot;)           #  &quot;chair&quot;id_ &#x3D; obj.get_cp(&quot;instance_id&quot;)        #  42color &#x3D; obj.get_cp(&quot;color&quot;, &quot;white&quot;)   #  &quot;white&quot;（默认值）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Camera-Configuration"><a href="#Camera-Configuration" class="headerlink" title="Camera Configuration"></a>Camera Configuration</h2><h3 id="相机内参"><a href="#相机内参" class="headerlink" title="相机内参"></a>相机内参</h3><p>一般情况下包含两个方向焦距以及主点，表示为</p><script type="math/tex; mode=display">K = \begin{bmatrix}f_x & 0   & c_x \\0   & f_y & c_y \\0   & 0   & 1\end{bmatrix}</script><p>bproc有两种方式设置内参，第一种是直接设置K</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.camera.set_intrinsics_from_K_matrix(K, image_width, image_height)# 用法为K &#x3D; np.array([    [800, 0, 400],   # fx, 0, cx    [0, 800, 300],   # fy, cy    [0, 0, 1]])# 图像分辨率为 800x600bproc.camera.set_intrinsics_from_K_matrix(K, image_width&#x3D;800, image_height&#x3D;600)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>第二种是设置物理参数，这种需要进行计算，为了内容完整性还是写出（注意这里有一些合理性假设例如$f_x=f_y$）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.camera.set_intrinsics_from_blender_params(    lens&#x3D;value,    lens_unit&#x3D;&quot;MILLIMETERS&quot;  # 设定为&quot;MILLIMETERS&quot;表示输入的lens值是以毫米为单位的焦距)bproc.camera.set_intrinsics_from_blender_params(lens&#x3D;math.pi&#x2F;3, lens_unit&#x3D;&quot;FOV&quot;) #设置水平视场角为 60°（≈ π&#x2F;3 弧度）#视场角（Field of View, FOV）：以弧度为单位指定水平视角宽度<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="相机外参"><a href="#相机外参" class="headerlink" title="相机外参"></a>相机外参</h3><p>定义相机在世界坐标系的位置和朝向，相当于从相机坐标系到世界坐标系的变换矩阵</p><script type="math/tex; mode=display">\mathbf{T} = \begin{bmatrix}R_{11} & R_{12} & R_{13} & t_x \\R_{21} & R_{22} & R_{23} & t_y \\R_{31} & R_{32} & R_{33} & t_z \\0      & 0      & 0      & 1\end{bmatrix}</script><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.camera.add_camera_pose(cam2world_matrix)# 构造一个 4x4 变换矩阵（相机在 [0, -2, 1]，看向原点）tmat &#x3D; bproc.math.build_transformation_mat(    location&#x3D;[0, -2, 1],    rotation_euler&#x3D;[0, math.radians(80), 0]  )# 添加相机位姿bproc.camera.add_camera_pose(tmat)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>需要注意的是每调用一次 <code>add_camera_pose</code>，就会添加一个<strong>关键帧（keyframe）</strong>，渲染时会从该视角生成一张图像</p><p>此外还有从OpenCV坐标系转换到OpenGL坐标系的用法，Blender使用OpenGL坐标系，与OpenCV的Z坐标一个向内一个向外，Y坐标一个向上一个向下，因此OpenCV 的相机到世界变换矩阵（cam2world）不能直接用于 Blender，需要进行转换</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 将 OpenCV 格式的 cam2world 矩阵转换为 Blender&#x2F;OpenGL 兼容格式cam2world_opengl &#x3D; bproc.math.change_source_coordinate_frame_of_transformation_matrix(    transformation_matrix&#x3D;cam2world_opencv,    source_frame&#x3D;[&quot;X&quot;, &quot;-Y&quot;, &quot;-Z&quot;]  # OpenCV → OpenGL)bproc.camera.add_camera_pose(cam2world_gl)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Sampler"><a href="#Sampler" class="headerlink" title="Sampler"></a>Sampler</h2><p>BlenderProc 提供了强大的 bproc.sampler模块，支持多种空间采样策略，可以生成更多样化的布局</p><div class="table-container"><table><thead><tr><th>采样器</th><th>方法</th><th>用途</th></tr></thead><tbody><tr><td>球面采样</td><td>sampler.sphere()</td><td>相机环绕物体（固定距离）</td></tr><tr><td>壳状采样</td><td>sampler.shell()</td><td>相机环绕物体（随机距离）</td></tr><tr><td>半球采样</td><td>sampler.hemisphere()</td><td>上半空间采样</td></tr><tr><td>圆柱采样</td><td>sampler.cylinder()</td><td>工业场景（如机械臂视角）</td></tr><tr><td>网格采样</td><td>sampler.grid()</td><td>规则网格路径（如无人机航拍）</td></tr><tr><td>表面采样</td><td>sampler.surface()</td><td>在平面上随机分布物体</td></tr><tr><td>体积采样</td><td>sampler.volume()</td><td>在空间区域内随机分布</td></tr></tbody></table></div><p>这里只详细说明壳状采样，其他类似 </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">cam2world &#x3D; bproc.sampler.shell(    center&#x3D;[0, 0, 0],      # 采样中心点    radius_min&#x3D;2.0,        # 最小半径    radius_max&#x3D;3.0,        # 最大半径    mode&#x3D;&quot;SURFACE&quot;         # 采样模式：SURFACE(球壳表面) 或 VOLUME（整个球体内部）)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Render"><a href="#Render" class="headerlink" title="Render"></a>Render</h2><h3 id="帧区间"><a href="#帧区间" class="headerlink" title="帧区间"></a>帧区间</h3><p>BlenderProc的渲染是基于帧序列的，当调用渲染函数时，他会渲染$[frame_{start},frame_{end})$的所有帧，其中每一帧对应一个camera pose，可以用如下方式设置渲染帧范围</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.global_settings.set_render_range(frame_start&#x3D;1, frame_end&#x3D;3)  # 渲染第1帧和第2帧<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="RGB渲染器（主渲染）"><a href="#RGB渲染器（主渲染）" class="headerlink" title="RGB渲染器（主渲染）"></a>RGB渲染器（主渲染）</h3><p>最常用的方式是</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data &#x3D; bproc.renderer.render()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中render()会返回一个dict，包含启用的所有图像类型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">&#123;  &quot;colors&quot;: [    &lt;np.uint8: [512, 512, 3]&gt;,  &#x2F;&#x2F; 第1帧 RGB    &lt;np.uint8: [512, 512, 3]&gt;   &#x2F;&#x2F; 第2帧 RGB  ],  &quot;normals&quot;: [    &lt;np.float32: [512, 512, 3]&gt;, &#x2F;&#x2F; 第1帧法线    &lt;np.float32: [512, 512, 3]&gt;  ],  &quot;distance&quot;: [    &lt;np.float32: [512, 512]&gt;,    &#x2F;&#x2F; 第1帧距离图    &lt;np.float32: [512, 512]&gt;  ]&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="深度图和距离图"><a href="#深度图和距离图" class="headerlink" title="深度图和距离图"></a>深度图和距离图</h3><p>首先是距离图，是distance，像素的distance值=相机位置到3D点的真实欧氏距离，可用于3D重建和点云生成</p><p>其次是深度图，即depth/z-buffer，像素的深度值=3D点在相机Z轴上的投影距离</p><p>一般用到的是distance，两者的用法如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.renderer.enable_distance_output()bproc.renderer.enable_depth_output()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="法线图"><a href="#法线图" class="headerlink" title="法线图"></a>法线图</h3><p>法线渲染器会输出每个像素对应表面的法线向量（在世界坐标系下）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.renderer().enable_normals_output()# 输出类型：np.float32，形状 [H, W, 3],值范围是[-1，1],表示法线方向<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="分割渲染"><a href="#分割渲染" class="headerlink" title="分割渲染"></a>分割渲染</h3><p>用于标注图像中每个像素属于哪个物体</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data &#x3D; bproc.renderer.render_segmap(map_by&#x3D;[&quot;instance&quot;, &quot;class&quot;, &quot;name&quot;])# instance即实例分割，为每个物体分配唯一ID# class即语义分割，使用物体的category_id属性<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>输出的数据类似</p><pre class="line-numbers language-json" data-language="json"><code class="language-json">&#123;  &quot;instance_segmaps&quot;: [...],  &#x2F;&#x2F; 实例分割图  &quot;class_segmaps&quot;: [...],     &#x2F;&#x2F; 类别分割图  &quot;instance_attribute_maps&quot;: [    [  &#x2F;&#x2F; 每帧一个映射表      &#123;&quot;idx&quot;: 0, &quot;name&quot;: &quot;chair_01&quot;&#125;,      &#123;&quot;idx&quot;: 1, &quot;name&quot;: &quot;lamp_02&quot;&#125;    ],    [...]  &#x2F;&#x2F; 下一帧（映射保持一致）  ]&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以用上面的set_cp来设置物体类别ID</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">obj &#x3D; bproc.loader.load_obj(&quot;chair.obj&quot;)obj.set_cp(&quot;category_id&quot;, 3)  # 类别 3 &#x3D; 椅子<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="光流渲染器"><a href="#光流渲染器" class="headerlink" title="光流渲染器"></a>光流渲染器</h3><p>光流是来描述像素在连续的帧之间的运动方向和大小的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data &#x3D; bproc.renderer.render_optical_flow()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="采样去噪"><a href="#采样去噪" class="headerlink" title="采样去噪"></a>采样去噪</h3><p>控制每个像素的采样数，知道噪声低于设置的阈值，同时也可以限制最大采样次数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.renderer.set_noise_threshold(0.05)  # 值越小越清晰越慢,0.0~0.1bproc.renderer.set_max_amount_of_samples(512)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>去噪器可以大幅减少所需的采样数量，官方文档中暂时给出了启用Intel和关闭去噪的用法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 启用 Intel Open Image Denoiserbproc.renderer.set_denoiser(&quot;INTEL&quot;)# 关闭去噪bproc.renderer.set_denoiser(None)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Writer"><a href="#Writer" class="headerlink" title="Writer"></a>Writer</h2><p>完成render渲染后，需要把生成的数据用于训练模型，BlenderProc提供了多种Writer模块，如HDF5,COCO,BOP等</p><p>不管用哪种Writer，基本流程都是一样的，所有 Writer 都会自动创建目录并组织文件结构</p><p>首先是hdf5，每个.hdf5是一个包含colors，distance，instance_segamp，camera_intrinsics，camera_rt_matrix等的类似json文件</p><p>其次是COCO，多用于目标检测和实例分割，使用起来的参数较多，见下代码(举的例子是实例分割)</p><p>最后是BOP，多用于6D位姿估计。用法见下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 1. 渲染数据data &#x3D; bproc.renderer.render()# 2. 调用对应的 writerbproc.writer.write_hdf5(&quot;&#x2F;output&#x2F;hdf5&quot;, data)bproc.writer.write_coco_annotations(    data&#x3D;data,    instance_segmaps&#x3D;data[&quot;instance_segmaps&quot;],  # 提前渲染    dataset_name&#x3D;&quot;my_dataset&quot;,    supercategory&#x3D;&quot;scene&quot;,    images_dir&#x3D;&quot;&#x2F;output&#x2F;coco&#x2F;images&quot;,    annotations_dir&#x3D;&quot;&#x2F;output&#x2F;coco&#x2F;annotations&quot;)bproc.writer.write_bop(    output_dir&#x3D;&quot;&#x2F;output&#x2F;bop&quot;,    camera_settings&#x3D;&#123;        &quot;depth_scale&quot;: 1.0,           # 深度图缩放因子        &quot;intrinsics&quot;: K               # 相机内参矩阵    &#125;,    dataset&#x3D;&quot;my_bop_dataset&quot;,    frames_data&#x3D;data,    save_world2cam_transforms&#x3D;True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后是可视化数据</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">blenderproc vis hdf5 &#x2F;output&#x2F;hdf5&#x2F;0.hdf5blenderproc vis coco &#x2F;output&#x2F;coco&#x2F;annotations&#x2F;my_dataset.json<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="Keyframes"><a href="#Keyframes" class="headerlink" title="Keyframes"></a>Keyframes</h2><p>关键帧可以批量渲染，适合大规模的合成数据集生成，网格只上传一次到GPU，每增加一次相机位姿会自动添加一个关键帧</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">for i in range(100):    bproc.camera.add_camera_pose(pose_i)  # 添加相机位姿，即添加关键帧bproc.renderer.render()  # 一次性渲染<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在调用bproc.camera.add_camera_pose()时，关键帧会自动递增编号，也可以在该方法后加一个frame=k来显示绑定该相机位姿到帧k</p><p>同时注意如果添加多个相机位姿之后再调用obj.set_location()，就会重置所有帧的物体位置，可能导致出错，同样可以在该方法后面加一个frame参数来为特定帧设定物体位置</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">obj.set_location([2, 0, 0], frame&#x3D;1) #在第一帧时物体位置设定为2，0，0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果在同一个文件中多次调用renderer，必须重置关键帧，不然关键帧会一直累积，渲染的帧数会越来越多</p><h2 id="Rigid-Physics"><a href="#Rigid-Physics" class="headerlink" title="Rigid Physics"></a>Rigid Physics</h2><h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p>为了防止出现穿模或悬空等情况，BlenderProc集成了刚体物理引擎，可以模拟重力</p><p>对一个需要参与物理模拟的物体启用刚体组件，例如：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">obj.enable_rigidbody(    active&#x3D;True,              # 是否主动移动（受重力）    mass&#x3D;1.0,                 # 质量（kg）    friction&#x3D;0.5,             # 摩擦系数    collision_shape&#x3D;&quot;CONVEX_HULL&quot;  # 碰撞形状)table.enable_rigidbody(active&#x3D;False, collision_shape&#x3D;&quot;MESH&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中，active参数为True表示物体受重力影响，会移动，为False表示物体是固定不动作为障碍物的，例如墙壁地板等</p><p>collision_shape表示碰撞形状，直接影响模拟稳定性和计算效率，CONVEX_HULL表示简单的凸形物体，例如球和立方体，忽略其凹陷部分；MESH表示复杂非凸物体，例如齿轮等，渲染不太稳定；COMPOUND为有高精度需求的非凸物体。</p><h3 id="Convex-decomposition"><a href="#Convex-decomposition" class="headerlink" title="Convex_decomposition"></a>Convex_decomposition</h3><p>如上文所述，如果对一些非凸物体（椅子）直接使用MESH碰撞形状容易导致物体穿模或抖动，因此BlenderProc内置了V-HACD来进行凸分解</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">obj.build_convex_decomposition_collision_shape(    vhacd_path&#x3D;&quot;&#x2F;tmp&#x2F;vhacd&quot;  # 存储分解结果的目录)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>原始物体会被分解为多个凸块，渲染时不可见，仅用于物理碰撞检测，在模拟结束后会自动清理</p><h3 id="物理模拟"><a href="#物理模拟" class="headerlink" title="物理模拟"></a>物理模拟</h3><p>BlenderProc有两种模拟的模式，首先是静态摆放，它模拟整个下落过程，但是只会保留最终的静止姿态，然后清除动画，也就是说最后生成的是<strong>单帧稳定场景</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.object.simulate_physics_and_fix_final_poses(    min_simulation_time&#x3D;4,     # 最少模拟 4 秒    max_simulation_time&#x3D;20,    # 最多模拟 20 秒    check_object_interval&#x3D;1    # 每 1 秒检查是否静止)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 随机设置多个物体随机初始位置for obj in objects:    obj.set_location(np.random.uniform([-0.5, -0.5, 2], [0.5, 0.5, 3]))    obj.enable_rigidbody(active&#x3D;True, collision_shape&#x3D;&quot;CONVEX_HULL&quot;)# 模拟物理，固定最终位置bproc.object.simulate_physics_and_fix_final_poses()# 添加相机并渲染for i in range(5):    pose &#x3D; bproc.sampler.shell(center&#x3D;[0,0,0], radius_min&#x3D;2, radius_max&#x3D;3)    bproc.camera.add_camera_pose(pose)data &#x3D; bproc.renderer.render()bproc.writer.write_hdf5(&quot;&#x2F;output&#x2F;scene_001&quot;, data)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>第二种方法是动态渲染，这个会保留动画，可以用作训练视频模型，暂时没有深入整理</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">bproc.object.simulate_physics(    min_simulation_time&#x3D;3,    max_simulation_time&#x3D;10,    check_object_interval&#x3D;1)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Blender </tag>
            
            <tag> BlenderProc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-View 3D Point Tracking</title>
      <link href="/2025/10/11/Multi-View-3D-Point-Tracking/"/>
      <url>/2025/10/11/Multi-View-3D-Point-Tracking/</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" async  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><p>本文提出了首个数据驱动的多视角3D点跟踪器，通过kNN关联与时空Transformer实现高精度、鲁棒的前馈式跟踪，支持任意点跟踪与多视角融合。  </p><hr><h2 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h2><p>Multi-View 3D Point Tracking</p><p>文章来自2025ICCV，作者是Frano Rajiˇc和 Haofei Xu等人，arxiv地址为  </p><p><a href="https://arxiv.org/abs/2508.21060">[[2508.21060] Multi-View 3D Point Tracking</a></p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="Scene-flow-场景流"><a href="#Scene-flow-场景流" class="headerlink" title="Scene flow(场景流)"></a>Scene flow(场景流)</h3><p>在三维空间中，对连续两帧图像之间的每个可见点估计其<strong>三维运动向量（即位移）</strong>，是光流在3D空间的推广，同时通常的方法对图像中<strong>每一个像素或点云中的每一个点</strong>都估计一个3D运动向量，而不是只估计某些关键点的运动，即为<strong>Dense</strong>。</p><p>通常会构建一个能量函数（energy function），包含数据项（如光度一致性）和正则项（如平滑性约束），然后通过迭代优化求解，但是其<strong>速度慢且依赖多视角输入（相比MVTracker需要多得多的同步相机）</strong>，且目前大多数场景流方法仍然只处理<strong>相邻的两帧图像</strong>，无法建立长时间跨度的3D点对应关系。</p><h3 id="2D-Point-Tracking"><a href="#2D-Point-Tracking" class="headerlink" title="2D Point Tracking"></a>2D Point Tracking</h3><p>在视频序列中，持续追踪某些特征点（可能是角点、纹理点等）在整个时间轴上的位置变化，一般能够跨数十甚至数百帧保持对点的追踪，即使发生遮挡、模糊、光照变化等，即为<strong>Long-term</strong>。</p><p><strong>CoTracker</strong>使用self-Attention，利用其他已知轨迹点的信息来帮助当前点的匹配；<strong>LocoTrack</strong>将传统的基于相关性的匹配方法升级为 <strong>双向4D相关</strong>，即两个空间维度x，y和两个时间维度（前一帧后一帧），有更强的局部匹配能力。</p><h3 id="3D-Point-Tracking"><a href="#3D-Point-Tracking" class="headerlink" title="3D Point Tracking"></a>3D Point Tracking</h3><p>3D点跟踪的目的是在视频序列中，持续追踪空间中的某些3D点（比如物体表面的一个角、人的鼻子等），形成一条跨越多帧的<strong>3D轨迹</strong>。相比Scene flow有可以长期追踪。</p><h4 id="基于单目输入的3D跟踪（Monocular-3D-Tracking）"><a href="#基于单目输入的3D跟踪（Monocular-3D-Tracking）" class="headerlink" title="基于单目输入的3D跟踪（Monocular 3D Tracking）"></a>基于单目输入的3D跟踪（Monocular 3D Tracking）</h4><p><strong>SpatialTracker</strong>把2D扩展到3D，使用Triplane表示法（我暂时不太了解，接下来会看一看）编码3D场景，同时融合深度信息（模型估计或辅助输入）；<strong>DELTA</strong>不只是追踪稀疏的关键点，而是尝试估计<strong>整张图像平面上所有像素的稠密3D轨迹</strong>。这两种方法都依赖monocular input，同时目前很多前沿工作仍聚焦于“如何用单摄像头做尽可能好的3D跟踪”，本质上存在深度模糊性。</p><h4 id="基于多相机-几何重建的方法"><a href="#基于多相机-几何重建的方法" class="headerlink" title="基于多相机 + 几何重建的方法"></a>基于多相机 + 几何重建的方法</h4><p><strong>Dynamic 3DGS</strong>将整个动态场景建模为随时间变化的3D高斯分布集合（每个高斯代表一个局部颜色+位置+尺度+透明度），可以同时做高质量的3D重建与点跟踪，具有很高的几何精度，但是其致命缺点是需要 <strong>极多的同步摄像头（27个）</strong> 和额外的深度传感器来提供初始点云，<strong>严重依赖极端复杂的采集设备</strong>，<strong>难以在真实世界广泛应用</strong>。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>作者的目标是实现<strong>在线的、跨多视角的3D点跟踪</strong>，输入是多个摄像头<strong>同步拍摄的RGB图像帧</strong>（不同角度同时拍照），且所有摄像头的<strong>内外参数已知</strong>；系统可以逐帧处理视频而并非离线处理（即online）。</p><p>输入是来自 <strong>V 个不同视角</strong>的视频序列，每一帧图像中，都有一些<strong>指定的查询点（query points）</strong>，需要把这些点一直跟踪到最后一帧，形成一条连贯的3D轨迹，同时得到每一帧的<strong>预测可见性（visibility）</strong>。</p><p>整体流程可以概括为：</p><p>多视角输入 → 深度估计 → 3D点云融合 → 特征提取 → 跨帧匹配 → 输出3D轨迹</p><h3 id="问题的抽象描述"><a href="#问题的抽象描述" class="headerlink" title="问题的抽象描述"></a>问题的抽象描述</h3><p>已标定的多视角视频序列$ I_v^t \in \mathbb{R}^{H \times W \times 3} $，有V个摄像头，T帧图像，$I_v^t$为第v个摄像头在t帧时拍摄的图像。</p><p>每个查询点 $q^n$ 由四个元素组成：</p><ul><li><p><strong>查询帧</strong> $t_n^q$​：查询点出现的时间帧。</p></li><li><p><strong>查询点的初始三维位置</strong>$(x_q^n, y_q^n, z_q^n)$：在世界坐标系下，查询点的初始位置。</p></li></ul><p>共有N个查询点，即为:</p><script type="math/tex; mode=display">q_n = (t_q^n, x_q^n, y_q^n, z_q^n) \in \mathbb{R}^4</script><p>相机内参矩阵 $ K_v^t \in \mathbb{R}^{3 \times 3} $ 和外参矩阵 $ E_v^t \in \mathbb{R}^{4 \times 4} $</p><p>需要得到查询点p的3D轨迹及可见性：</p><script type="math/tex; mode=display">p_t^n = (x_t^n, y_t^n, z_t^n) \in \mathbb{R}^3  ，v_t^n \in \{0, 1\}</script><p>同时假设查询帧 $t_n^q$ 时刻，<strong>初始位置就是真实值（ground truth）</strong>，即为：</p><script type="math/tex; mode=display">p_{t_n^q}^n = (x_q^n, y_q^n, z_q^n)</script><h3 id="点云编码"><a href="#点云编码" class="headerlink" title="点云编码"></a>点云编码</h3><h4 id="提取特征图与深度图"><a href="#提取特征图与深度图" class="headerlink" title="提取特征图与深度图"></a>提取特征图与深度图</h4><p>对每一个$I_t^v$，使用CNNbackbone来提取特征图${\Phi}_t^v$，输出三维张量（高度，宽度，通道数），即$H/S \times W/S \times d$，即为stride=S的下采样，同时特征图设置不同尺度</p><p>深度图有两种来源，一是外部深度估计模型（如DUSt3R），二是直接输入的真是深度图</p><h4 id="像素投影到3D坐标"><a href="#像素投影到3D坐标" class="headerlink" title="像素投影到3D坐标"></a>像素投影到3D坐标</h4><script type="math/tex; mode=display">x = {E_t^v}^{-1} ({K_t^v}^{-1} \cdot \begin{pmatrix} u_x \\ u_y \\ 1 \end{pmatrix} \cdot D_t^v [u_y, u_x])</script><p>从左到右依次为相机外参矩阵，相机内参矩阵，像素坐标转换的齐次坐标，像素对应的深度值(没有深度值的点会被略过)</p><p>最终得到3D点$x\in \mathbb{R}^3$</p><h4 id="构建融合的3D特征点云"><a href="#构建融合的3D特征点云" class="headerlink" title="构建融合的3D特征点云"></a>构建融合的3D特征点云</h4><script type="math/tex; mode=display">X_t^s = (x, \Phi_t^{v,s} [u_y, u_x]) \quad v \in \{1, \dots, V\}, \quad (u_x, u_y) \in \Omega_t^v</script><p>也就是把3D点x和其在特征图中的向量进行绑定，把V个视角在同一帧t提取到的3D点+特征对合并为统一的3D点云，s代表点云的尺度（例如1~4），不同尺度用于不同粒度的匹配</p><h4 id="初始化跟踪点"><a href="#初始化跟踪点" class="headerlink" title="初始化跟踪点"></a>初始化跟踪点</h4><p>每一个查询点$q^n$都需要一个特征$f_t^n$来方便后续的匹配，初始化方法为在查询帧$t_q^n$，去最高分辨率的3D特征点云$X_{t_q^n}^1$中找到距离初始位置$p_{t_q^n}^n$最近的3D点，将其特征$\phi^{n,*}$作为跟踪点的初始特征用于后续的匹配和更新。</p><script type="math/tex; mode=display">(x^{n,*}, \phi^{n,*}) = \arg \min_{x, \phi \in X_{t_q^n}^1} \| x - p_{t_q^n}^n\|</script><p>注意这里的$f_t^n$是需要随时间更新的。</p><h3 id="多尺度空间相关性（Spatial-Correlation）"><a href="#多尺度空间相关性（Spatial-Correlation）" class="headerlink" title="多尺度空间相关性（Spatial Correlation）"></a>多尺度空间相关性（Spatial Correlation）</h3><h4 id="KNN相关性"><a href="#KNN相关性" class="headerlink" title="KNN相关性"></a>KNN相关性</h4><script type="math/tex; mode=display">C_t^{n,s} = \left\{ \langle f_t^n, \phi_k \rangle \mid (x_k, \phi_k) \in N_K(\hat p_t^n,X_t^s) \right\}</script><ul><li>对于第 <code>n</code> 个正在跟踪的点，在第 <code>t</code> 帧、第 <code>s</code> 个尺度下：<ul><li>有一个当前的位置估计值 $\hat p_t^n$​（上一帧的结果或预测）。</li><li>我们去<strong>第 <code>s</code> 层尺度的3D特征点云 $X_t^s$​</strong> 中，找离它最近的 <strong>K 个点</strong>，记为 $N_K(\hat p_t^n,X_t^s)$。</li><li>对每一个邻居点$(x^k,\phi^k)$，我们计算它的特征$\phi^k$和当前跟踪点的外观特征$f_t^n$的<strong>相似度</strong>：用点积表示。</li><li>所有这些相似度组成一个集合 $C_t^{n,s}$，即为“<strong>相关性向量</strong>”。</li></ul></li></ul><p>这里的尺度还是上面提到的（1~4），分辨率从高到低。</p><h4 id="编码3D偏移量"><a href="#编码3D偏移量" class="headerlink" title="编码3D偏移量"></a>编码3D偏移量</h4><p>对每一个邻居点$(x^k,\phi^k)$，不仅要传递其相似度，还要拼接其相对位置偏移（这里是only offset，作者在后文讲述了这是效果最好的方式），可以表述为</p><script type="math/tex; mode=display">input_k=[\langle f_t^n, \phi_k \rangle,x^k-\hat p_t^n]</script><h3 id="使用Transformer迭代跟踪"><a href="#使用Transformer迭代跟踪" class="headerlink" title="使用Transformer迭代跟踪"></a>使用Transformer迭代跟踪</h3><p>对于每一个追踪点n和时间t，构造一个token $G_t^n$</p><script type="math/tex; mode=display">G_t^n=(\eta(\hat p_t^n-\hat p_{t_q^n}^n),f_t^n,C_t^{n,s},\hat v_t^n)</script><p>从左到右依次是</p><p>$\eta(\hat p_t^n-\hat p_{t_q^n}^n)$相对位置编码，表示从起点移动了多少，本文为正弦位置编码</p><p>$f_t^n$ 当前时刻点的外观特征</p><p>$C_t^{n,s}$上面提到的多尺度KNN相关性</p><p>$\hat v_t^n$当前对可见性的估计</p><h4 id="Transformer处理"><a href="#Transformer处理" class="headerlink" title="Transformer处理"></a>Transformer处理</h4><p>这里简要概述，不做详细解释，类似CoTracker</p><p>首先是时序自注意力（Temporal），每个点回顾自己过去几帧的表现，学习运动模式（如匀速、加速）并帮助预测下一帧位置</p><p>其次是空间交叉注意力（Vitural Tracks），引入一组<strong>可学习的虚拟轨迹</strong>（learned virtual tracks），这些不是真实点，而是模型内部的“空间查询”  ，作用是建模<strong>空间上下文关系</strong>。 </p><p>最后进行输出，但是并不直接输出最终位置，而是输出残差更新并进行迭代优化</p><script type="math/tex; mode=display">(\Delta \hat p_t^n, \Delta f_t^n) = \psi(G_t^n)</script><p>前者是建议的位置调整量，后者是建议的特征调整量。</p><script type="math/tex; mode=display">\hat p_t^{n,m+1}=\hat p_t^{n,m}+\Delta \hat p_t^{n,m+1}</script><script type="math/tex; mode=display">\hat f_t^{n,m+1}=\hat f_t^{n,m}+\Delta \hat f_t^{n,m+1}</script><p>共进行M次迭代优化，每次迭代后，<strong>都用新的位置重新计算kNN相关性</strong>，构成一个反馈循环</p><h4 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h4><p>在最后一个迭代后，同时输出位置$p_t^{n,M}$和最终的特征$f_t^{n,M}$，并且用最终特征来预测可见性$\hat v_t^n$</p><script type="math/tex; mode=display">\hat v_t^n=\sigma(W \cdot f_t^{n,M})</script><p>$W$在这里是一个可学习的投影矩阵，最后输出0~1之间的概率，同时这个可见性也作为下一帧的输入</p><h3 id="窗口化推理（Windows-Inference）"><a href="#窗口化推理（Windows-Inference）" class="headerlink" title="窗口化推理（Windows Inference）"></a>窗口化推理（Windows Inference）</h3><p>模型使用 Transformer 和 M 次迭代 refinement，内存和计算开销大，无法一次性加载整个长视频，因此需要分段处理，引入滑动窗口。</p><p>设定一个最大窗口长度 $T$（比如 T=8 或 16 帧），对于更长的视频（长度 $T’ &gt; T$），我们将其划分为多个<strong>重叠的时间窗口</strong>，每个窗口长 $T$ 帧，相邻窗口之间<strong>平移 $T/2$帧</strong>（即重叠一半）,这样可以确保轨迹在窗口边界处连续。</p><p>每个窗口之间进行轨迹传播，处理完第$j$个窗口后，$j+1$个窗口不在从头初始化，而是接续前面的轨迹，从而实现<strong>跨窗口的连续跟踪</strong>，即使某个窗口中点被遮挡，也能靠前后窗口恢复。</p><h3 id="Supervision"><a href="#Supervision" class="headerlink" title="Supervision"></a>Supervision</h3><p>文章使用的损失函数包含了位置误差和可见性分类误差，前者作为主任务。</p><script type="math/tex; mode=display">\mathcal{L} = \mathcal{L}_{xyz} + \lambda_{vis} \mathcal{L}_{vis}</script><p>位置损失的计算为</p><script type="math/tex; mode=display">\mathcal{L}_{xyz} = \sum_{j,m,n,t} \frac{\gamma^{M-m}}{JMNT} \left| p_n^{t_{n,m,j}} - p_n^{t_{n,m,j}} \right|_1</script><p>N个查询点，M次迭代，J个窗口，T帧，</p><p>$\gamma ^{M-m}$是<strong>指数衰减权重</strong>，$\gamma$小于1，因为结果越到后面越重要。</p><p>可见性损失的计算为</p><script type="math/tex; mode=display">\mathcal{L}_{vis} = \sum_{j,t,n} \frac{1}{JTN} \text{B-BCE}(\hat v_t^{n,j},  v_t^{n,j})</script><p>即对<strong>所有窗口、所有帧、所有点</strong>的可见性预测误差求和</p><p>B-BCE是平衡二元交叉熵损失，赋予少数类（例如不可见）更高的权重，惩罚更重</p><h2 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h2><h3 id="数据集和指标"><a href="#数据集和指标" class="headerlink" title="数据集和指标"></a>数据集和指标</h3><p>论文在三个数据集上进行实验，涵盖合成与真实场景：</p><p><strong>Multi-View Kubric</strong>：合成数据集，包含8至12个相机视角，场景为桌面级物体交互。提供真值深度和3D点轨迹，用于主实验和融研。</p><p><strong>DexYCB</strong>：真实数据集，包含8个同步相机，记录手与物体的交互过程。深度由DUSt3R等估计方法提供，用于评估在真实噪声条件下的泛化能力。<br><strong>Panoptic Studio</strong>：真实大场景数据集，配备27个以上相机，记录多人活动。深度同样依赖估计方法或传感器输入，用于测试在复杂、多视角环境下的性能。</p><p>所有实验统一使用3D空间中的轨迹匹配指标进行评估，包括Average Jaccard (AJ)、δavg、Overall Accuracy (OA) 和 Mean Tracking Error (MTE)</p><div class="table-container"><table><thead><tr><th>指标</th><th>全称</th><th>含义</th><th>趋势</th></tr></thead><tbody><tr><td><strong>AJ</strong></td><td>Average Jaccard</td><td>3D轨迹匹配度（IoU）</td><td>越高越好</td></tr><tr><td><strong>δavg</strong></td><td>Average Distance</td><td>预测点与真值平均距离</td><td>越高越好</td></tr><tr><td><strong>OA</strong></td><td>Overall Accuracy</td><td>误差 &lt; 5cm 的帧占比</td><td>越高越好</td></tr><tr><td><strong>MTE</strong></td><td>Mean Tracking Error</td><td>平均欧氏误差（cm）</td><td>越低越好</td></tr></tbody></table></div><h3 id="对比实验"><a href="#对比实验" class="headerlink" title="对比实验"></a>对比实验</h3><p>论文将MVTracker与三类方法进行对比：</p><ul><li><p><strong>单视角方法</strong>：包括CoTracker3、DELTA、LocoTrack，仅使用单个视角输入，代表当前主流视频点跟踪型。</p></li><li><p><strong>多视角学习方法</strong>：包括Triplane、SpatialTracker，利用多视角特征进行3D建模。</p></li><li><p><strong>优化类方法</strong>：包括Shape of Motion、Dynamic 3DGS，依赖测试时序列级优化，非前馈推理。</p></li></ul><p>对比在Multi-View Kubric、DexYCB和Panoptic Studio上进行，评估不同方法在AJ、δavg、OA和MTE上的表现</p><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><h3 id="点关联组件"><a href="#点关联组件" class="headerlink" title="点关联组件"></a>点关联组件</h3><p>在Multi-View Kubric上训练不同变体，训练步数为总步数的25%，使用8 GPUs。对比三种关联编码方式：</p><ul><li><p>“No offset”：不使用偏移向量，仅依赖邻居点特征。</p></li><li><p>“Offset + location”：拼接偏移向量与邻居点的绝对世界坐标。</p></li><li><p>“Offset only”：仅使用相对偏移向量。</p></li></ul><p>最终结果是使用 offset only效果最好</p><h4 id="相机布局"><a href="#相机布局" class="headerlink" title="相机布局"></a>相机布局</h4><ul><li><p>Panoptic Studio：选择4个相机，设置三种布局：对称分布（Setup A）、邻近分布（Setup B和C）</p></li><li><p>DexYCB：选择连续的4个相机，分别为视图1–4（Setup A）、3–6（Setup B）、5–8（Setup C）。</p></li></ul><p>最终结果是MVTracker对相机布局是Robust的</p><h4 id="训练增强"><a href="#训练增强" class="headerlink" title="训练增强"></a>训练增强</h4><ul><li><p>训练时输入视图数量的可变性（从1到8视图随机采样）</p></li><li><p>深度图来源的混合使用：同时使用真值深度和估计深度进行训练</p></li></ul><p>在附录A中提供额外分析，包括深度估计质量对跟踪性能的影响；模型对深度噪声的鲁棒性测试；不同深度估计器（如DUSt3R、SPARF等）下的性能对比；以及典型失败案例分析，这里不做阐述。</p>]]></content>
      
      
      <categories>
          
          <category> 2025ICCV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多视角建模 </tag>
            
            <tag> 3D点追踪 </tag>
            
            <tag> 点云 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>西瓜书中涉及的机器学习算法</title>
      <link href="/2025/10/08/ML/"/>
      <url>/2025/10/08/ML/</url>
      
        <content type="html"><![CDATA[<p>这是笔者在准备nju推免机试时准备的自用资料，但是估计从今年（2025）过后不会再有这类型的机器学习算法题目了，可以作为学习西瓜书的一些参考（应该有不少谬误及typo）</p><hr><h2 id="常见损失函数"><a href="#常见损失函数" class="headerlink" title="常见损失函数"></a>常见损失函数</h2><h3 id="1-Mean-Squared-Error-MSE"><a href="#1-Mean-Squared-Error-MSE" class="headerlink" title="1. Mean Squared Error (MSE)"></a>1. Mean Squared Error (MSE)</h3><p>均方误差 (MSE) 用于回归任务，衡量预测值与真实值之间的平均平方差。</p><h4 id="数学公式："><a href="#数学公式：" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">L_{\text{MSE}} = \frac{1}{N} \sum_{i=1}^{N} (y_{\text{true}}^i - y_{\text{pred}}^i)^2</script><ul><li>$y_{\text{true}}^i $是第 ( i ) 个样本的真实值。</li><li>$ y_{\text{pred}}^i$ 是第 ( i ) 个样本的预测值。</li><li>( N ) 是样本总数。</li></ul><h3 id="2-Mean-Absolute-Error-MAE"><a href="#2-Mean-Absolute-Error-MAE" class="headerlink" title="2. Mean Absolute Error (MAE)"></a>2. Mean Absolute Error (MAE)</h3><p>平均绝对误差 (MAE) 用于回归任务，衡量预测值与真实值之间的平均绝对差。</p><h4 id="数学公式：-1"><a href="#数学公式：-1" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">L_{\text{MAE}} = \frac{1}{N} \sum_{i=1}^{N} |y_{\text{true}}^i - y_{\text{pred}}^i|</script><ul><li>$ y_{\text{true}}^i $ 是第 ( i ) 个样本的真实值。</li><li>$ y_{\text{pred}}^i $ 是第 ( i ) 个样本的预测值。</li></ul><hr><h3 id="3-Binary-Cross-Entropy"><a href="#3-Binary-Cross-Entropy" class="headerlink" title="3. Binary Cross-Entropy"></a>3. Binary Cross-Entropy</h3><p>二分类交叉熵用于二分类任务，衡量模型预测的概率与真实标签之间的差异。</p><h4 id="数学公式：-2"><a href="#数学公式：-2" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">L_{\text{binary}} = - \frac{1}{N} \sum_{i=1}^{N} \left[ y_{\text{true}}^i \log(y_{\text{pred}}^i) + (1 - y_{\text{true}}^i) \log(1 - y_{\text{pred}}^i) \right]</script><ul><li>( $y_{\text{true}}^i \in \{0, 1\}$ ) 是第 ( i ) 个样本的真实标签。</li><li>( $y_{\text{pred}}^i $) 是第 ( i ) 个样本的预测概率。</li></ul><hr><h3 id="4-Categorical-Cross-Entropy"><a href="#4-Categorical-Cross-Entropy" class="headerlink" title="4. Categorical Cross-Entropy"></a>4. Categorical Cross-Entropy</h3><p>多分类交叉熵用于多分类任务，衡量模型预测的概率分布与真实标签的分布之间的差异。</p><h4 id="数学公式：-3"><a href="#数学公式：-3" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">L_{\text{categorical}} = - \frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{\text{true},c}^i \log(y_{\text{pred},c}^i)</script><ul><li>( $y_{\text{true},c}^i \in \{0, 1\}$ ) 是第 ( i ) 个样本的真实标签的 one-hot 编码。</li><li>( $y_{\text{pred},c}^i $) 是第 ( i ) 个样本属于类别 ( c ) 的预测概率。</li><li>( C ) 是类别的总数。</li></ul><hr><h3 id="5-Hinge-Loss-SVM-Loss"><a href="#5-Hinge-Loss-SVM-Loss" class="headerlink" title="5. Hinge Loss (SVM Loss)"></a>5. Hinge Loss (SVM Loss)</h3><p>铰链损失（SVM损失）通常用于支持向量机（SVM），它最大化分类边界。</p><h4 id="数学公式：-4"><a href="#数学公式：-4" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">L_{\text{hinge}} = \frac{1}{N} \sum_{i=1}^{N} \max(0, 1 - y_{\text{true}}^i y_{\text{pred}}^i)</script><ul><li>( $y_{\text{true}}^i$ ) 是第 ( i ) 个样本的真实标签（取值为 ±1)）。</li><li>( $y_{\text{pred}}^i $) 是第 ( i ) 个样本的预测值。</li></ul><hr><h3 id="6-Huber-Loss"><a href="#6-Huber-Loss" class="headerlink" title="6. Huber Loss"></a>6. Huber Loss</h3><p>Huber 损失对回归任务中的异常值进行了处理，当误差较小时使用平方误差，误差较大时使用线性误差。</p><h4 id="数学公式：-5"><a href="#数学公式：-5" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">L_{\text{huber}} = \frac{1}{N} \sum_{i=1}^{N} \left[ \begin{array}{ll}0.5 \cdot \left| y_{\text{true}}^i - y_{\text{pred}}^i \right|^2 & \text{if } \left| y_{\text{true}}^i - y_{\text{pred}}^i \right| \leq \delta \\\delta \cdot \left( \left| y_{\text{true}}^i - y_{\text{pred}}^i \right| - 0.5 \cdot \delta \right) & \text{if } \left| y_{\text{true}}^i - y_{\text{pred}}^i \right| > \delta\end{array} \right.</script><ul><li>( \delta ) 是一个超参数，控制“平滑”与“惩罚”之间的平衡。</li><li>( y_{\text{true}}^i ) 是第 ( i ) 个样本的真实值。</li><li>( y_{\text{pred}}^i ) 是第 ( i ) 个样本的预测值。</li></ul><hr><h3 id="7-L2-Regularization-Loss"><a href="#7-L2-Regularization-Loss" class="headerlink" title="7. L2 Regularization Loss"></a>7. L2 Regularization Loss</h3><p>L2 正则化损失常用于防止过拟合，鼓励模型参数的平方和较小。</p><h4 id="数学公式：-6"><a href="#数学公式：-6" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">L_{\text{L2}} = \lambda_{\text{reg}} \sum_{j=1}^{M} w_j^2</script><ul><li>( w_j ) 是模型参数的第 ( j ) 个权重。</li><li>( \lambda_{\text{reg}} ) 是正则化系数。</li><li>( M ) 是参数的数量。</li><li><ul><li>惩罚的是参数的<strong>平方</strong>，所以对大的参数惩罚非常重（比如 w=10，惩罚是100；w=2，惩罚是4）。</li><li>它会让所有参数都<strong>向0收缩</strong>，但通常不会让任何参数<strong>精确为0</strong>。</li><li>结果是：<strong>所有特征都保留，但权重变小了</strong>，模型更平滑。</li><li>处理特征相关性强</li></ul></li></ul><hr><h3 id="8-L1-Regularization-Loss"><a href="#8-L1-Regularization-Loss" class="headerlink" title="8. L1 Regularization Loss"></a>8. L1 Regularization Loss</h3><p>L1 正则化损失常用于促进稀疏性，鼓励模型参数为零。</p><h4 id="数学公式：-7"><a href="#数学公式：-7" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">L_{\text{L1}} = \lambda_{\text{reg}} \sum_{j=1}^{M} |w_j|</script><ul><li>( w_j ) 是模型参数的第 ( j ) 个权重。</li><li>( \lambda_{\text{reg}} ) 是正则化系数。</li><li>( M ) 是参数的数量。</li><li><ul><li>惩罚的是参数的<strong>绝对值</strong>，对大参数和小参数的惩罚是线性的。</li><li>由于其几何特性（L1的等高线是菱形），优化过程中更容易“撞到角点”，而角点对应某些参数为0。</li><li>结果是：<strong>会把不重要的特征的权重直接压缩为0</strong>，实现<strong>特征选择</strong></li><li>促进参数权重的稀疏性</li></ul></li></ul><hr><h3 id="9-Kullback-Leibler-Divergence-KL-Divergence"><a href="#9-Kullback-Leibler-Divergence-KL-Divergence" class="headerlink" title="9. Kullback-Leibler Divergence (KL Divergence)"></a>9. Kullback-Leibler Divergence (KL Divergence)</h3><p>KL 散度衡量两个概率分布之间的差异，常用于概率模型和生成模型。</p><h4 id="数学公式：-8"><a href="#数学公式：-8" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">D_{\text{KL}}(p || q) = \sum_{i=1}^{N} p_i \log \left( \frac{p_i}{q_i} \right)</script><ul><li>( p_i ) 是真实分布的第 ( i ) 个概率值。</li><li>( q_i ) 是预测分布的第 ( i ) 个概率值。</li></ul><hr><h3 id="10-Softmax-Function"><a href="#10-Softmax-Function" class="headerlink" title="10. Softmax Function"></a>10. Softmax Function</h3><p>Softmax 函数将一个向量转换为概率分布，广泛应用于多分类问题。</p><h4 id="数学公式：-9"><a href="#数学公式：-9" class="headerlink" title="数学公式："></a>数学公式：</h4><script type="math/tex; mode=display">\text{softmax}(x)_i = \frac{e^{x_i}}{\sum_{j=1}^{C} e^{x_j}}</script><ul><li>( x_i ) 是输入向量 ( x ) 中的第 ( i ) 个元素。</li><li>( C ) 是类别的总数。</li></ul><hr><h3 id="11-Softmax-Loss"><a href="#11-Softmax-Loss" class="headerlink" title="11. Softmax Loss"></a>11. Softmax Loss</h3><p>Softmax 损失（与交叉熵损失类似）常用于多分类问题中，结合 Softmax 函数计算损失。</p><h3 id="数学公式：-10"><a href="#数学公式：-10" class="headerlink" title="数学公式："></a>数学公式：</h3><script type="math/tex; mode=display">L_{\text{softmax}} = - \frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{\text{true},c}^i \log(y_{\text{pred},c}^i)</script><ul><li>( $y_{\text{true},c}^i \in \{0, 1\} $) 是第 ( i ) 个样本的真实标签的 one-hot 编码。</li><li>( $y_{\text{pred},c}^i $) 是第 ( i ) 个样本属于类别 ( c ) 的预测概率。</li></ul><hr><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as np# 1. Mean Squared Error (MSE)def mean_squared_error(y_true, y_pred):    return np.mean((y_true - y_pred) ** 2)# 2. Mean Absolute Error (MAE)def mean_absolute_error(y_true, y_pred):    return np.mean(np.abs(y_true - y_pred))# 3. Binary Cross-Entropydef binary_crossentropy(y_true, y_pred):    epsilon &#x3D; 1e-15  # Avoid log(0)    y_pred &#x3D; np.clip(y_pred, epsilon, 1 - epsilon)  # Prevent y_pred from being 0 or 1    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))&#x2F;&#x2F;把 y_pred 的所有值限制在 [epsilon, 1 - epsilon] 范围内# 4. Categorical Cross-Entropydef categorical_crossentropy(y_true, y_pred):    #numpy.clip(a, a_min, a_max, out&#x3D;None)    epsilon &#x3D; 1e-15  # 避免对数计算时出现log(0)    y_pred &#x3D; np.clip(y_pred, epsilon, 1 - epsilon)  # 防止y_pred为0或1    #y_true 必须是 one-hot 编码（独热编码） 的形式    return -np.mean(np.sum(y_true * np.log(y_pred), axis&#x3D;1))    #axis&#x3D;1出来时竖着，&#x3D;0出来时横着# 5. Hinge Loss (SVM Loss)def hinge_loss(y_true, y_pred):    return np.mean(np.maximum(0, 1 - y_true * y_pred))# 6. Huber Lossdef huber_loss(y_true, y_pred, delta&#x3D;1.0):    error &#x3D; np.abs(y_true - y_pred)    is_small_error &#x3D; error &lt;&#x3D; delta    small_error_loss &#x3D; 0.5 * error**2    large_error_loss &#x3D; delta * (error - 0.5 * delta)    return np.mean(np.where(is_small_error, small_error_loss, large_error_loss))# 7. L2 Regularization Lossdef l2_regularization_loss(weights, lambda_reg&#x3D;0.01):    return lambda_reg * np.sum(weights**2)# 8. L1 Regularization Lossdef l1_regularization_loss(weights, lambda_reg&#x3D;0.01):    return lambda_reg * np.sum(np.abs(weights))# 9. Kullback-Leibler Divergence (KL Divergence)def kl_divergence(p, q):    epsilon &#x3D; 1e-15  # Prevent log(0)    p &#x3D; np.clip(p, epsilon, 1 - epsilon)    q &#x3D; np.clip(q, epsilon, 1 - epsilon)    return np.sum(p * np.log(p &#x2F; q))# 10. Softmax Functiondef softmax(x):    exp_x &#x3D; np.exp(x - np.max(x, axis&#x3D;-1, keepdims&#x3D;True))  # Prevent overflow    return exp_x &#x2F; np.sum(exp_x, axis&#x3D;-1, keepdims&#x3D;True)# 11. Softmax Lossdef softmax_loss(y_true, y_pred):    epsilon &#x3D; 1e-15    y_pred &#x3D; np.clip(y_pred, epsilon, 1 - epsilon)  # Prevent log(0)    return -np.mean(np.sum(y_true * np.log(y_pred), axis&#x3D;1))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h3><p>如果数据中存在缺失值，可以选择填充它们，通常用均值或中位数来填充数值型数据。如果是类别数据，也可以选择填充众数。</p><p><code>mean_value = np.nanmean(column)#忽略nan值</code></p><p><code>column[np.isnan(column)] = mean_value # 填充nan缺失值为mean_value</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npdef fill_missing_values(data):    &#39;&#39;&#39;    使用每列的均值填充缺失值    :param data: 数据集，类型为ndarray    :return: 填充后的数据集    &#39;&#39;&#39;    # 遍历每一列，填充缺失值    for i in range(data.shape[1]):        column &#x3D; data[:, i]        # 计算列的均值（忽略nan）        mean_value &#x3D; np.nanmean(column)        # 填充缺失值        column[np.isnan(column)] &#x3D; mean_value    return data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><p>对特征进行标准化，使其均值为0，方差为1，避免特征尺度对模型产生不良影响。标准化可以使用 <code>(x - mean) / std</code> 的方式来实现。</p><p><code>means=np.mean(data,axis=0) #取每一个特征的均值</code></p><p><code>std=np.std(data,axis=0) #取每一个特征的标准差</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">def standardize_data(data):    &#39;&#39;&#39;    标准化数据：每个特征减去均值，再除以标准差    :param data: 数据集，类型为ndarray    :return: 标准化后的数据集    &#39;&#39;&#39;    # 计算每列的均值和标准差    means &#x3D; np.mean(data, axis&#x3D;0)    stds &#x3D; np.std(data, axis&#x3D;0)    # 标准化每一列    standardized_data &#x3D; (data - means) &#x2F; stds    return standardized_data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p><img src="/images/ml/72967e50-080e-477c-91cc-73731e5a22db.png" alt="72967e50-080e-477c-91cc-73731e5a22db"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">min_vals &#x3D; np.min(data, axis&#x3D;0)max_vals &#x3D; np.max(data, axis&#x3D;0)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">def normalize_data(data):    &#39;&#39;&#39;    归一化数据：将每个特征缩放到[0, 1]范围内    :param data: 数据集，类型为ndarray    :return: 归一化后的数据集    &#39;&#39;&#39;    # 计算每列的最小值和最大值    min_vals &#x3D; np.min(data, axis&#x3D;0)    max_vals &#x3D; np.max(data, axis&#x3D;0)    # 归一化每一列    normalized_data &#x3D; (data - min_vals) &#x2F; (max_vals - min_vals)    return normalized_data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Z-score"><a href="#Z-score" class="headerlink" title="Z-score"></a>Z-score</h3><p>可以使用 Z-Score 方法来去除异常值。通常认为 Z-Score 大于 3 或小于 -3 的样本是异常值。</p><p><code>filtered_data = data[np.all(np.abs(z_scores) &lt; threshold, axis=1)]</code></p><ul><li><code>axis=1</code>：沿着列方向判断（即：对每个样本的所有特征判断）</li><li><code>np.all</code>：要求<strong>所有特征都满足条件</strong>（即：所有特征的 |Z| &lt; threshold）</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">def remove_outliers(data, threshold&#x3D;3):    &#39;&#39;&#39;    使用 Z-Score 去除异常值    :param data: 数据集，类型为ndarray    :param threshold: Z-Score 阈值，默认是3    :return: 去除异常值后的数据集    &#39;&#39;&#39;    # 计算每列的均值和标准差    means &#x3D; np.mean(data, axis&#x3D;0)    stds &#x3D; np.std(data, axis&#x3D;0)    # 计算 Z-Score    z_scores &#x3D; (data - means) &#x2F; stds    # 过滤 Z-Score 小于阈值的数据    filtered_data &#x3D; data[np.all(np.abs(z_scores) &lt; threshold, axis&#x3D;1)]    return filtered_data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npdef linear_regression_gradient_descent(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int) -&gt; np.ndarray:    # Your code here, make sure to round    m,n&#x3D;X.shape    theta&#x3D;np.zeros((n,1))    y &#x3D; y.reshape(-1, 1)  # (m,) -&gt; (m, 1)    for i in range(iterations):        # 计算预测误差        error &#x3D; X @ theta - y  # (m, 1)        # 计算梯度: (1&#x2F;m) * X^T @ error        gradient &#x3D; (1&#x2F;m) * X.T @ error        # 更新参数        theta -&#x3D; alpha * gradient    return np.round(theta,4)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Python 尝试广播 <code>(3,1)</code> 和 <code>(3,)</code>，但<strong>广播规则不匹配</strong>，<code>y</code> reshape 成 <code>(m, 1)</code></p><h2 id="广义线性模型"><a href="#广义线性模型" class="headerlink" title="广义线性模型"></a>广义线性模型</h2><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p><img title="" src="/images/ml/de3a4ee6-0c36-421d-b365-d688dd1c4542.png" alt="de3a4ee6-0c36-421d-b365-d688dd1c4542" style="zoom:100%;"><img title="" src="/images/ml/94d0039d-c97e-4a61-ad89-375994782858.png" alt="94d0039d-c97e-4a61-ad89-375994782858" style="zoom:100%;"></p><p><img title="" src="/images/ml/6caef8a4-87bd-4b74-ae1c-97b14174b7f9.png" alt="6caef8a4-87bd-4b74-ae1c-97b14174b7f9" style="zoom:100%;"><img title="" src="/images/ml/93d50e4f-e0a3-4658-af4d-49e041d061d2.png" alt="93d50e4f-e0a3-4658-af4d-49e041d061d2" style="zoom:100%;"></p><p>MSE(mean squard error) MAE(mean absolute error) RMSE(root mse) R^2(R-squard)</p><p><code>np.mean((y_predict - y_test) ** 2) #mean自带了求和功能</code></p><p><code>X = np.hstack((np.ones((train_data.shape[0], 1)), train_data))#hstack添加一个偏置项b，每个样本的bias特征值为1</code></p><p><code>np.linalg.inv(X.T.dot(X)).dot(X.T).dot(train_label)</code></p><p><code>numpy.var(array, axis) #var为方差variance，std为标准差</code></p><p><code>numpy.vstack(([1,2,3],[4,5,6])) 行顺序堆叠</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as np# MSEdef mse_score(y_predict, y_test):    return np.mean((y_predict - y_test) ** 2)# R2def r2_score(y_predict, y_test):    &#39;&#39;&#39;    input: y_predict (ndarray): 预测值           y_test (ndarray): 真实值    output: r2 (float): r2值    &#39;&#39;&#39;    t1 &#x3D; np.sum((y_predict - y_test) ** 2)    t2 &#x3D; np.sum((y_test - np.mean(y_test)) ** 2)    return 1 - t1 &#x2F; t2class LinearRegression:    def __init__(self):        &#39;&#39;&#39;初始化线性回归模型&#39;&#39;&#39;        self.theta &#x3D; None    def fit_normal(self, train_data, train_label):        &#39;&#39;&#39;        input: train_data (ndarray): 训练样本               train_label (ndarray): 训练标签        &#39;&#39;&#39;        X &#x3D; np.hstack((np.ones((train_data.shape[0], 1)), train_data))        #创建一个列向量，全为1，长度等于样本数        self.theta &#x3D; np.linalg.inv(X.T.dot(X)).dot(X.T).dot(train_label)        return self.theta    def predict(self, test_data):        &#39;&#39;&#39;        input: test_data (ndarray): 测试样本        &#39;&#39;&#39;        test_data &#x3D; np.hstack((np.ones((test_data.shape[0], 1)), test_data))        return test_data.dot(self.theta)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="逻辑回归Logistic-Regression"><a href="#逻辑回归Logistic-Regression" class="headerlink" title="逻辑回归Logistic Regression"></a>逻辑回归Logistic Regression</h3><p>逻辑回归是通过回归的思想来解决二分类问题的算法，用一个<strong>S型的函数（Sigmoid函数）</strong>，把线性回归的结果压缩到 [0,1] 区间，解释为“属于某个类别的概率”。它内部还是在做<strong>线性回归</strong> wTx+b，只是最后加了一个非线性变换（Sigmoid），用来做<strong>分类概率输出</strong>。可以使用np.exp(-z)</p><p><img title="" src="/images/ml/c08e2d31-b7a3-464d-9912-a0008883dcf1.png" alt="c08e2d31-b7a3-464d-9912-a0008883dcf1" style="zoom:100%;"></p><p>交叉熵损失yi代表真实类别，log(yi_hat)代表预测类别</p><p><img title="" src="/images/ml/22893227-1066-4b56-b28f-bf929f91158e.png" alt="22893227-1066-4b56-b28f-bf929f91158e" style="zoom:100%;"><img title="" src="/images/ml/ec35d332-8f41-40cc-b8b6-cc53fecdc323.png" alt="ec35d332-8f41-40cc-b8b6-cc53fecdc323" style="zoom:100%;"></p><h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>沿着“当前点的负梯度方向”走一小步，就能慢慢靠近最小值，在多维空间中，<strong>梯度向量</strong>是函数增长最快的方向。</p><p>大学习率收敛快，迅速接近最优解，但是容易震荡无法收敛，小学习率稳定收敛到精确解（可能局部），但是慢</p><div class="table-container"><table><thead><tr><th><strong>问题</strong></th><th><strong>过拟合</strong></th><th><strong>欠拟合</strong></th></tr></thead><tbody><tr><td><strong>表现</strong></td><td>训练误差低，测试误差高</td><td>训练误差和测试误差都高，模型过于简单或不充分学习数据特征</td></tr><tr><td><strong>学习率过大</strong></td><td>可能导致模型无法稳定收敛，训练过程震荡，导致最终过拟合训练数据</td><td>过大的学习率可能跳过局部最优，导致无法捕捉到数据中的复杂模式，出现欠拟合</td></tr><tr><td><strong>学习率过小</strong></td><td>可能导致训练过程过于缓慢，使得模型误学习训练数据中的噪声，过拟合</td><td>过小的学习率可能导致参数更新不足，学习不到数据的复杂模式，造成欠拟合</td></tr><tr><td><strong>解决方法</strong></td><td>增加正则化，减少模型复杂度，更多数据，适当调整学习率</td><td>增加模型复杂度，训练更多轮次，使用合适的学习率</td></tr></tbody></table></div><pre class="line-numbers language-python" data-language="python"><code class="language-python"># -*- coding: utf-8 -*-import numpy as npimport warningswarnings.filterwarnings(&quot;ignore&quot;)def sigmoid(x):    &#39;&#39;&#39;    sigmoid函数    :param x: 转换前的输入    :return: 转换后的概率    &#39;&#39;&#39;    return 1&#x2F;(1+np.exp(-x))def fit(x,y,eta&#x3D;1e-3,n_iters&#x3D;10000):    &#39;&#39;&#39;    训练逻辑回归模型    :param x: 训练集特征数据，类型为ndarray    :param y: 训练集标签，类型为ndarray    :param eta: 学习率，类型为float    :param n_iters: 训练轮数，类型为int    :return: 模型参数，类型为ndarray    &#39;&#39;&#39;    #   请在此添加实现代码   #    #********** Begin *********#    m,n&#x3D;x.shape    theta&#x3D;np.zeros(n)    for i in range(n_iters):        yy&#x3D;x.dot(theta)        z&#x3D;sigmoid(yy)        grad&#x3D;x.T.dot(z-y)        theta-&#x3D;eta*grad    return theta    #********** End **********#from sklearn.linear_model import LogisticRegressiondef digit_predict(train_image, train_label, test_image):    &#39;&#39;&#39;    实现功能：训练模型并输出预测结果    :param train_sample: 包含多条训练样本的样本集，类型为ndarray,shape为[-1, 8, 8]    :param train_label: 包含多条训练样本标签的标签集，类型为ndarray    :param test_sample: 包含多条测试样本的测试集，类型为ndarry    :return: test_sample对应的预测标签    &#39;&#39;&#39;    #************* Begin ************#    train&#x3D;train_image.reshape(len(train_image),-1)#-1 表示自动计算维度，将除样本数量以外的维度全部拉平成一维。    test&#x3D;test_image.reshape(len(test_image),-1)    model&#x3D;LogisticRegression(max_iter&#x3D;1000,C&#x3D;12)# C：正则化系数的倒数，默认为 1.0 ，越小代表正则化越强；    model.fit(train,train_label)    result&#x3D;model.predict(test)    return result    #************* End **************#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h3><p>它是一个<strong>二分类线性模型</strong>，核心思想是：找到一个超平面，将两类数据线性分开。</p><ul><li><p><strong>适用于线性可分数据集</strong>：即存在一个超平面能将两类样本完全分开。</p></li><li><p><strong>不能处理非线性问题</strong>：如异或问题（XOR）感知机无法解决。</p></li></ul><p><img title="" src="/images/ml/f572fd80-7786-4793-85d6-0f4738df2710.png" alt="f572fd80-7786-4793-85d6-0f4738df2710" style="zoom:100%;"><img title="" src="/images/ml/42e50b31-90f0-4b65-a426-5b8b2a1fa845.png" alt="42e50b31-90f0-4b65-a426-5b8b2a1fa845" style="zoom:100%;"></p><p><code>predict = np.where(output &gt; 0, 1, -1)</code></p><p><code>predict=np.sign(output)</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">#encoding&#x3D;utf8import numpy as np#构建感知机算法class Perceptron(object):    def __init__(self, learning_rate &#x3D; 0.01, max_iter &#x3D; 200):        self.lr&#x3D;learning_rate        self.max_iter&#x3D;max_iter    def fit(self, data, label):        &#39;&#39;&#39;        input:data(ndarray):训练数据特征              label(ndarray):训练数据标签        output:w(ndarray):训练好的权重               b(ndarry):训练好的偏置        &#39;&#39;&#39;        #编写感知机训练方法，w为权重，b为偏置        #********* Begin *********#        self.w&#x3D;np.random.randn(data.shape[1])        self.b&#x3D;0        for i in range(self.max_iter):            for j in range(len(data)):                output&#x3D;self.w.dot(data[j].T)+self.b                predict&#x3D;1 if output&gt;0 else -1                if(label[j]*output&lt;&#x3D;0):                    self.w+&#x3D;self.lr*label[j]*data[j]                    self.b+&#x3D;self.lr*label[j]        #********* End *********#    def predict(self, data):        &#39;&#39;&#39;        input:data(ndarray):测试数据特征        output:predict(ndarray):预测标签        &#39;&#39;&#39;        #********* Begin *********#        output &#x3D; np.dot(data, self.w) + self.b        predict &#x3D; np.where(output &gt; 0, 1, -1)        predict&#x3D;np.sign(output)        #********* End *********#        return predict#encoding&#x3D;utf8import osimport pandas as pdfrom sklearn.linear_model.perceptron import Perceptronif os.path.exists(&#39;.&#x2F;step2&#x2F;result.csv&#39;):    os.remove(&#39;.&#x2F;step2&#x2F;result.csv&#39;)#********* Begin *********#train_data&#x3D;pd.read_csv(&#39;.&#x2F;step2&#x2F;train_data.csv&#39;)train_label&#x3D;pd.read_csv(&#39;.&#x2F;step2&#x2F;train_label.csv&#39;)train_label&#x3D;train_label[&#39;target&#39;]test_data&#x3D;pd.read_csv(&#39;.&#x2F;step2&#x2F;test_data.csv&#39;)model&#x3D;Perceptron(eta0&#x3D;0.1,max_iter&#x3D;500)#eta0：学习率大小，默认为 1.0 ；#max_iter：最大训练轮数。model.fit(train_data,train_label)prediction&#x3D;model.predict(test_data)res&#x3D;pd.DataFrame(prediction,columns&#x3D;[&#39;result&#39;])res.to_csv(&#39;.&#x2F;step2&#x2F;result.csv&#39;,index&#x3D;False)#********* End *********#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="LDA（线性判别分析）"><a href="#LDA（线性判别分析）" class="headerlink" title="LDA（线性判别分析）"></a>LDA（线性判别分析）</h3><p>LDA 是一种 <strong>有监督降维</strong> 技术，其目标是将数据投影到一个低维空间中，使得不同类别之间尽可能可分。目标是最大化类间散度（类之间的距离），最小化类内散度（每类自己的分散程度）。</p><p><img title="" src="/images/ml/4d717c12-bca5-47eb-ab20-f99094171823.png" alt="4d717c12-bca5-47eb-ab20-f99094171823" style="zoom:100%;"><img title="" src="/images/ml/b53022c6-9481-4c55-95cb-702d108573d5.png" alt="b53022c6-9481-4c55-95cb-702d108573d5" style="zoom:100%;"></p><p><img title="" src="/images/ml/4d5a5350-0b9e-4559-b764-ce155badb894.png" alt="4d5a5350-0b9e-4559-b764-ce155badb894" style="zoom:100%;"><img title="" src="/images/ml/3e366804-e71c-43ad-8782-1b6cc0153e69.png" alt="3e366804-e71c-43ad-8782-1b6cc0153e69" style="zoom:100%;"><img title="" src="/images/ml/470f2a07-a3aa-4edf-8c7c-8dc4c1a54a8d.png" alt="470f2a07-a3aa-4edf-8c7c-8dc4c1a54a8d" style="zoom:100%;"><img title="" src="/images/ml/bfa7df51-524a-441f-96ef-9e0129454a26.png" alt="bfa7df51-524a-441f-96ef-9e0129454a26" style="zoom:100%;"></p><p><code>x0m = np.mean(x0, axis=0)  # 类别 0 的均值向量,求样本的每个特征均值要加axis=0</code></p><p><code>sigma0 = np.cov(x0, rowvar=False)#默认 np.cov 会按行计算特征（即样本是列），但我们通常每一行是一个样本，所以需要加</code>.T<code>或使用rowvar=False</code></p><p><code>mean_diff = (x0m - x1m).reshape(-1, 1)  # 列向量化, shape=(n,) 变成 shape=(n, 1)，列向量</code></p><p><code>return np.linalg.inv(sw).dot(x0m - x1m)</code></p><p><code>x_new = model.fit_transform(x, y)</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npdef lda(X, y):    &#39;&#39;&#39;    线性判别分析（Linear Discriminant Analysis）    参数:        X(ndarray): 样本特征矩阵，形状为 (n_samples, n_features)        y(ndarray): 样本标签向量，取值为 0 或 1（仅支持二分类）    返回:        w(ndarray): 最优投影方向向量，用于将高维数据投影到一维，实现类别分离    &#39;&#39;&#39;    # 将数据按类别分开（这里是二分类，分成类 0 和类 1）    x0 &#x3D; X[y &#x3D;&#x3D; 0]  # 类别 0 的所有样本    x1 &#x3D; X[y &#x3D;&#x3D; 1]  # 类别 1 的所有样本    # 分别计算每一类的均值向量（每个特征的均值）    x0m &#x3D; np.mean(x0, axis&#x3D;0)  # 类别 0 的均值向量    x1m &#x3D; np.mean(x1, axis&#x3D;0)  # 类别 1 的均值向量    # 分别计算每一类的类内协方差矩阵（每一类内部的样本方差+协方差）    # rowvar&#x3D;False 表示按列计算协方差（列是特征，行是样本）    sigma0 &#x3D; np.cov(x0, rowvar&#x3D;False)    sigma1 &#x3D; np.cov(x1, rowvar&#x3D;False)    # 总类内散度矩阵 Sw（两个类别的协方差矩阵之和）    sw &#x3D; sigma0 + sigma1    # 类间散度矩阵 Sb &#x3D; (μ1 - μ0)(μ1 - μ0)^T，衡量类别中心的分离程度    mean_diff &#x3D; (x0m - x1m).reshape(-1, 1)  # 列向量化    sb &#x3D; mean_diff @ mean_diff.T  # 外积构成类间散度矩阵    # 计算广义特征值问题 Sw^-1 * Sb 的特征值与特征向量    eigvals, eigvecs &#x3D; np.linalg.eig(np.linalg.inv(sw).dot(sb))    # 将特征值按从大到小排序，找出最大特征值对应的方向    idx &#x3D; np.argsort(eigvals)[::-1]  # 逆序排列索引    w &#x3D; eigvecs[:, idx[0]]  # 最大特征值对应的特征向量（最佳投影方向）    return w  # 返回用于降维的最优方向向量#encoding&#x3D;utf8 from sklearn.discriminant_analysis import LinearDiscriminantAnalysisdef lda(x,y):    &#39;&#39;&#39;    input:x(ndarray):待处理数据          y(ndarray):待处理数据标签    output:x_new(ndarray):降维后数据    &#39;&#39;&#39;    model &#x3D; LinearDiscriminantAnalysis(n_components&#x3D;2)     x_new &#x3D; model.fit_transform(x, y)    return x_new<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="多分类策略"><a href="#多分类策略" class="headerlink" title="多分类策略"></a>多分类策略</h3><h4 id="OvO"><a href="#OvO" class="headerlink" title="OvO"></a>OvO</h4><p>将 K 类的多分类问题拆分为 $\frac{K(K-1)}{2}$ 个二分类问题，每个分类器只区分两个类别。</p><p>对于任意两个类别 $c_i$ 与 $c_j$（$i &lt; j$）：</p><ol><li><p>从数据集中仅选出这两个类别的样本。</p></li><li><p>用二分类模型训练出分类器 $f_{i,j}$，判断样本属于 $c_i$ 还是 $c_j$。</p></li><li><p>最终得到 $\frac{K(K-1)}{2}$ 个分类器。</p></li><li><ul><li><p>对测试样本 $x$，输入所有分类器 $f_{i,j}$。</p></li><li><p>每个分类器对样本进行投票（即判断更像哪个类别）。</p></li><li><p>汇总投票，得票最多的类别为最终预测类别。</p></li></ul></li></ol><p><code>self.classes_ = np.unique(y)</code></p><p><code>self.models[(cls1, cls2)] = model</code> map</p><p><code>votes = [defaultdict(int) for _ in range(len(X))]</code></p><p><code>for (cls1, cls2), model in self.models.items()</code></p><p><code>`enumerate(preds)</code> 的作用是：<strong>在遍历预测结果 <code>preds</code> 的同时，提供每个预测结果的索引</strong>。它返回的是 <code>(索引, 值)</code> 对。`</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">from collections import defaultdictfrom sklearn.linear_model import LogisticRegressionclass OvOClassifier:    def __init__(self, base_model&#x3D;None):        self.base_model &#x3D; base_model if base_model else LogisticRegression()        self.models &#x3D; &#123;&#125;        self.classes_ &#x3D; None    def fit(self, X, y):        self.classes_ &#x3D; np.unique(y)        self.models &#x3D; &#123;&#125;        for i in range(len(self.classes_)):            for j in range(i + 1, len(self.classes_)):                cls1, cls2 &#x3D; self.classes_[i], self.classes_[j]# 找到所有属于 cls1 或 cls2 的样本X_pair &#x3D; []y_binary &#x3D; []for xi, yi in zip(X, y):    if yi &#x3D;&#x3D; cls1 or yi &#x3D;&#x3D; cls2:        X_pair.append(xi)        y_binary.append(1 if yi &#x3D;&#x3D; cls1 else 0)X_pair &#x3D; np.array(X_pair)y_binary &#x3D; np.array(                model &#x3D; LogisticRegression()                model.fit(X_pair, y_binary)                self.models[(cls1, cls2)] &#x3D; model#是一个 字典，key 是一个类别对的 元组，value 是对应的 训练好的模型对象    def predict(self, X):        votes &#x3D; [defaultdict(int) for _ in range(len(X))]#创建了一个列表 votes，这个列表有 len(X) 个元素，每个元素是一个 defaultdict(int)        for (cls1, cls2), model in self.models.items():            preds &#x3D; model.predict(X)            for i, pred in enumerate(preds):                voted_class &#x3D; cls1 if pred &#x3D;&#x3D; 1 else cls2                votes[i][voted_class] +&#x3D; 1        final_preds &#x3D; []        final_preds &#x3D; [max(vote, key&#x3D;vote.get) for vote in votes]#vote 是一个 dict（通常是像 &#123;&#39;A&#39;: 2, &#39;B&#39;: 3&#125; 这样的结构），键是类别，值是票数；#vote.get 用作 key 函数，表示对每个键使用 vote.get(键) 作为排序依据；#max(...) 找出拥有最多票数的类别。        return np.array(final_preds)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="OvR"><a href="#OvR" class="headerlink" title="OvR"></a>OvR</h4><p>将一个 K 类的多分类问题拆解为 K 个二分类问题。每个分类器的任务是识别某一个类别（“正类”）与其余所有类别（“负类”）之间的区别。</p><p>假设标签集合为 $C = {c_1, c_2, …, c_K}$</p><p>对于每一个类别 $c_i$：</p><ol><li><p>创建一个新的二分类训练集：</p><ul><li><p>样本属于 $c_i$ 的，标签为 1（正类）</p></li><li><p>样本不属于 $c_i$ 的，标签为 0（负类）</p></li></ul></li><li><p>用一个二分类器（如 Logistic Regression、SVM）训练该数据子集。</p></li><li><p>共训练 K 个分类器，分别记为 $f_1, f_2, …, f_K$。</p></li><li><ul><li><p>对于一个测试样本 $x$，将其输入所有分类器 $f_1(x), …, f_K(x)$。</p></li><li><p>每个分类器输出一个置信度/得分。</p></li><li><p>选择得分最高的那个分类器所代表的类别作为预测结果。</p></li></ul></li></ol><div class="table-container"><table><thead><tr><th>特性</th><th>OvR (One-vs-Rest)</th><th>OvO (One-vs-One)</th></tr></thead><tbody><tr><td>分类器数量</td><td>K</td><td>K(K-1)/2</td></tr><tr><td>每个分类器训练样本</td><td>全部样本（正类 vs 其他）</td><td>两类样本</td></tr><tr><td>预测机制</td><td>最大置信度</td><td>多数投票</td></tr><tr><td>实现复杂度</td><td>较低</td><td>较高</td></tr><tr><td>优点</td><td>简洁、高效</td><td>更适合类别数少、边界复杂的任务</td></tr><tr><td>缺点</td><td>易受类别不均衡影响</td><td>分类器数量多、计算成本高</td></tr></tbody></table></div><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as np# 逻辑回归类class tiny_logistic_regression(object):    def __init__(self):        # W 是系数，b 是截距        self.coef_ &#x3D; None        self.intercept_ &#x3D; None        self._theta &#x3D; None  # 存储所有的 W 和 b        self.label_map &#x3D; &#123;&#125;  # 0&#x2F;1 到标签的映射    def _sigmoid(self, x):        return 1. &#x2F; (1. + np.exp(-x))  # Sigmoid 激活函数    # 训练模型    def fit(self, train_datas, train_labels, learning_rate&#x3D;1e-4, n_iters&#x3D;1e3):        # 计算损失函数        def J(theta, X_b, y):            y_hat &#x3D; self._sigmoid(X_b.dot(theta))            try:                return -np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)) &#x2F; len(y)            except:                return float(&#39;inf&#39;)  # 避免计算出错        # 损失函数对 theta 的梯度        def dJ(theta, X_b, y):            return X_b.T.dot(self._sigmoid(X_b.dot(theta)) - y) &#x2F; len(y)        # 批量梯度下降        def gradient_descent(X_b, y, initial_theta, learning_rate, n_iters&#x3D;1e2, epsilon&#x3D;1e-6):            theta &#x3D; initial_theta            cur_iter &#x3D; 0            while cur_iter &lt; n_iters:                gradient &#x3D; dJ(theta, X_b, y)                last_theta &#x3D; theta                theta &#x3D; theta - learning_rate * gradient  # 更新 theta                # 判断是否满足收敛条件                if abs(J(theta, X_b, y) - J(last_theta, X_b, y)) &lt; epsilon:                    break                cur_iter +&#x3D; 1            return theta        # 将训练数据加上截距项（x0 &#x3D; 1）        X_b &#x3D; np.hstack([np.ones((len(train_datas), 1)), train_datas])        initial_theta &#x3D; np.zeros(X_b.shape[1])  # 初始化theta为零        self._theta &#x3D; gradient_descent(X_b, train_labels, initial_theta, learning_rate, n_iters)        self.intercept_ &#x3D; self._theta[0]        self.coef_ &#x3D; self._theta[1:]        return self    # 预测样本属于正类的概率    def predict_proba(self, X):        X_b &#x3D; np.hstack([np.ones((len(X), 1)), X])        return self._sigmoid(X_b.dot(self._theta))    # 预测：如果属于正类的概率 &gt;&#x3D; 0.5，则预测为1，否则为0    def predict(self, X):        proba &#x3D; self.predict_proba(X)        return np.array(proba &gt;&#x3D; 0.5, dtype&#x3D;&#39;int&#39;)# One-vs-Rest (OvR) 分类器class OvR(object):    def __init__(self):        self.models &#x3D; []  # 用于保存每个类别的二分类器        self.real_label &#x3D; []  # 用于保存正类标签    def fit(self, train_datas, train_labels):        &#39;&#39;&#39;        OvR的训练阶段，将模型保存到self.models中        :param train_datas: 训练集数据，类型为ndarray        :param train_labels: 训练集标签，类型为ndarray，shape为(-1,)        :return: None        &#39;&#39;&#39;        self.classes &#x3D; np.unique(train_labels)  # 获取所有类别标签        for cls in self.classes:            # 将当前类别作为正类，其他类别作为负类            y_binary &#x3D; (train_labels &#x3D;&#x3D; cls).astype(int)            model &#x3D; tiny_logistic_regression()            model.fit(train_datas, y_binary)  # 使用二分类器训练模型            self.models.append(model)  # 将训练好的模型加入模型列表            self.real_label.append(cls)  # 保存当前类别的标签    def predict(self, test_datas):        &#39;&#39;&#39;        OvR的预测阶段        :param test_datas: 测试集数据，类型为ndarray        :return: 预测结果，类型为ndarray        &#39;&#39;&#39;        # 存储每个样本对每个类别的概率        all_probs &#x3D; np.zeros((len(test_datas), len(self.classes)))        for i, model in enumerate(self.models):            # 获取每个模型对每个测试样本属于该类别的概率            probs &#x3D; model.predict_proba(test_datas)            all_probs[:, i] &#x3D; probs  # 存储该类别的概率        # 每个样本选择概率最大的类别        predicted_class_indices &#x3D; np.argmax(all_probs, axis&#x3D;1)        return self.real_label[predicted_class_indices]  # 返回每个样本的最终预测类别<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>np.log2,Counter,len,np.unique</p><p>for label,count in labelcount.items():</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npfrom collections import Counterdef calcInfoGain(feature, label, index):    &#39;&#39;&#39;    计算信息增益    :param feature: 测试用例中的特征矩阵，类型为ndarray    :param label: 测试用例中的标签，类型为ndarray    :param index: 特征列的索引，指示使用第几个特征来计算信息增益。    :return: 信息增益，类型float    &#39;&#39;&#39;    # 计算原始熵    all_count &#x3D; len(label)    # 获取标签的频率    label_count &#x3D; Counter(label)    # 计算标签的熵    all_entropy &#x3D; 0    for label_value, count in label_count.items():        p &#x3D; count &#x2F; all_count        all_entropy -&#x3D; p * np.log2(p)    # 计算按特征划分后的熵    feature_values &#x3D; np.unique(feature[:, index])  # 获取该特征的所有可能值# feature[:, index] 表示选择 feature 矩阵的所有行（: 表示所有行），但是只选择第 index 列（即该列所有样本的特征值）。    weighted_entropy &#x3D; 0    for value in feature_values:        # 根据特征值划分数据        subset_label &#x3D; label[feature[:, index] &#x3D;&#x3D; value]        subset_count &#x3D; len(subset_label)        # 计算子集的熵        subset_entropy &#x3D; 0        subset_label_count &#x3D; Counter(subset_label)        for subset_label_value, count in subset_label_count.items():            p &#x3D; count &#x2F; subset_count            subset_entropy -&#x3D; p * np.log2(p)        # 加权平均子集的熵        weighted_entropy +&#x3D; (subset_count &#x2F; all_count) * subset_entropy    # 信息增益 &#x3D; 总熵 - 加权熵    info_gain &#x3D; all_entropy - weighted_entropy    return info_gain return info_gain<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="信息增益率"><a href="#信息增益率" class="headerlink" title="信息增益率"></a>信息增益率</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">def calcInfoGainRatio(feature, label, index):    #********* Begin *********#    all_count&#x3D;len(label)    #D    needE&#x3D;0    all_features &#x3D; np.unique(feature[:, index])  # 获取该特征列的所有唯一值    for f in all_features:        count&#x3D;0        for j in range(len(label)):            if feature[j][index]&#x3D;&#x3D;f:                count+&#x3D;1        #D1        needE-&#x3D;(count&#x2F;all_count)*np.log2(count&#x2F;all_count)    gain&#x3D;calcInfoGain(feature,label,index)    return gain&#x2F;needE    #********* End *********#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Gini系数"><a href="#Gini系数" class="headerlink" title="Gini系数"></a>Gini系数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">def calcGini(feature, label, index):    &#39;&#39;&#39;    &#39;&#39;&#39;    #********* Begin *********#    #先计算特征个数，在用特征里面的小个数计算    allcount&#x3D;len(label)    feats&#x3D;np.unique(feature[:,index])    Gini&#x3D;0    for val in feats:        sub_count&#x3D;0        sublabels&#x3D;[]        subG&#x3D;1        for j in range(allcount):            if feature[j][index]&#x3D;&#x3D;val:                sub_count+&#x3D;1                sublabels.append(label[j])        label_count&#x3D;Counter(sublabels)        for la,co in label_count.items():            subG-&#x3D;(co&#x2F;sub_count)**2        Gini+&#x3D;subG*(sub_count&#x2F;allcount)    return Gini    #********* End *********#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>鸢尾花识别</p><p>pd.read_csv,to_csv,DataFrame,</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npfrom sklearn.tree import DecisionTreeClassifierimport pandas as pd#********* Begin *********#model&#x3D;DecisionTreeClassifier()train_label &#x3D; pd.read_csv(&#39;.&#x2F;step7&#x2F;train_label.csv&#39;).valuestrain_data &#x3D; pd.read_csv(&#39;.&#x2F;step7&#x2F;train_data.csv&#39;).valuestest_data &#x3D; pd.read_csv(&#39;.&#x2F;step7&#x2F;test_data.csv&#39;).valuesmodel.fit(train_data,train_label)result&#x3D;model.predict(test_data)resultd&#x3D;pd.DataFrame(result,columns&#x3D;[&#39;prediction&#39;])resultd.to_csv(&#39;.&#x2F;step7&#x2F;predict.csv&#39;,index&#x3D;False)#********* End *********#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="贝叶斯分类器"><a href="#贝叶斯分类器" class="headerlink" title="贝叶斯分类器"></a>贝叶斯分类器</h2><p>全概率公式</p><p><img src="/images/ml/9bbceb6a-0ae0-449f-9af5-cb33b8ef2ffd.png" title="" alt="9bbceb6a-0ae0-449f-9af5-cb33b8ef2ffd" style="zoom:100%;"></p><p>贝叶斯公式（条件概率乘法定理/全概率公式）</p><p><img src="/images/ml/cb2d0212-cba3-430c-8d92-d2eb0ca1ffe9.png" title="" alt="cb2d0212-cba3-430c-8d92-d2eb0ca1ffe9" style="zoom:100%;"><img src="/images/ml/b772390c-44da-4753-ba81-a7004d95f0a1.png" title="" alt="b772390c-44da-4753-ba81-a7004d95f0a1" style="zoom:100%;"></p><h3 id="朴素贝叶斯分类"><a href="#朴素贝叶斯分类" class="headerlink" title="朴素贝叶斯分类"></a>朴素贝叶斯分类</h3><p><code>label_val, label_count = np.unique(label, return_counts=True)</code></p><p><code>self.label_prob = &#123;label_val[i]: label_count[i] / all_count for i in range(len(label_val))&#125;</code></p><p><code>feat_lines = feature[label == val]</code></p><p><code>for a, b in zip(feat_val, feat_count):</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npclass NaiveBayesClassifier(object):    def __init__(self):        self.label_prob &#x3D; &#123;&#125;  # 每种类别在数据中出现的概率        self.condition_prob &#x3D; &#123;&#125;  # 条件概率 P(x|y)    def fit(self, feature, label):        &#39;&#39;&#39;        对模型进行训练，计算各种概率        :param feature: 训练数据集的特征，ndarray        :param label: 训练数据集的标签，ndarray        :return: 无返回        &#39;&#39;&#39;        # 计算每个标签的概率 P(y)        label_val, label_count &#x3D; np.unique(label, return_counts&#x3D;True)        all_count &#x3D; len(label)        self.label_prob &#x3D; &#123;label_val[i]: label_count[i] &#x2F; all_count for i in range(len(label_val))&#125;        # 计算每个标签下特征的条件概率 P(x|y)        feat_num &#x3D; feature.shape[1]  # 特征数量        self.condition_prob &#x3D; &#123;&#125;        for val in label_val:            feat_lines &#x3D; feature[label &#x3D;&#x3D; val]  # 当前标签下的特征数据            feature_prob &#x3D; &#123;&#125;            for i in range(feat_num):                feat_val, feat_count &#x3D; np.unique(feat_lines[:, i], return_counts&#x3D;True)  # 当前特征列的取值及其频数                feature_prob[i] &#x3D; &#123;&#125;                sub_count &#x3D; len(feat_lines)                for a, b in zip(feat_val, feat_count):                    feature_prob[i][a] &#x3D; b &#x2F; sub_count  # 计算条件概率            self.condition_prob[val] &#x3D; feature_prob  # 保存当前标签的条件概率    def predict(self, feature):        &#39;&#39;&#39;        对数据进行预测，返回预测结果        :param feature: 测试数据集所有特征组成的ndarray        :return: 预测的标签        &#39;&#39;&#39;        predictions &#x3D; []        for sample in feature:            label_post &#x3D; &#123;&#125;            # 计算每个标签的后验概率 P(y|x)            for label_val, prob in self.label_prob.items():                probability &#x3D; np.log2(prob)  # P(y)                # 计算当前标签下的条件概率 P(x|y)                for idx, val in enumerate(sample):                    probability +&#x3D; np.log2(self.condition_prob[label_val][idx].get(val, 1e-10))                label_post[label_val] &#x3D; probability            # 选择后验概率最大的标签作为预测结果            predict &#x3D; max(label_post, key&#x3D;label_post.get)            predictions.append(predict)        return np.array(predictions)  # 返回 numpy 数组<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Laplace平滑"><a href="#Laplace平滑" class="headerlink" title="Laplace平滑"></a>Laplace平滑</h3><p>假设N表示训练数据集总共有多少种类别，Ni表示训练数据集中第i列总共有多少种取值。则训练过程中在算类别的概率时分子加1，分母加N，算条件概率时分子加1，分母加Ni</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npclass NaiveBayesClassifier(object):    def __init__(self):        &#39;&#39;&#39;        &#39;&#39;&#39;        self.label_prob &#x3D; &#123;&#125;  # 存储每个类别的先验概率        self.condition_prob &#x3D; &#123;&#125;  # 存储每个类别下每个特征的条件概率    def fit(self, feature, label):        &#39;&#39;&#39;        对模型进行训练，计算每种类别的先验概率和条件概率        :param feature: 训练数据集所有特征组成的 ndarray        :param label: 训练数据集所有标签组成的 ndarray        :return: 无返回值，通过更新 self.label_prob 和 self.condition_prob 来保存训练结果        &#39;&#39;&#39;        #********* Begin *********#        row_num &#x3D; len(feature)  # 样本的数量        col_num &#x3D; len(feature[0])  # 特征的数量        unique_label_count &#x3D; len(set(label))  # 唯一类别的数量        # 计算每个类别的出现次数        for c in label:            if c in self.label_prob:                self.label_prob[c] +&#x3D; 1            else:                self.label_prob[c] &#x3D; 1        # 计算每个类别的先验概率，并进行拉普拉斯平滑        for key in self.label_prob.keys():            self.label_prob[key] +&#x3D; 1  # 拉普拉斯平滑            self.label_prob[key] &#x2F;&#x3D; (unique_label_count + row_num)  # 计算先验概率            # 构建条件概率字典，初始化每个类别下每个特征值的概率            self.condition_prob[key] &#x3D; &#123;&#125;            for i in range(col_num):                self.condition_prob[key][i] &#x3D; &#123;&#125;                for k in np.unique(feature[:, i], axis&#x3D;0):  # 遍历每个特征的不同取值                    self.condition_prob[key][i][k] &#x3D; 1  # 初始概率设为 1（拉普拉斯平滑）        # 统计训练集中每个类别下特征值的频次        for i in range(len(feature)):            for j in range(len(feature[i])):                # 更新每个特征值的出现频次                self.condition_prob[label[i]][j][feature[i][j]] +&#x3D; 1        # 计算每个类别下每个特征值的条件概率，进行拉普拉斯平滑        for label_key in self.condition_prob.keys():            for k in self.condition_prob[label_key].keys():                total &#x3D; len(self.condition_prob[label_key][k].keys())  # 特征的种类数                for v in self.condition_prob[label_key][k].values():                    total +&#x3D; v  # 总的计数值（包括平滑项）                for kk in self.condition_prob[label_key][k].keys():                    # 计算条件概率                    self.condition_prob[label_key][k][kk] &#x2F;&#x3D; total        #********* End *********#    def predict(self, feature):        &#39;&#39;&#39;        对数据进行预测，返回预测结果        :param feature: 测试数据集所有特征组成的 ndarray        :return: 预测结果的数组，包含每个测试样本的预测类别        &#39;&#39;&#39;        result &#x3D; []  # 存储预测结果        # 对每条测试数据进行预测        for i, f in enumerate(feature):            prob &#x3D; np.zeros(len(self.label_prob.keys()))  # 存储每个类别的概率，初始化为零            ii &#x3D; 0  # 用于索引类别            for label, label_prob in self.label_prob.items():                prob[ii] &#x3D; label_prob  # 初始化为先验概率                for j in range(len(f)):  # 遍历当前样本的所有特征                    # 计算该特征值在该类别下的条件概率                    prob[ii] *&#x3D; self.condition_prob[label][j][f[j]]                ii +&#x3D; 1  # 处理下一个类别            # 选择具有最大概率的类别作为预测结果            result.append(list(self.label_prob.keys())[np.argmax(prob)])        return np.array(result)  # 返回预测结果<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="新闻文本分类"><a href="#新闻文本分类" class="headerlink" title="新闻文本分类"></a>新闻文本分类</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">from sklearn.feature_extraction.text import CountVectorizerfrom sklearn.naive_bayes import MultinomialNBfrom sklearn.feature_extraction.text import TfidfTransformerimport numpy as npdef news_predict(train_sample, train_label, test_sample):    &#39;&#39;&#39;    训练模型并进行预测，返回预测结果    :param train_sample: 原始训练集中的新闻文本，类型为 ndarray    :param train_label: 训练集中新闻文本对应的主题标签，类型为 ndarray    :param test_sample: 原始测试集中的新闻文本，类型为 ndarray    :return: 预测结果，类型为 ndarray    &#39;&#39;&#39;    #********* Begin *********#    # 实例化CountVectorizer，转换文本为词频矩阵    vec &#x3D; CountVectorizer()    X_train &#x3D; vec.fit_transform(train_sample)  # 先fit拟合训练集，再对训练集进行词频向量化    X_test &#x3D; vec.transform(test_sample)  # 对测试集进行词频向量化    # 实例化TfidfTransformer，转换为TF-IDF矩阵    tfidf &#x3D; TfidfTransformer()    X_train &#x3D; tfidf.fit_transform(X_train)  # 将训练集词频矩阵转换为TF-IDF矩阵    X_test &#x3D; tfidf.transform(X_test)  # 将测试集词频矩阵转换为TF-IDF矩阵    # 实例化MultinomialNB模型，设置平滑参数alpha&#x3D;0.8    model &#x3D; MultinomialNB(alpha&#x3D;0.8)    model.fit(X_train, train_label)  # 使用训练集训练模型    # 预测测试集的标签    result &#x3D; model.predict(X_test)    # 返回预测结果    return np.array(result)    #********* End *********#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><h3 id="线性SVM"><a href="#线性SVM" class="headerlink" title="线性SVM"></a>线性SVM</h3><p><code>计算训练数据的均值和标准差    mean = np.mean(train_data, axis=0)    std = np.std(train_data,axis=0)</code></p><p><code>train_data = (train_data - mean) / std</code></p><p><code>model = LinearSVC(C=10, max_iter=10000)  # 增大C的值并增加最大迭代次数</code></p><p><strong><code>C</code>（正则化参数）</strong>: 控制模型的复杂度，较大的 <code>C</code> 值会让模型更加“严格”地拟合训练数据，但可能导致过拟合。较小的 <code>C</code> 值则允许更多的错误，从而使得模型更为平滑，防止过拟合</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">#encoding&#x3D;utf8from sklearn.svm import LinearSVCimport pandas as pdimport numpy as npdef linearsvc_predict(train_data,train_label,test_data):    &#39;&#39;&#39;    input:train_data(ndarray):训练数据          train_label(ndarray):训练标签    output:predict(ndarray):测试集预测标签    &#39;&#39;&#39;    # ********* Begin *********#    # 1. 数据标准化（手动进行标准化：均值0，方差1）    # 计算训练数据的均值和标准差    mean &#x3D; np.mean(train_data, axis&#x3D;0)    std &#x3D; np.std(train_data, axis&#x3D;0)    # 对训练数据和测试数据进行标准化    train_data &#x3D; (train_data - mean) &#x2F; std    test_data &#x3D; (test_data - mean) &#x2F; std    # 2. 创建并训练模型    model &#x3D; LinearSVC(C&#x3D;10, max_iter&#x3D;10000)  # 增大C的值并增加最大迭代次数    model.fit(train_data, train_label)    # 3. 预测测试数据    predict &#x3D; model.predict(test_data)    # ********* End *********#     return predict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="非线性SVM"><a href="#非线性SVM" class="headerlink" title="非线性SVM"></a>非线性SVM</h3><p><img title="" src="/images/ml/526644dc-2c68-464b-9590-50f1c27f5fcc.png" alt="526644dc-2c68-464b-9590-50f1c27f5fcc" style="zoom:100%;"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">#encoding&#x3D;utf8from sklearn.svm import SVCdef svc_predict(train_data,train_label,test_data,kernel):    &#39;&#39;&#39;    input:train_data(ndarray):训练数据          train_label(ndarray):训练标签          kernel(str):使用核函数类型:              &#39;linear&#39;:线性核函数              &#39;poly&#39;:多项式核函数              &#39;rbf&#39;:径像核函数&#x2F;高斯核    output:predict(ndarray):测试集预测标签    &#39;&#39;&#39;    #********* Begin *********#     model&#x3D;SVC(kernel&#x3D;kernel)    model.fit(train_data,train_label)    predict&#x3D;model.predict(test_data)    #********* End *********#     return predict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><h3 id="boosting"><a href="#boosting" class="headerlink" title="boosting"></a>boosting</h3><p>提升方法基于这样一种思想：对于一个复杂任务来说，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断好。</p><p>历史上，<strong>Kearns 和 Valiant 首先提出了强可学习和弱可学习的概念</strong>指出：在 PAC 学习的框架中，一个概念，</p><p>如果存在一个多项式的学习算法能够学习它，并且正确率很高，那么就称这个概念是强可学习的；</p><p>一个概念，如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，那么就称这个概念是弱可学习的。</p><p>非常有趣的是 Schapire 后来证明强可学习与弱可学习是等价的，也就是说，在 PAC 学习的框架下，一个概念是强可学习的充分必要条件是这个概念是弱可学习的。</p><p>这样一来，问题便成为，在<strong>学习中，如果已经发现了弱学习算法，那么能否将它提升为强学习算法。大家知道，发现弱学习算法通常要比发现强学习算法容易得多</strong>。那么如何具体实施提升，便成为开发提升方法时所要解决的问题。</p><p>与 bagging 不同， boosting 采用的是一个串行训练的方法。首先，它训练出一个弱分类器，然后在此基础上，再训练出一个稍好点的弱分类器，以此类推，不断的训练出多个弱分类器，最终再将这些分类器相结合，这就是 boosting 的基本思想</p><p>可以看出，<strong>子模型之间存在强依赖关系，必须串行生成。</strong> boosting 是利用不同模型的相加，构成一个更好的模型，求取模型一般都采用序列化方法，后面的模型依据前面的模型</p><p>Adaboost算法原理<br>对提升方法来说，有两个问题需要回答：<strong>一是在每一轮如何改变训练数据的权值或概率分布；二是如何将弱分类器组合成一个强分类器</strong></p><p>关于第 1 个问题，<strong>AdaBoost的做法是，提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值</strong></p><p>这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注。于是，分类问题被一系列的弱分类器“分而治之”。</p><p>至于第 2 个问题，即弱分类器的组合，<strong>AdaBoost采取加权多数表决的方法，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。</strong></p><h3 id="bagging"><a href="#bagging" class="headerlink" title="bagging"></a>bagging</h3><p>与 Boosting 这种串行集成学习算法不同， Bagging 是并行式集成学习方法。</p><p>如果使用 Bagging 解决分类问题，就是将多个分类器的结果整合起来进行投票，选取票数最高的结果作为最终结果。如果使用 Bagging 解决回归问题，就将多个回归器的结果加起来然后求平均，将平均值作为最终结果。</p><p>n足够大时，考虑用正态分布来拟合二项分布</p><p><img src="/images/ml/02a997d7-32a2-4a6f-a846-782d1ecd53a2.png" title="" alt="02a997d7-32a2-4a6f-a846-782d1ecd53a2" style="zoom:100%;"></p><p> Bagging 在训练时的特点就是随机有放回采样和并行。</p><p><strong>随机有放回采样:</strong> 假设训练数据集有 m 条样本数据，每次从这 m 条数据中随机取一条数据放入采样集，然后将其返回，让下一次采样有机会仍然能被采样。<strong>然后重复 m 次，就能得到拥有 m 条数据的采样集</strong>，该采样集作为 Bagging 的众多分类器中的一个作为训练数据集。假设有 T 个分类器（随便什么分类器），那么就重复 T 此随机有放回采样，<strong>构建出 T 个采样集分别作为 T 个分类器的训练数据集</strong>。</p><p><strong>并行：</strong> 假设有 10 个分类器，在 Boosting 中，1 号分类器训练完成之后才能开始 2 号分类器的训练，而<strong>在 Bagging 中，分类器可以同时进行训练，当所有分类器训练完成之后，整个 Bagging 的训练过程就结束了</strong>。</p><p><code>samples = np.random.choice(n, n, replace=True)</code>从0到n-1选取n个有放回采样，</p><p><code>prediction=[model.predict(feature) for model in self.models]</code></p><p><code>votes=[prediction[j][i] for j in range(self.n_model)]</code></p><p><code>max(set(votes),key=votes.count)</code>以votes.count为排序依据，对set(votes)进行排序并取最大值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npfrom sklearn.tree import DecisionTreeClassifierclass BaggingClassifier():    def __init__(self, n_model&#x3D;10):        &#39;&#39;&#39;        初始化函数，设置模型参数        :param n_model: 分类器数量，默认为10个决策树        &#39;&#39;&#39;        # 分类器的数量，默认为10        self.n_model &#x3D; n_model        # 用于保存训练后的模型，存储每个决策树        self.models &#x3D; []    def fit(self, feature, label):        # 获取样本数量        n &#x3D; len(label)        # 训练 n_model 个决策树        for i in range(self.n_model):            # 有放回地随机采样样本索引            samples &#x3D; np.random.choice(n, n, replace&#x3D;True)            # 生成样本的特征和标签子集            sample_f &#x3D; feature[samples]            sample_l &#x3D; label[samples]            # 使用决策树模型进行训练，最大深度为3            model &#x3D; DecisionTreeClassifier(max_depth&#x3D;3)            model.fit(sample_f, sample_l)            # 将训练好的模型添加到模型列表中            self.models.append(model)    def predict(self, feature):        &#39;&#39;&#39;        对测试集数据进行预测，采用投票机制        :param feature: 测试集数据，类型为ndarray，形状为 (n_samples, n_features)        :return: 预测结果，类型为ndarray，形状为 (n_samples,)        &#39;&#39;&#39;        # 存储每个模型的预测结果        prediction&#x3D;[]        for model in self.models:            prediction.append(model.predict(feature))        # prediction&#x3D;[model.predict(feature) for model in self.models]        final_prediction&#x3D;[]        for i in range(len(feature)):            votes&#x3D;[prediction[j][i] for j in range(self.n_model)]            l&#x3D;max(set(votes),key&#x3D;votes.count)            final_prediction.append(l)        return np.array(final_prediction)        #************* End **************#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h4><p>随机森林是 Bagging 的一种扩展变体，随机森林的训练过程相对与 Bagging 的训练过程的改变有：</p><p><strong>基学习器：</strong> Bagging 的基学习器可以是任意学习器，而<strong>随机森林则是以决策树作为基学习器</strong>。<br><strong>随机属性选择：</strong> 假设原始训练数据集有 10 个特征，从这 10 个特征中<strong>随机选取 k 个特征构成训练数据子集</strong>，然后将这个子集作为训练集扔给决策树去训练。其中 k 的取值一般为 <strong>log2(特征数量)</strong> 。<br>这样的改动通常会使得随机森林具有更加强的泛化性，因为每一棵决策树的训练数据集是随机的，而且训练数据集中的特征也是随机抽取的。如果每一棵决策树模型的差异比较大，那么就很容易<strong>能够解决决策树容易过拟合的问题</strong>。</p><p>随机森林的预测流程与 Bagging 的预测流程基本一致，<strong>如果是回归，就将结果基学习器的预测结果全部加起来算平均</strong>；如果是<strong>分类，就投票，票数最多的结果作为最终结果。但需要注意的是，在预测时所用到的特征必须与训练模型时所用到的特征保持一致</strong>。</p><p><code>s = np.random.choice(l, self.feature_nums, replace=False)</code>随机选择不重复的特征</p><p><code>sub_sample = sample_f[:, s]</code>在s列的所有行数据</p><p><code>votes.append(model.predict([sub_f])[0])  # 获取预测结果</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npfrom collections import Counterfrom sklearn.tree import DecisionTreeClassifierclass RandomForestClassifier():    def __init__(self, n_model&#x3D;10):        &#39;&#39;&#39;        初始化函数        &#39;&#39;&#39;        self.n_model &#x3D; n_model        self.feature_nums &#x3D; None        self.models &#x3D; []        self.col_indexs &#x3D; []    def fit(self, feature, label):        &#39;&#39;&#39;        训练模型        :param feature: 训练集数据，类型为ndarray        :param label: 训练集标签，类型为ndarray        :return: None        &#39;&#39;&#39;        n, l &#x3D; feature.shape        if self.feature_nums is None:            self.feature_nums &#x3D; int(np.log2(l))  # 取整以确保feature_nums是整数        for i in range(self.n_model):            # 有放回采样            sample &#x3D; np.random.choice(n, n, replace&#x3D;True)            sample_f &#x3D; feature[sample]            sample_l &#x3D; label[sample]            # 随机选择特征列            s &#x3D; np.random.choice(l, self.feature_nums, replace&#x3D;False)            self.col_indexs.append(s)            sub_sample &#x3D; sample_f[:, s]            model &#x3D; DecisionTreeClassifier(max_depth&#x3D;3)            model.fit(sub_sample, sample_l)            self.models.append(model)    def predict(self, feature):        &#39;&#39;&#39;        :param feature: 测试集数据，类型为ndarray        :return: 预测结果，类型为ndarray        &#39;&#39;&#39;        predictions &#x3D; []           for j in range(feature.shape[0]):  # 遍历每个测试样本            votes &#x3D; []            for i, model in enumerate(self.models):  # 遍历每棵决策树                col &#x3D; self.col_indexs[i]  # 获取模型训练时使用的特征列                sub_f &#x3D; feature[j, col]  # 获取测试样本的特征                votes.append(model.predict([sub_f])[0])  # 获取预测结果            # 投票机制，选择出现次数最多的结果            predictions.append(max(set(votes), key&#x3D;votes.count))        return np.array(predictions)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><h3 id="层次聚类距离计算："><a href="#层次聚类距离计算：" class="headerlink" title="层次聚类距离计算："></a>层次聚类距离计算：</h3><p><code>dist = np.linalg.norm(i - j) #直接计算i，j的欧氏距离</code></p><p><code>return np.min(dist) #np.argmin(dist)返回索引</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npdef calc_min_dist(cluster1, cluster2):    &#39;&#39;&#39;    计算簇间最小距离    :param cluster1:簇1中的样本数据，类型为ndarray    :param cluster2:簇2中的样本数据，类型为ndarray    :return:簇1与簇2之间的最小距离    &#39;&#39;&#39;    min_dist &#x3D; float(&#39;inf&#39;)  # 初始化最小距离为正无穷大    for i in cluster1:        for j in cluster2:            dist &#x3D; np.linalg.norm(i - j)  # 计算欧几里得距离            if dist &lt; min_dist:                min_dist &#x3D; dist    return min_distdef calc_max_dist(cluster1, cluster2):    &#39;&#39;&#39;    计算簇间最大距离    :param cluster1:簇1中的样本数据，类型为ndarray    :param cluster2:簇2中的样本数据，类型为ndarray    :return:簇1与簇2之间的最大距离    &#39;&#39;&#39;    max_dist &#x3D; -float(&#39;inf&#39;)  # 初始化最大距离为负无穷大    for i in cluster1:        for j in cluster2:            dist &#x3D; np.linalg.norm(i - j)  # 计算欧几里得距离            if dist &gt; max_dist:                max_dist &#x3D; dist    return max_distdef calc_avg_dist(cluster1, cluster2):    &#39;&#39;&#39;    计算簇间平均距离    :param cluster1:簇1中的样本数据，类型为ndarray    :param cluster2:簇2中的样本数据，类型为ndarray    :return:簇1与簇2之间的平均距离    &#39;&#39;&#39;    total_dist &#x3D; 0    count1 &#x3D; 0    count2 &#x3D; 0    for i in cluster1:        for j in cluster2:            total_dist +&#x3D; np.linalg.norm(i - j)  # 计算欧几里得距离    return total_dist &#x2F; (len(cluster1)*len(cluster2))  # 返回平均距离<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h3><h4 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h4><p>曼哈顿距离即每个维度距离求和，欧氏距离即空间直线距离</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">def distance(x,y,p&#x3D;2):    &#39;&#39;&#39;    input:x(ndarray):第一个样本的坐标          y(ndarray):第二个样本的坐标          p(int):等于1时为曼哈顿距离，等于2时为欧氏距离    output:distance(float):x到y的距离          &#39;&#39;&#39;     if(p&#x3D;&#x3D;1):          return sum(np.abs(x-y))    else:          return np.sqrt(sum((x-y)**2))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="质心计算"><a href="#质心计算" class="headerlink" title="质心计算"></a>质心计算</h4><p><code>dist=np.power(np.sum(np.abs(x-y)**p),1/p)</code></p><p><code>Cmass=np.mean(data,axis=0);</code></p><p><code>dist_list=sorted(dist)</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">#encoding&#x3D;utf8import numpy as np#计算样本间距离def distance(x, y, p&#x3D;2):    #********* Begin *********#    # 计算x和y之间差的绝对值的p次方      dist&#x3D;np.power(np.sum(np.abs(x-y)**p),1&#x2F;p)    # 计算最终的距离值     #********* End *********#    return dist#计算质心def cal_Cmass(data):    &#39;&#39;&#39;    input:data(ndarray):数据样本    output:mass(ndarray):数据样本质心    &#39;&#39;&#39;    #********* Begin *********#    # 计算数据样本的质心（即每个维度的平均值）      Cmass&#x3D;np.mean(data,axis&#x3D;0)    #********* End *********#    return Cmass#计算每个样本到质心的距离，并按照从小到大的顺序排列def sorted_list(data,Cmass):    &#39;&#39;&#39;    input:data(ndarray):数据样本          Cmass(ndarray):数据样本质心    output:dis_list(list):排好序的样本到质心距离    &#39;&#39;&#39;    #********* Begin *********#    # 初始化一个空列表，用于存储距离      dist&#x3D;[]    # 遍历数据样本中的每个样本     for sample in data:        dis&#x3D;distance(Cmass,sample)        dist.append(dis)    # 计算当前样本到质心的距离，并添加到列表中      # 对距离列表进行排序      dist_list&#x3D;sorted(dist)    return dist_list    #********* End *********#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="k-means-1"><a href="#k-means-1" class="headerlink" title="k-means"></a>k-means</h4><p><code>model = KMeans(n_clusters=k, init=&#39;k-means++&#39;, max_iter=500, tol=1e-4, random_state=42)</code></p><p>K-means 是一种 <strong>无监督学习</strong> 方法，它确实没有使用真实标签（ground truth labels），但仍然会为每个样本分配一个 <strong>聚类标签（cluster index）</strong>，这个标签是算法自动生成的，表示样本属于哪个簇（cluster）</p><ol><li><p><strong>初始化聚类中心</strong></p><ul><li>随机选择 <code>k</code> 个样本作为初始聚类中心 <code>centroids</code>。</li></ul></li><li><p><strong>迭代优化</strong>（直到收敛或达到最大迭代次数）：</p><ul><li><p><strong>步骤 1：分配样本到最近的簇</strong></p><ul><li><p>对每个样本 <code>x ∈ X</code>，计算它与所有 <code>centroids</code> 的距离，并分配到最近的簇。</p></li><li><p>代码实现：<code>create_clusters(centroids, X)</code>。</p></li></ul></li><li><p><strong>步骤 2：更新聚类中心</strong></p><ul><li><p>对每个簇，计算其所有样本的均值，作为新的聚类中心。</p></li><li><p>代码实现：<code>update_centroids(clusters)</code>。</p></li></ul></li><li><p><strong>步骤 3：检查收敛</strong></p><ul><li><p>如果新旧聚类中心的距离变化 <code>&lt;= ε</code>（<code>varepsilon</code>），则停止迭代。</p></li><li><p>否则，继续迭代。</p></li></ul></li></ul></li><li><p><strong>返回聚类标签</strong></p><ul><li>最终，为每个样本分配其最近的聚类中心的索引，作为聚类标签 <code>labels</code>。</li></ul></li></ol><p><code>labels = np.zeros(X.shape[0], dtype=int)</code></p><p><code>return np.argmin(distance)</code></p><p><code>clusters=[[] for _ in range(self.k)]</code></p><p><code>new_centroids[i] = np.mean(clusters[i], axis=0)</code></p><p><code>centroid_shift = np.linalg.norm(new_centroids - centroids)</code></p><p><code>#NumPy 提供的一个线性代数函数，用来计算矩阵的“范数”，在这里是计算 向量的欧几里得距离</code></p><p>sample=np.random.choice(len(X),self.k,replace=False)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">#encoding&#x3D;utf8import numpy as np# 计算一个样本与数据集中所有样本的欧氏距离的平方def euclidean_distance(one_sample, X):    return np.sum((X - one_sample) ** 2, axis&#x3D;1)class Kmeans():    &quot;&quot;&quot;Kmeans聚类算法.    Parameters:    -----------    k: int        聚类的数目.    max_iterations: int        最大迭代次数.     varepsilon: float        判断是否收敛, 如果上一次的所有k个聚类中心与本次的所有k个聚类中心的差都小于varepsilon,         则说明算法已经收敛    &quot;&quot;&quot;    def __init__(self, k&#x3D;2, max_iterations&#x3D;500, varepsilon&#x3D;0.0001):        self.k &#x3D; k        self.max_iterations &#x3D; max_iterations        self.varepsilon &#x3D; varepsilon        np.random.seed(1)    #********* Begin *********#    # 从所有样本中随机选取self.k样本作为初始的聚类中心    def init_random_centroids(self, X):        sample&#x3D;np.random.choice(len(X),self.k,replace&#x3D;False)        return X[sample]    # 返回距离该样本最近的一个中心索引[0, self.k)    def _closest_centroid(self, sample, centroids):        distance&#x3D;euclidean_distance(sample,centroids)        return np.argmin(distance)    # 将所有样本进行归类，归类规则就是将该样本归类到与其最近的中心    def create_clusters(self, centroids, X):        clusters&#x3D;[[] for _ in range(self.k)]        for sample in X:            closest_idx&#x3D;self._closest_centroid(sample,centroids)            clusters[closest_idx].append(sample)        return clusters    # 对中心进行更新    def update_centroids(self, clusters, X):        new_centroids &#x3D; np.zeros((self.k, len(clusters[0][0])))        for i in range(self.k):            # 对每个簇内样本求均值            new_centroids[i] &#x3D; np.mean(clusters[i], axis&#x3D;0)        return new_centroids    # 对整个数据集X进行Kmeans聚类，返回其聚类的标签    def predict(self, X):        # 从所有样本中随机选取self.k样本作为初始的聚类中心        centroids&#x3D;self.init_random_centroids(X)        # 迭代，直到算法收敛(上一次的聚类中心和这一次的聚类中心几乎重合)或者达到最大迭代次数           for i in range(self.max_iterations):            clusters&#x3D;self.create_clusters(centroids,X)            new_centroids&#x3D;self.update_centroids(clusters,X)            centroid_shift &#x3D; np.linalg.norm(new_centroids - centroids)            if centroid_shift &lt;&#x3D; self.varepsilon:                break            # 更新聚类中心            centroids &#x3D; new_centroids            # 如果聚类中心几乎没有变化，说明算法已经收敛，退出迭代        labels &#x3D; np.zeros(X.shape[0], dtype&#x3D;int)        for i, sample in enumerate(X):            labels[i] &#x3D; self._closest_centroid(sample, centroids)        return labels<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h3><ul><li><p><strong>簇（Cluster）</strong> = <strong>高密度区域</strong>（数据点密集）。</p></li><li><p><strong>噪声（Noise）</strong> = <strong>低密度区域</strong>（数据点稀疏）。</p></li><li><p><strong><code>eps</code> (ε)</strong>：邻域半径，用于判断两个点是否“相邻”。</p></li><li><p><strong><code>min_samples</code></strong>：形成一个簇所需的最小样本数（核心点的邻域至少要有这么多点）。</p></li></ul><div class="table-container"><table><thead><tr><th>类型</th><th>定义</th><th>示例</th></tr></thead><tbody><tr><td><strong>核心点（Core Point）</strong></td><td>在 <code>eps</code> 邻域内至少有 <code>min_samples</code> 个点（包括自己）</td><td>若 <code>min_samples=5</code>，某点周围有 ≥5 个点（含自己），则它是核心点</td></tr><tr><td><strong>边界点（Border Point）</strong></td><td>在某个核心点的 <code>eps</code> 邻域内，但自身不满足核心点条件</td><td>周围点 &lt; <code>min_samples</code>，但属于某个核心点的邻域</td></tr><tr><td><strong>噪声点（Noise Point）</strong></td><td>既不是核心点，也不是边界点</td><td>离群点，不属于任何簇</td></tr></tbody></table></div><ul><li><p>如果点 <code>q</code> 在点 <code>p</code> 的 <code>eps</code> 邻域内，且 <code>p</code> 是核心点，则称 <code>q</code> 从 <code>p</code> <strong>密度直达</strong>。</p></li><li><p>如果存在一个核心点序列 <code>p1, p2, ..., pn</code>，使得 <code>pi+1</code> 从 <code>pi</code> 密度直达，则称 <code>p1</code> 和 <code>pn</code> <strong>密度相连</strong>。</p></li></ul><ol><li><p><strong>随机选择一个未访问的点 <code>p</code></strong>。</p></li><li><p><strong>检查 <code>p</code> 的 <code>eps</code> 邻域</strong>：</p><ul><li><p>如果 <code>p</code> 是核心点（邻域内点数 ≥ <code>min_samples</code>）：</p><ul><li><p>创建一个新簇。</p></li><li><p>递归地找出所有从 <code>p</code> <strong>密度可达</strong>的点，加入该簇。</p></li></ul></li><li><p>如果 <code>p</code> 是噪声点，标记为噪声。</p></li></ul></li><li><p><strong>重复上述过程，直到所有点被访问</strong>。</p></li></ol><ul><li><p><strong>不需要预先指定簇数量（k）</strong>（比 K-means 更灵活）。</p></li><li><p><strong>能发现任意形状的簇</strong>（K-means 只能发现球形簇）。</p></li><li><p><strong>能识别噪声点</strong>（适合处理离群值）。</p></li><li><p><strong>对参数 <code>eps</code> 和 <code>min_samples</code> 敏感</strong>，需要调参。</p><p>| 特性           | DBSCAN                | K-means |<br>| —————— | ——————————- | ———- |<br>| <strong>簇形状</strong>      | 任意形状                  | 球形      |<br>| <strong>噪声处理</strong>     | 能识别噪声                 | 不能      |<br>| <strong>需指定簇数（k）</strong> | 不需要                   | 需要      |<br>| <strong>参数依赖</strong>     | <code>eps</code> 和 <code>min_samples</code> | <code>k</code>     |<br>| <strong>适合场景</strong>     | 非凸簇、噪声多               | 凸簇、数据均匀 |</p><p><code>neighbors += new_neighbors  # 将新邻域的点加入待处理列表</code><br><code>fit_predict()</code> 是一个结合了训练和预测的简化语法，通常在 <strong>聚类</strong> 或 <strong>无监督学习</strong> 中使用，它的作用是：首先对数据进行训练（拟合模型），然后直接对数据进行预测，返回聚类标签或者分类标签。这种方法可以简化代码并提高效率，尤其是在进行无监督学习时</p></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">#encoding&#x3D;utf8 import numpy as npimport random# 寻找eps邻域内的点def findNeighbor(j, X, eps):    &quot;&quot;&quot;    计算样本X[j]的eps邻域，返回所有在该邻域内的点的索引    input:        j (int): 当前点的索引        X (ndarray): 样本数据        eps (float): 邻域半径    output:        N (list): 邻域内的点的索引    &quot;&quot;&quot;    N &#x3D; []  # 存放邻域内的点    for p in range(X.shape[0]):  # 遍历所有点        # 计算欧式距离        temp &#x3D; np.sqrt(np.sum(np.square(X[j] - X[p])))          if temp &lt;&#x3D; eps:  # 如果点p在eps半径范围内            N.append(p)  # 将该点加入邻域列表    return Ndef expandCluster(X, labels, point, neighbors, cluster_id, eps, min_Pts):    &quot;&quot;&quot;    扩展簇，将密度可达的点加入到当前簇    input:        X (ndarray): 样本数据        labels (list): 当前的聚类标签        point (int): 当前扩展的核心点的索引        neighbors (list): 核心点的邻域        cluster_id (int): 当前簇的ID        eps (float): 邻域半径        min_Pts (int): 最小邻域内点数    &quot;&quot;&quot;    labels[point] &#x3D; cluster_id  # 将当前点标记为当前簇的成员    i &#x3D; 0    while i &lt; len(neighbors):  # 遍历邻域中的每一个点        neighbor_point &#x3D; neighbors[i]        # 如果邻居点是噪声（未分类），将其标记为当前簇的一部分        if labels[neighbor_point] &#x3D;&#x3D; -1:              labels[neighbor_point] &#x3D; cluster_id        # 如果邻居点没有被标记，且它是一个核心点，则继续扩展簇        elif labels[neighbor_point] &#x3D;&#x3D; 0:            labels[neighbor_point] &#x3D; cluster_id            new_neighbors &#x3D; findNeighbor(neighbor_point, X, eps)            if len(new_neighbors) &gt;&#x3D; min_Pts:  # 如果该点是核心点                neighbors +&#x3D; new_neighbors  # 将新邻域的点加入待处理列表        i +&#x3D; 1# DBSCAN算法def dbscan(X, eps, min_Pts):    &#39;&#39;&#39;    输入:        X (ndarray): 样本数据        eps (float): eps邻域半径        min_Pts (int): eps邻域内最少点个数    输出:        labels (list): 聚类结果，每个点的标签（-1表示噪声，其他数字表示簇编号）    &#39;&#39;&#39;    # 样本数量    nums &#x3D; len(X)    labels &#x3D; np.zeros(nums)  # 初始化所有点的标签为0（表示未处理）    cluster_id &#x3D; 0  # 聚类编号初始化为0    # 遍历每个样本点    for i in range(nums):        if labels[i] !&#x3D; 0:  # 如果该点已经被处理过，跳过            continue        else:            # 获取点i的邻域            neighbors &#x3D; findNeighbor(i, X, eps)            if len(neighbors) &lt; min_Pts:  # 如果邻域内的点数小于min_Pts，标记为噪声                labels[i] &#x3D; -1            else:  # 如果是核心点，则扩展簇                cluster_id +&#x3D; 1  # 创建一个新的簇                labels[i] &#x3D; cluster_id  # 将当前点标记为该簇                expandCluster(X, labels, i, neighbors, cluster_id, eps, min_Pts)    return labels  # 返回聚类结果<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="AGNES"><a href="#AGNES" class="headerlink" title="AGNES"></a>AGNES</h3><p>自底向上的不断合并簇直到簇数量满足要求</p><p><code>clusters[cova] += clusters[covb]</code> 合并簇</p><p><code>del clusters[covb]  # 删除第二个簇</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npdef AGNES(feature, k):    &#39;&#39;&#39;    AGNES聚类并返回聚类结果，量化距离时请使用簇间最大欧氏距离    假设数据集为&#96;[1, 2], [10, 11], [1, 3]]，那么聚类结果可能为&#96;[[1, 2], [1, 3]], [[10, 11]]]    :param feature:数据集，类型为ndarray    :param k:表示想要将数据聚成&#96;k&#96;类，类型为&#96;int&#96;    :return:聚类结果，类型为list    &#39;&#39;&#39;    #********* Begin *********#    clusters&#x3D;[[feature[i]] for i in range(len(feature))]    cluster_nums&#x3D;len(clusters)    while cluster_nums &gt; k:        dist_min &#x3D; 1e9        cova, covb &#x3D; -1, -1        # 寻找距离最小的簇对        for idx1 in range(cluster_nums):            for idx2 in range(idx1 + 1, cluster_nums):                # 计算两个簇之间的最小欧氏距离                dist &#x3D; []                for i in clusters[idx1]:                    for j in clusters[idx2]:                        dist.append(np.linalg.norm(i - j))                curr_max &#x3D; np.min(dist)  # 选择最小欧氏距离                if curr_min &lt; dist_min:                    dist_min &#x3D; curr_max                    cova, covb &#x3D; idx1, idx2        # 合并最小距离的两个簇        clusters[cova] +&#x3D; clusters[covb]        del clusters[covb]  # 删除第二个簇        # 更新簇的数量        cluster_nums -&#x3D; 1    #********* End *********#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h3><p>单次迭代</p><p><code>np.sum(np.abs(np.array(new_thetas)-np.array(thetas))</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npdef em_single(init_values, observations):    pa, pb &#x3D; init_values    a_heads &#x3D; 0    a_tails &#x3D; 0    b_heads &#x3D; 0    b_tails &#x3D; 0    for trial in observations:        num_heads &#x3D; sum(trial)        num_tails &#x3D; len(trial) - num_heads        log_ka &#x3D; np.sum([np.log(pa if coin &#x3D;&#x3D; 1 else 1 - pa) for coin in trial])        log_kb &#x3D; np.sum([np.log(pb if coin &#x3D;&#x3D; 1 else 1 - pb) for coin in trial])        # Convert log-probabilities to probabilities safely        max_log &#x3D; max(log_ka, log_kb)        exp_ka &#x3D; np.exp(log_ka - max_log)        exp_kb &#x3D; np.exp(log_kb - max_log)        total &#x3D; exp_ka + exp_kb        softa &#x3D; exp_ka &#x2F; total        softb &#x3D; exp_kb &#x2F; total        a_heads +&#x3D; softa * num_heads        a_tails +&#x3D; softa * num_tails        b_heads +&#x3D; softb * num_heads        b_tails +&#x3D; softb * num_tails    return [a_heads &#x2F; (a_heads + a_tails), b_heads &#x2F; (b_heads + b_tails)]def em(observations, thetas, tol&#x3D;1e-4, iterations&#x3D;100):    &quot;&quot;&quot;    模拟抛掷硬币实验并使用EM算法估计硬币A与硬币B正面朝上的概率。    :param observations: 抛掷硬币的实验结果记录，类型为list。    :param thetas: 硬币A与硬币B正面朝上的概率的初始值，类型为list，如[0.2, 0.7]代表硬币A正面朝上的概率为0.2，硬币B正面朝上的概率为0.7。    :param tol: 差异容忍度，即当EM算法估计出来的参数theta不怎么变化时，可以提前挑出循环。例如容忍度为1e-4，则表示若这次迭代的估计结果与上一次迭代的估计结果之间的L1距离小于1e-4则跳出循环。为了正确的评测，请不要修改该值。    :param iterations: EM算法的最大迭代次数。为了正确的评测，请不要修改该值。    :return: 将估计出来的硬币A和硬币B正面朝上的概率组成list或者ndarray返回。如[0.4, 0.6]表示你认为硬币A正面朝上的概率为0.4，硬币B正面朝上的概率为0.6。    &quot;&quot;&quot;    #********* Begin *********#    new_thetas&#x3D;0    for i in range(iterations):        new_thetas&#x3D;em_single(thetas,observations)        if(np.sum(np.abs(np.array(new_thetas)-np.array(thetas)))&lt;tol):            break        thetas&#x3D;new_thetas    return new_thetas    #********* End *********#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h3><h4 id="外部指标"><a href="#外部指标" class="headerlink" title="外部指标"></a>外部指标</h4><p><img title="" src="/images/ml/330931b0-7aa1-49a4-9175-648ba48b488f.png" alt="330931b0-7aa1-49a4-9175-648ba48b488f" style="zoom:100%;"><img src="/images/ml/4c790a9f-bc87-4ae3-b8d2-0e71053ba5fe.png" title="" alt="4c790a9f-bc87-4ae3-b8d2-0e71053ba5fe" style="zoom:100%;"><img src="/images/ml/2511f0bd-2098-4af2-8995-1ad788f84bf2.png" title="" alt="2511f0bd-2098-4af2-8995-1ad788f84bf2" style="zoom:100%;"><img src="/images/ml/f58e9601-924d-4456-bfd0-82c71595e1aa.png" alt="f58e9601-924d-4456-bfd0-82c71595e1aa"></p><p><code>if y_true[i] == y_true[j] and y_pred[i] == y_pre #求与操作用and，&amp;是位运算</code></p><p><code>a+=1</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">def calc(y_true, y_pred):    a &#x3D; b &#x3D; c &#x3D; d &#x3D; 0    for i in range(len(y_true)):        for j in range(i + 1, len(y_pred)):            if y_true[i] &#x3D;&#x3D; y_true[j] and y_pred[i] &#x3D;&#x3D; y_pred[j]:                a +&#x3D; 1            elif y_true[i] &#x3D;&#x3D; y_true[j] and y_pred[i] !&#x3D; y_pred[j]:                b +&#x3D; 1            elif y_true[i] !&#x3D; y_true[j] and y_pred[i] &#x3D;&#x3D; y_pred[j]:                c +&#x3D; 1            else:                d +&#x3D; 1    return [a, b, c, d]def calc_JC(y_true, y_pred):    ex &#x3D; calc(y_true, y_pred)    return ex[0] &#x2F; (ex[0] + ex[1] + ex[2]) if (ex[0] + ex[1] + ex[2]) !&#x3D; 0 else 0.0def calc_FM(y_true, y_pred):    ex &#x3D; calc(y_true, y_pred)    if (ex[0] + ex[1]) &#x3D;&#x3D; 0 or (ex[0] + ex[2]) &#x3D;&#x3D; 0:        return 0.0    return np.sqrt((ex[0] &#x2F; (ex[0] + ex[1])) * (ex[0] &#x2F; (ex[0] + ex[2])))def calc_Rand(y_true, y_pred):    m &#x3D; len(y_true)    ex &#x3D; calc(y_true, y_pred)    return 2 * (ex[0] + ex[3]) &#x2F; (m * (m - 1)) if m &gt; 1 else 0.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="内部指标"><a href="#内部指标" class="headerlink" title="内部指标"></a>内部指标</h4><p>DB 指数越小就越就意味着簇内距离越小同时簇间距离越大，也就是说DB 指数越小越好</p><p>Dunn 指数越大意味着簇内距离越小同时簇间距离越大，也就是说 Dunn 指数 越大越好</p><p><img title="" src="/images/ml/29169c68-916f-4aca-b12f-9cf208277638.png" alt="29169c68-916f-4aca-b12f-9cf208277638" style="zoom:100%;"><img title="" src="/images/ml/a27f2156-e19b-448d-a1a4-35ff3967c1e0.png" alt="a27f2156-e19b-448d-a1a4-35ff3967c1e0" style="zoom:100%;"></p><p><code>np.array,arr.tolist</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npa &#x3D; [1, 2, 3]arr &#x3D; np.array(a)arr &#x3D; np.array([1, 2, 3])a &#x3D; arr.tolist()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>centroids = np.array([np.mean(feature[pred == label], axis=0) for label in labels])</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npdef calc_DBI(feature, pred):    labels &#x3D; np.unique(pred)    k &#x3D; len(labels)    centroids &#x3D; np.array([np.mean(feature[pred &#x3D;&#x3D; label], axis&#x3D;0) for label in labels])    # 计算每个簇的类内平均距离（紧密度）    s &#x3D; []    for label in labels:        cluster_points &#x3D; feature[pred &#x3D;&#x3D; label]        centroid &#x3D; np.mean(cluster_points, axis&#x3D;0)        distances &#x3D; np.sqrt(np.sum((cluster_points - centroid) ** 2, axis&#x3D;1))        s.append(np.mean(distances))    s &#x3D; np.array(s)    # 计算簇质心间的距离矩阵    M &#x3D; np.zeros((k, k))    for i in range(k):        for j in range(k):            if i !&#x3D; j:                M[i][j] &#x3D; np.linalg.norm(centroids[i] - centroids[j])    # DBI 计算    dbi &#x3D; 0    for i in range(k):        max_r &#x3D; -np.inf        for j in range(k):            if i !&#x3D; j:                r &#x3D; (s[i] + s[j]) &#x2F; M[i][j]                if r &gt; max_r:                    max_r &#x3D; r        dbi +&#x3D; max_r    return dbi &#x2F; k    for label in labels:        feat&#x3D;feature[pred&#x3D;&#x3D;label]        center&#x3D;np.mean(feat,axis&#x3D;0)        dist&#x3D;[]        for i in feat:            dist.append(np.linalg.norm(i-center))        s.append(np.mean(dist))    #s[i]为簇内平均距离    maxsum&#x3D;0    for i in range(k):        max1&#x3D;0        for j in range(k):            if(i!&#x3D;j):                max1&#x3D;max((s[i]+s[j])&#x2F;np.linalg.norm(centroids[i]-centroids[j]),max1)        maxsum+&#x3D;max1    return maxsum&#x2F;k    #********* End *********#def calc_DI(feature, pred):    labels &#x3D; np.unique(pred)    k &#x3D; len(labels)    # 计算每个簇的最大内部距离    max_intra &#x3D; 0    for label in labels:        points &#x3D; feature[pred &#x3D;&#x3D; label]        for i in range(len(points)):            for j in range(i + 1, len(points)):                dist &#x3D; np.linalg.norm(points[i] - points[j])                if dist &gt; max_intra:                    max_intra &#x3D; dist    # 计算簇间最小距离    min_inter &#x3D; np.inf    for i in range(k):        for j in range(i + 1, k):            points_i &#x3D; feature[pred &#x3D;&#x3D; labels[i]]            points_j &#x3D; feature[pred &#x3D;&#x3D; labels[j]]            for p in points_i:                for q in points_j:                    dist &#x3D; np.linalg.norm(p - q)                    if dist &lt; min_inter:                        min_inter &#x3D; dist    return min_inter &#x2F; max_intra if max_intra !&#x3D; 0 else 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h2><p>维数灾难通常是指对于已知样本数目，存在一个特征数目的最大值，当实际使用的特征数目超过这个最大值时，机器学习算法的性能不是得到改善，而是退化（过拟合）。</p><ul><li><p>降低机器学习算法的时间复杂度；</p></li><li><p>节省了提取不必要特征的开销；</p></li><li><p>缓解因为维数灾难所造成的过拟合现象。</p></li></ul><h3 id="PCA主成分分析"><a href="#PCA主成分分析" class="headerlink" title="PCA主成分分析"></a>PCA主成分分析</h3><p> PCA 是将数据从原来的坐标系转换到新的坐标系，新的坐标系的选择是由数据本身决定的。</p><p>第一个新坐标轴选择的是原始数据中方差最大的方向，第二个新坐标轴的选择和第一个坐标轴正交且方差最大的方向。然后该过程一直重复，重复次数为原始数据中的特征数量。最后会发现大部分方差都包含在最前面几个新坐标轴中，因此可以忽略剩下的坐标轴，从而达到降维的目的。</p><p> PCA 在降维时，需要指定将维度降至多少维，假设降至 k 维，则 PCA 的算法流程如下：</p><p>demean；<br>计算数据的协方差矩阵；<br>计算协方差矩阵的特征值与特征向量；<br>按照特征值，将特征向量从大到小进行排序；<br>选取前 k 个特征向量作为转换矩阵；<br>demean 后的数据与转换矩阵做矩阵乘法获得降维后的数据</p><p><code>matrix=np.cov(data.T) #cov函数期望行代表特征</code></p><p><code>val, vec = np.linalg.eigh(mat) #计算特征值和特征向量</code></p><p><code>indices = np.argsort(val)[::-1]  # 倒序排序，val越大越重要</code></p><p><code>vec_res = vec_sort[:,:k]</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npdef pca(data, k):    &#39;&#39;&#39;    对data进行PCA，并将结果返回    :param data: 数据集，类型为ndarray    :param k: 想要降成几维，类型为int    :return: 降维后的数据，类型为ndarray    &#39;&#39;&#39;    #********* Begin *********#    # 均值归一化    me &#x3D; np.mean(data, axis&#x3D;0)    data &#x3D; data - me    # 计算协方差矩阵        # after_demean的行数为样本个数，列数为特征个数    # 由于cov函数的输入希望是行代表特征，列代表数据的矩阵，所以要转置    mat &#x3D; np.cov(data.T)    # 计算特征值和特征向量    val, vec &#x3D; np.linalg.eigh(mat)    # 按特征值从大到小排序，选择前k个特征向量    indices &#x3D; np.argsort(val)[::-1]  # 倒序排序，val越大越重要    vec_sort &#x3D; vec[:, indices]       # 按排序后的索引选择特征向量    # 选择前k个主成分    vec_res &#x3D; vec_sort[:, [i for i in range(k)]]        # 取前k列    # 返回降维后的数据    return data.dot(vec_res)    #********* End *********#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="MDS多维缩放"><a href="#MDS多维缩放" class="headerlink" title="MDS多维缩放"></a>MDS多维缩放</h3><p>MDS 算法认为，在数据样本中，每个样本的每个特征值并不是数据间关系的必要特征，真正的基础特征是每个点与数据集中其他点的距离。</p><p><img src="/images/ml/52b1aa56-a1b4-4912-9f37-958227f2295d.png" title="" alt="52b1aa56-a1b4-4912-9f37-958227f2295d" style="zoom:100%;"></p><p><code>H = np.eye(n_samples) - np.ones((n_samples, n_samples)) / n_samples #单位阵减去1/n全一矩阵</code></p><p><code>B = -0.5 * np.dot(H, np.dot(distance_matrix ** 2, H))</code></p><p><code>eigvals_k = np.diag(np.sqrt(eigvals_sorted[:k])) #取前 k 个排序好的特征值，先开平方，然后把它们放到一个对角矩阵中</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npdef euclidean_distance(x, y):    &quot;&quot;&quot;计算欧几里得距离&quot;&quot;&quot;    return np.sqrt(np.sum((x - y) ** 2))def compute_distance_matrix(data):    &quot;&quot;&quot;计算距离矩阵&quot;&quot;&quot;    n_samples &#x3D; data.shape[0]    distance_matrix &#x3D; np.zeros((n_samples, n_samples))    for i in range(n_samples):        for j in range(n_samples):           distance_matrix[i, j] &#x3D; euclidean_distance(data[i], data[j])    return distance_matrixdef mds(data, k):    &quot;&quot;&quot;    手动实现MDS降维    :param data: 原始数据 (样本，特征) 形式的 numpy 数组    :param k: 目标降维的维度，默认2    :return: 降维后的数据    &quot;&quot;&quot;    # 1. 计算距离矩阵    distance_matrix &#x3D; compute_distance_matrix(data)    # 2. 中心化距离矩阵    n_samples &#x3D; distance_matrix.shape[0]    H &#x3D; np.eye(n_samples) - np.ones((n_samples, n_samples)) &#x2F; n_samples    B &#x3D; -0.5 * np.dot(H, np.dot(distance_matrix ** 2, H))    # 3. 特征值分解    eigvals, eigvecs &#x3D; np.linalg.eigh(B)    # 4. 按照特征值从大到小排序    sorted_indices &#x3D; np.argsort(eigvals)[::-1]  # 降序排列    eigvals_sorted &#x3D; eigvals[sorted_indices]    eigvecs_sorted &#x3D; eigvecs[:, sorted_indices]    # 5. 选择前k个特征值和特征向量    eigvals_k &#x3D; np.diag(np.sqrt(eigvals_sorted[:k]))    eigvecs_k &#x3D; eigvecs_sorted[:, :k]    # 6. 计算低维坐标    low_dim_data &#x3D; np.dot(eigvecs_k, eigvals_k)    return low_dim_data  # 返回转置后的低维数据# -*- coding: utf-8 -*-from sklearn.manifold import MDSdef mds(data,d):    &#39;&#39;&#39;    input:data(ndarray):待降维数据          d(int):降维后数据维度    output:Z(ndarray):降维后数据    &#39;&#39;&#39;    #********* Begin *********#    model&#x3D;MDS(n_components&#x3D;d)#n_components ：即我们进行 MDS 降维时降到的维数。在降维时需要输入这个参数。    Z&#x3D;model.fit_transform(data)    #********* End *********#    return Z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Isomap等度量映射"><a href="#Isomap等度量映射" class="headerlink" title="Isomap等度量映射"></a>Isomap等度量映射</h3><p>Isomap 算法可以看作是 “在局部保持邻居关系的基础上，再用 MDS 降维”</p><p><img src="/images/ml/12a51984-99cd-49db-8d4d-223eb5b394bc.png" alt="12a51984-99cd-49db-8d4d-223eb5b394bc"></p><p><code>Z = V @ L #特征向量组成的矩阵在左边，乘特征值构成的的对角阵</code></p><p><code>model = Isomap(n_components=d,n_neighbors=k) 取k个相邻数据，降到d维</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># -*- coding: utf-8 -*-import numpy as npdef isomap(data, d, k, Max&#x3D;1e9):    &#39;&#39;&#39;    input:        data(ndarray): 待降维数据，shape&#x3D;(n_samples, n_features)        d(int): 降维后数据维数        k(int): 最近的k个样本        Max(float): 表示无穷大    output:        Z(ndarray): 降维后的数据，shape&#x3D;(n_samples, d)    &#39;&#39;&#39;    n &#x3D; data.shape[0]    # Step 1: 计算欧氏距离矩阵    dist_matrix &#x3D; np.zeros((n, n))    for i in range(n):        for j in range(i + 1, n):            dist &#x3D; np.linalg.norm(data[i] - data[j])            dist_matrix[i][j] &#x3D; dist_matrix[j][i] &#x3D; dist    # Step 2: 构建 k-近邻图（非邻接的点设为 Max）    graph &#x3D; np.full((n, n), Max)    for i in range(n):        neighbors &#x3D; np.argsort(dist_matrix[i])[1:k+1]  # 取前k个最近邻（排除自身）        for j in neighbors:            graph[i][j] &#x3D; dist_matrix[i][j]            graph[j][i] &#x3D; dist_matrix[i][j]  # 保持对称    # Step 3: 使用 Floyd-Warshall 算法求最短路径（近似测地线）    for k_mid in range(n):        for i in range(n):            for j in range(n):                if graph[i][j] &gt; graph[i][k_mid] + graph[k_mid][j]:                    graph[i][j] &#x3D; graph[i][k_mid] + graph[k_mid][j]    # Step 4: 多维尺度分析 (MDS)    D &#x3D; graph    D_squared &#x3D; D ** 2    H &#x3D; np.eye(n) - np.ones((n, n)) &#x2F; n    B &#x3D; -0.5 * H @ D_squared @ H    # Step 5: 特征值分解    eigvals, eigvecs &#x3D; np.linalg.eigh(B)    idx &#x3D; np.argsort(eigvals)[::-1]    eigvals &#x3D; eigvals[idx]    eigvecs &#x3D; eigvecs[:, idx]    # Step 6: 计算嵌入坐标 Z    L &#x3D; np.diag(np.sqrt(eigvals[:d]))    V &#x3D; eigvecs[:, :d]    Z &#x3D; V @ L    return Z# -*- coding: utf-8 -*-from sklearn.manifold import Isomapdef isomap(data,d,k):    &#39;&#39;&#39;    input:data(ndarray):待降维数据          d(int):降维后数据维度          k(int):最近的k个样本    output:Z(ndarray):降维后数据    &#39;&#39;&#39;    #********* Begin *********#    model &#x3D; Isomap(n_components&#x3D;d,n_neighbors&#x3D;k)    Z&#x3D;model.fit_transform(data)    #********* End *********#    return Z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="LLE局部线性嵌入"><a href="#LLE局部线性嵌入" class="headerlink" title="LLE局部线性嵌入"></a>LLE局部线性嵌入</h3><p><img src="/images/ml/8fe236dc-3502-4bd8-9969-bbe2f0fd0db8.png" title="" alt="8fe236dc-3502-4bd8-9969-bbe2f0fd0db8" style="zoom:100%;"></p><p><code>Z = data[N_i] - data[i]  # shape: (k, m)</code></p><p> <code>C = Z.dot(Z.T)  # 计算邻居之间差异的协方差矩阵 C，形状是 (k, k)</code></p><p><code>C += np.eye(k) * 1e-3  # 为了数值稳定，给协方差矩阵 C 加上一个小的正则项（0.001）</code></p><p><code>w = np.linalg.solve(C, ones)  # 解线性方程组，得到每个邻居的权重</code></p><p><code>W[i, N_i[j]] = w[j]  # 将第 j 个邻居的权重填入相应位置</code></p><p><code>M = (I - W).T.dot(I - W)  # 计算矩阵 M，形式为 (I - W)^T * (I - W)</code></p><p> <code>Z = eigvecs[:, idx[1:d+1]]  # 选取最小的 d 个特征值对应的特征向量（跳过第一个全1特征向量）</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># encoding&#x3D;utf8 import numpy as np# 计算数据集的欧氏距离矩阵def calc_dist(data):    n &#x3D; data.shape[0]  # 获取样本数目    dist_matrix &#x3D; np.zeros((n, n))  # 初始化一个 n x n 的距离矩阵    for i in range(n):        for j in range(n):            # 计算第 i 个样本与第 j 个样本的欧氏距离            dist_matrix[i, j] &#x3D; np.linalg.norm(data[i] - data[j])  # np.linalg.norm 计算欧氏距离    return dist_matrix# 找到每个样本的 k 个最近邻def find_neighbors(dist_matrix, k):    n &#x3D; dist_matrix.shape[0]  # 获取样本数目    neighbors &#x3D; np.zeros((n, k), dtype&#x3D;int)  # 初始化一个 n x k 的邻居矩阵    for i in range(n):        # 对于每个样本，按距离从小到大排序，找到前 k 个邻居（排除自己）        sorted_indices &#x3D; np.argsort(dist_matrix[i])  # 排序，返回排序后的索引        neighbors[i] &#x3D; sorted_indices[1:k+1]  # 排除自己（即第一个是自己，跳过）    return neighbors# 局部线性嵌入（LLE）算法def lle(data, d, k):    n, m &#x3D; data.shape  # n: 样本数目, m: 原始特征维度    dist_matrix &#x3D; calc_dist(data)  # 计算数据点之间的距离矩阵    neighbors &#x3D; find_neighbors(dist_matrix, k)  # 找到每个样本的 k 个邻居    # 初始化权重矩阵 W，存储每个样本到其邻居的权重    W &#x3D; np.zeros((n, n))    # 对于每个样本，计算其到邻居的权重    for i in range(n):        # 获取第 i 个样本的 k 个邻居的索引        N_i &#x3D; neighbors[i]        # 构建邻居矩阵 Z：每列是一个邻居与 x_i 的差        Z &#x3D; data[N_i] - data[i]  # Z 的形状是 (k, m)，即每行是一个邻居的差向量        C &#x3D; Z.dot(Z.T)  # 计算邻居之间差异的协方差矩阵 C，形状是 (k, k)        C +&#x3D; np.eye(k) * 1e-3  # 为了数值稳定，给协方差矩阵 C 加上一个小的正则项（0.001）#在计算协方差矩阵 C &#x3D; Z.dot(Z.T) 时，可能会遇到矩阵 C 变得奇异（即行列式为零），特别是当邻居之间的差异非常小或者完全相同时。这种情况下，矩阵 C 可能不可逆，导致无法进行后续的线性求解。        # 解线性方程 Cw &#x3D; 1，得到权重 w        ones &#x3D; np.ones(k)  # 创建一个大小为 k 的全1向量        w &#x3D; np.linalg.solve(C, ones)  # 解线性方程组，得到每个邻居的权重        w &#x3D; w &#x2F; np.sum(w)  # 归一化权重，使得它们的和为 1        # 将计算得到的权重 w 填入第 i 行的权重矩阵 W 中        for j in range(k):            W[i, N_i[j]] &#x3D; w[j]  # 将第 j 个邻居的权重填入相应位置    # 构造矩阵 M &#x3D; (I - W)^T * (I - W)    I &#x3D; np.eye(n)  # n x n 的单位矩阵    M &#x3D; (I - W).T.dot(I - W)  # 计算矩阵 M，形式为 (I - W)^T * (I - W)    # 计算 M 的特征值和特征向量    eigvals, eigvecs &#x3D; np.linalg.eigh(M)  # eigvals: 特征值, eigvecs: 特征向量    # 选择最小的 d+1 个特征值对应的特征向量（第一个特征值是 0 对应的全1向量，跳过）    idx &#x3D; np.argsort(eigvals)  # 获取特征值的排序索引    Z &#x3D; eigvecs[:, idx[1:d+1]]  # 选取最小的 d 个特征值对应的特征向量（跳过第一个全1特征向量）    return Z  # 返回降维后的数据# -*- coding: utf-8 -*-from sklearn.manifold import LocallyLinearEmbeddingdef lle(data,d,k):    &#39;&#39;&#39;    input:data(ndarray):待降维数据          d(int):降维后数据维度          k(int):邻域内样本数    output:Z(ndarray):降维后数据    &#39;&#39;&#39;    #********* Begin *********#    model&#x3D;LocallyLinearEmbedding(n_components&#x3D;d,n_neighbors&#x3D;k)    Z&#x3D;model.fit_transform(data)    #********* End *********#    return Z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Python </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Image as IMU</title>
      <link href="/2025/10/08/Image-as-IMU/"/>
      <url>/2025/10/08/Image-as-IMU/</url>
      
        <content type="html"><![CDATA[<script type="text/javascript" async  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><p>这篇文章提出了从单张运动模糊图像中估计相机速度的方法，将模糊作为运动的线索而非噪声，此处的运动模糊是曝光时间内多个“虚拟图像”的叠加，其模糊轨迹可视为“虚拟光流”，蕴含了相机运动信息</p><hr><h2 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h2><p>Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image</p><p>文章来自2025ICCV，作者是Jerred Chen 和Ronald Clark，arxiv地址为</p><p><a href="https://arxiv.org/abs/2503.17358">[2503.17358] Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image</a></p><h2 id="传统方法的问题"><a href="#传统方法的问题" class="headerlink" title="传统方法的问题"></a>传统方法的问题</h2><p>在机器人和VR/AR应用中，相机快速移动会导致严重的<strong>运动模糊</strong>（motion blur）。这种模糊会破坏传统视觉里程计（VO）和运动恢复结构（SfM）方法所依赖的图像特征匹配，导致这些方法失效</p><p><strong>现有解决方案的缺陷</strong>：</p><ul><li><strong>丢弃模糊帧</strong>：简单粗暴，但是会丢失宝贵的运动信息。</li><li><strong>融合IMU</strong>：虽然有效，但引入了额外的硬件成本、复杂的传感器同步问题以及IMU固有的漂移误差（drift）</li></ul><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><ul><li><p><strong>图像形成过程</strong>：在曝光时间 τ 内，相机不断移动，每个像素累积了来自不同场景点的光线。公式(1)给出了模糊图像 $I_B$​ 的积分定义。</p><script type="math/tex; mode=display">I_B = g \int_{\tau_0}^{\tau} I_\nu(t) \, dt</script></li><li><p><strong>离散化近似</strong>：在实践中，将曝光时间离散化为 N 个瞬间，每个瞬间对应一个“虚拟图像”$I_{\nu_i}$ ​。模糊图像是这些虚拟图像的平均。</p><script type="math/tex; mode=display">I_B \approx g \frac{1}{N} \sum_{i=1}^{N} I_{\nu_i}</script></li><li><p><strong>核心直觉</strong>：一张模糊图像可以被视为由多个“虚拟图像”叠加而成。这些虚拟图像之间的像素对应关系，就编码了相机的运动信息。</p></li><li><p><strong>虚拟对应关系</strong>：假设场景是刚性的，那么从第一个虚拟图像到最后一个虚拟图像   $I_{\nu_1}, \ldots, I_{\nu_N}$  每个像素的位移就是一个“虚拟光流”。这个光流场直接关联到相机在曝光期间的相对运动。</p></li><li><p><strong>结合深度</strong>：如果再知道场景的深度 D，就可以将2D的像素运动（光流）与3D的相机运动联系起来，从而求解出完整的6DoF相对位姿。</p></li></ul><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="Flow-and-Depth-Prediction-光流与深度预测"><a href="#Flow-and-Depth-Prediction-光流与深度预测" class="headerlink" title="Flow and Depth Prediction (光流与深度预测)"></a><strong>Flow and Depth Prediction (光流与深度预测)</strong></h3><ul><li><p><strong>网络架构</strong>：采用 <strong>SegNeXt</strong> 作为共享编码器，两个独立的解码器分别输出光流 F 和深度 D。</p></li><li><p><strong>光流定义</strong>：其中 p1​ 是第一个虚拟图像中的像素坐标，p2′​ 是同一3D点投影到最后一个虚拟图像中的坐标。</p><script type="math/tex; mode=display">F = p'_2 - p_1</script></li><li><p><strong>损失函数</strong>：</p></li></ul><script type="math/tex; mode=display">L_1 = \lambda_F \|F - h_f(\hat{F}_{fw}, \hat{F}_{bw})\| + \lambda_D \|D - \hat{D}\|</script><ul><li><p>对光流和深度分别施加L1损失。</p></li><li><p>引入<strong>重定向函数</strong> hf​解决训练歧义。因为无法确定哪个虚拟图像是“开始”，所以标签 F 会被设定为与预测方向 F 更接近的那个真实方向（正向 $F_{fw}$或反向$F_{bw}$确保训练稳定。</p><script type="math/tex; mode=display">h_f(\hat{F}_{fw}, \hat{F}_{bw}; F) =\begin{cases}\hat{F}_{fw}, & \text{if } \langle \hat{F}_{fw}, F \rangle > \langle \hat{F}_{bw}, F \rangle \\\hat{F}_{bw}, & \text{otherwise}\end{cases}</script></li></ul><h3 id="Differentiable-Velocity-Computation-可微分速度计算"><a href="#Differentiable-Velocity-Computation-可微分速度计算" class="headerlink" title="Differentiable Velocity Computation (可微分速度计算)"></a><strong>Differentiable Velocity Computation (可微分速度计算)</strong></h3><ul><li><strong>理论依据</strong>：采用Trucco and Verri的运动场方程，该方程建立了像素运动 (Fx​,Fy​)、深度 d、焦距 f 和相机6DoF运动 (θx​,θy​,θz​,tx​,ty​,tz​) 之间的数学关系。</li></ul><script type="math/tex; mode=display">  F_x = \frac{t_z p_x - t_x f}{d} - \theta_y f + \theta_z p_y + \frac{\theta_x p_x p_y}{f} - \frac{\theta_y p_x^2}{f}</script><script type="math/tex; mode=display">  F_y = \frac{t_z p_y - t_y f}{d} + \theta_x f - \theta_z p_x - \frac{\theta_y p_x p_y}{f} + \frac{\theta_x p_y^2}{f}</script><ul><li><p><strong>线性系统</strong>：将运动场方程改写为标准的线性形式 Ax=b（公式8和9）。</p><ul><li>A 矩阵由像素坐标、深度和焦距构成。</li><li>x 是待求解的6个运动参数。</li><li>b 是预测的光流向量。</li></ul></li></ul><script type="math/tex; mode=display">A =\begin{bmatrix} -\frac{f}{d} & 0 & \frac{p_x}{d} & \frac{p_x p_y}{f} & -\frac{p_x^2 + f^2}{f} & p_y \\ 0 & -\frac{f}{d} & \frac{p_y}{d} & \frac{p_y^2 + f^2}{f} & -\frac{p_x p_y}{f} & -p_x\end{bmatrix}</script><script type="math/tex; mode=display">x =\begin{bmatrix}t_x \\ t_y \\ t_z \\ \theta_x \\ \theta_y \\ \theta_z\end{bmatrix}, \quadb =\begin{bmatrix}F_x \\ F_y\end{bmatrix}</script><ul><li><strong>最小二乘求解</strong>：对于图像中的所有像素，系统是超定的。使用最小二乘法求解最优解</li></ul><script type="math/tex; mode=display">  x = (A^\top A)^{-1} A^\top b</script><ul><li><p><strong>速度计算</strong>：将求得的相对位姿变化除以曝光时间 τ，即可得到瞬时速度 (ω,v)。</p></li><li><p><strong>端到端训练</strong>：由于最小二乘求解是可微分的，可以将最终的速度预测误差（公式11中的 L2​）反向传播，实现从输入图像到最终速度的端到端优化。</p></li></ul><script type="math/tex; mode=display">L_2 = \lambda_R \| R - h_p(\hat{R}) \|^2      + \lambda_t \| t - h_p(\hat{t}) \|^2      + L_1</script><h3 id="Direction-Disambiguation-方向歧义性解决"><a href="#Direction-Disambiguation-方向歧义性解决" class="headerlink" title="Direction Disambiguation (方向歧义性解决)"></a><strong>Direction Disambiguation (方向歧义性解决)</strong></h3><ul><li><p><strong>问题根源</strong>：运动模糊是时间对称的，无法区分正向和反向运动。</p></li><li><p><strong>解决方案</strong>：</p><ol><li><p>给定连续帧$I_{i-1}$, $I_i$, $I_{i+1}$，其中 $I_i$ 是模糊图像。</p></li><li><p>将预测的完整光流 $F_ i$ 按时间比例缩放，得到短时间光流 $F_{i’}$,然后用 $F_{i’}$扭曲$l_{i}$得到$l_{i’}$</p><script type="math/tex; mode=display">F'_i = \Delta t_f \, F_i, \quadI'_i = \Phi(I_i; F'_i)</script></li><li><p>计算两种可能方向（正向和反向）下的总光度误差 $e_{fw}$​ 和 $e_{bw}$(i-1，i，i+1)。</p><script type="math/tex; mode=display">P(I_1, I_2) = \frac{1}{HW} \sum_{u=0}^{H-1} \sum_{v=0}^{W-1} \big| I_1(u,v) - I_2(u,v) \big| \tag {帧光度误差}</script><script type="math/tex; mode=display">e_{fw} = P(I_{i+1}, I'_i, fw) + P(I_{i-1}, I'_i, bw)</script><script type="math/tex; mode=display">e_{bw} = P(I_{i+1}, I'_i, bw) + P(I_{i-1}, I'_i, fw)</script></li><li><p>选择误差更小的方向作为最终的运动方向。</p><script type="math/tex; mode=display">\omega, v =\begin{cases}\omega_{fw}, v_{fw}, & \text{if } e_{fw} < e_{bw} \\\omega_{bw}, v_{bw}, & \text{otherwise}\end{cases}</script></li></ol></li></ul><h2 id="数据集构建"><a href="#数据集构建" class="headerlink" title="数据集构建"></a>数据集构建</h2><h3 id="合成数据集"><a href="#合成数据集" class="headerlink" title="合成数据集"></a>合成数据集</h3><p><strong>模糊合成流程</strong>：</p><ol><li>选取一个真实图像 $I_{i}$ 。</li><li>使用<strong>RIFE</strong>插值模型，在 $I_{i}$ 和后续的 N 个真实帧之间生成多个虚拟帧，形成一个序列$I$。</li><li>将序列 $I$转换到线性空间，取平均，再转回sRGB，得到模糊图像 $I_B$​。</li></ol><p><strong>真值获取</strong>：</p><ul><li><p><strong>深度</strong>：使用PromptDA模型，结合第一个虚拟图像 $I_{\nu_1}$​ 和ARKit稀疏深度，生成稠密深度图 D。</p></li><li><p><strong>光流</strong>：利用深度图 D，将 $I_{\nu_1}$​ 中的所有像素反投影到3D空间，再投影到 $I_{\nu_N}$，计算位移得到真值光流 F。</p></li><li><p><strong>规模</strong>：约12万训练样本，1.2万验证样本</p></li></ul><h3 id="真实数据集"><a href="#真实数据集" class="headerlink" title="真实数据集"></a>真实数据集</h3><h2 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h2><p>为了评估模型的真实性能，作者在4个未见过的真实世界视频序列上进行了测试。评估的核心是相机的<strong>瞬时速度</strong>，因此需要精确的真值。</p><p>对于<strong>角速度</strong>（ω）的真值，直接采用了设备内置<strong>陀螺仪</strong>（gyroscope）的测量数据，这是最直接可靠的物理测量。对于<strong>线速度</strong>（v）的真值，由于没有直接的传感器，作者通过对<strong>ARKit</strong>系统估计出的相机位姿进行<strong>中心有限差分</strong>（centered finite-difference）计算来近似得到。</p><p>评价指标采用了各轴向的<strong>均方根误差</strong>（RMSE），单位分别为弧度每秒（rad/s）和米每秒（m/s）。作为对比的基线方法包括COLMAP、MASt3R和DROID-SLAM。由于这些方法本质上是估计多帧间的相对位姿而非瞬时速度，因此同样通过对它们输出的位姿序列进行有限差分来近似其速度估计，从而与本文方法进行公平比较。</p><h2 id="一些注意"><a href="#一些注意" class="headerlink" title="一些注意"></a>一些注意</h2><p>这篇论文虽然说“from a single motion-blurred image”，但其完整的方法流程（包括方向歧义解决）实际上<strong>隐含地假设了存在一个连续的视频流或至少能获取邻近帧</strong>。</p><p>例如系统正在实时接收视频帧。当检测到某一帧 ${I}_{i}$ 模糊时，它可以利用刚刚过去的 ${I}_{i-1}$ 和即将到来的 ${I}_{i+1}$来解决方向问题。</p>]]></content>
      
      
      <categories>
          
          <category> 2025ICCV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运动模糊 </tag>
            
            <tag> 运动估计 </tag>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Some python grammar</title>
      <link href="/2025/10/06/Some-python-grammar/"/>
      <url>/2025/10/06/Some-python-grammar/</url>
      
        <content type="html"><![CDATA[<p>这是一篇从C++算法代码的角度思考，如何速成python语法的文章，笔者由于之前需要通过一项python的算法测试，故编写了这篇文章，现在希望可以帮助大家</p><h2 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 题目描述:# 第一行是一个整数 n，表示接下来有 n 行数据。# 接下来的 n 行，每行一个整数。n &#x3D; int(input())            # 先读取数据量 nfor i in range(n):          # 循环 n 次    data &#x3D; int(input())     # 每次读取一个整数    # 在这里处理 data...    print(data * 2)         # 示例：输出两倍# 读取一行中的两个整数 (用空格分隔)line &#x3D; input()              # 读取整行，例如 &quot;5 10&quot;parts &#x3D; line.split()        # 按空白字符分割，得到列表 [&#39;5&#39;, &#39;10&#39;]a &#x3D; int(parts[0])           # 转换第一个元素b &#x3D; int(parts[1])           # 转换第二个元素# 更简洁的写法 (常用！)a, b &#x3D; map(int, input().split())# 解释: #   input().split() -&gt; [&#39;5&#39;, &#39;10&#39;] (字符串列表)#   map(int, ...) -&gt; 将int函数应用到列表每个元素，得到一个map对象#   a, b &#x3D; ... -&gt; 序列解包，把map对象的前两个值分别赋给a和b# 读取一行k个整数k &#x3D; 3x, y, z &#x3D; map(int, input().split())  # 如果知道数量# 或者，如果数量不确定，存入列表numbers &#x3D; list(map(int, input().split())) # 得到 [5, 10, 3, 8] 这样的列表# 题目描述:# 第一行包含两个整数 n 和 m。# 接下来 n 行，每行 m 个整数，表示一个 n×m 的矩阵。# 读取第一行n, m &#x3D; map(int, input().split())# 初始化一个空列表来存储矩阵matrix &#x3D; []# 读取 n 行for i in range(n):    # 读取一行，并分割成 m 个整数，存入列表    row &#x3D; list(map(int, input().split()))    matrix.append(row)  # 将这一行添加到矩阵中# 现在 matrix 是一个二维列表，可以像 C++ 二维数组一样访问# 例如，matrix[0][0] 是左上角的元素# matrix[i][j] 是第 i+1 行第 j+1 列的元素# 示例：计算所有元素的和total &#x3D; 0for i in range(n):    for j in range(m):        total +&#x3D; matrix[i][j]print(total)print(1, 2, 3)           # 输出: 1 2 3 (默认空格分隔，换行结束)print(1, 2, 3, sep&#x3D;&#39;-&#39;)  # 输出: 1-2-3print(1, end&#x3D;&#39; &#39;)        # 输出: 1 (不换行，以空格结束)print(2)                 # 输出: 2 (换行)# 最终效果: 1 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Trick"><a href="#Trick" class="headerlink" title="Trick"></a>Trick</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">mid&#x3D;(l+r)&#x2F;&#x2F;2 #python不声明类型，&#x2F;可能出现浮点数，故&#x2F;&#x2F;为整数除法TreeNode(nums[mid])#__init__为构造函数，直接调用即可# 1. 导入必要的模块（如果需要）import sysfrom collections import deque# 4. 主函数：处理输入、调用算法、输出结果def main():    # 读取输入（根据题目要求）    try:        line &#x3D; input().strip()        # 假设输入是一行整数，如: [-10,-3,0,5,9]        # 去掉括号，分割，转整数        nums &#x3D; list(map(int, line.strip(&#39;[]&#39;).split(&#39;,&#39;))) if line.strip(&#39;[]&#39;) else []    except:        print(&quot;Invalid input&quot;)        return    # 创建 Solution 实例并调用方法    sol &#x3D; Solution()    root &#x3D; sol.sortedArrayToBST(nums)    # 输出结果（例如：层序遍历输出）    result &#x3D; level_order(root)   print(result)import sysdata &#x3D; []for line in sys.stdin:    data.append(list(map(int, line.split())))t &#x3D; int(input())  # 测试用例数for _ in range(t):    n &#x3D; int(input())    nums &#x3D; list(map(int, input().split()))    # 处理每组数据self.res &#x3D; []  # 实例变量，在方法内初始化，可以在其他方法调用#你将 ans 列表的引用添加到了 res 中。由于 ans 是一个可变对象，并且在整个递归过程中被反复修改（append 和 pop），#最终 res 中的所有元素都会指向同一个 ans 对象，其值为空（因为最后都 pop() 了），或者状态混乱res.append(ans[:])  # 使用切片复制列表res.append(ans.copy())        left&#x3D;bisect.bisect_left(nums,target)        right&#x3D;bisect.bisect_right(nums,target)#类似lower_bound和upper_bound    indices &#x3D; np.random.permutation(X.shape[0])np.random.permutation(100)：生成一个从 0 到 99 的整数的随机排列（打乱顺序）one_hot[np.arange(x.size), x] &#x3D; 1num,counts&#x3D;np.unique(y,return_counts&#x3D;True)    # 生成索引,注意不是arrange    indices &#x3D; np.arange(n_samples)    # 是否打乱    if shuffle:        np.random.shuffle(indices)            sampled_indices &#x3D; np.random.choice(indices, size&#x3D;n_samples, replace&#x3D;True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>train_indices = np.concatenate(folds[:i] + folds[i+1:])  # 其余合并为训练集#类似extend</code></pre><ul><li><code>input()</code>：读取一行输入，返回字符串。</li><li><code>split()</code>：按空白字符（空格、制表符、换行）分割字符串。</li><li><code>map(func, iterable)</code>：对列表中的每个元素应用函数（如 <code>int</code>）。</li><li><code>list()</code>：将 <code>map</code> 对象转为列表</li><li><code>n = int(input())  假如第一行的数字代表数据组个数</code></li><li>```pyhton<br>folds = np.array_split(indices, 5)<br>folds[0] = array([0, 1])      # 第0折：2个样本<br>folds[1] = array([2, 3])      # 第1折：2个样本<br>folds[2] = array([4, 5])      # 第2折：2个样本<br>folds[3] = array([6, 7])      # 第3折：2个样本<br>folds[4] = array([8, 9])      # 第4折：2个样本<pre class="line-numbers language-none"><code class="language-none">## DICT&#96;&#96;&#96;pythond &#x3D; &#123;&#125;d[&#39;key1&#39;] &#x3D; 100           # 方式1：直接赋值（推荐）del d[&#39;key1&#39;]             # 删除键，不存在会报错 KeyErrord.pop(&#39;key2&#39;)             # 删除并返回值，不存在可设默认值 d.pop(&#39;key2&#39;, None)d[&#39;key1&#39;] &#x3D; 999           # 直接赋值修改d.update(&#123;&#39;key1&#39;: 888&#125;)   # 批量更新value &#x3D; d[&#39;key1&#39;]         # 获取值，key 不存在会报错value &#x3D; d.get(&#39;key1&#39;, -1) # 获取值，不存在返回默认值（推荐）&#39;key1&#39; in d               # 检查 key 是否存在，返回 True&#x2F;Falsed.keys()    # 所有键d.values()  # 所有值d.items()   # 所有键值对 (key, value)# 按 key 排序sorted_by_key &#x3D; dict(sorted(d.items(), key&#x3D;lambda x: x[0]))# 按 value 排序（从小到大）sorted_by_value &#x3D; dict(sorted(d.items(), key&#x3D;lambda x: x[1]))sorted_mp&#x3D;sorted(mp.items(),key&#x3D;lambda x:x[1],reverse&#x3D;True)#不转换为dict，因为dict不支持切片，直接用sorted可以转为list# 从大到小排序sorted_by_value_desc &#x3D; dict(sorted(d.items(), key&#x3D;lambda x: x[1], reverse&#x3D;True))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h2 id="SET"><a href="#SET" class="headerlink" title="SET"></a>SET</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">s &#x3D; set()           # 正确：创建空集合s &#x3D; &#123;1, 2, 3&#125;s.add(4)                  # 添加单个元素s.update([5, 6])          # 添加多个元素（可迭代对象）s.remove(4)               # 删除元素，不存在会报错s.discard(4)              # 删除元素，不存在也不报错s.pop()                   # 随机删除并返回一个元素（无序！）s.clear()                 #清空3 in s                    # 检查元素是否存在，O(1)s.issubset(other_set)     # 子集判断s.issuperset(other_set)   # 超集判断len(s)                    # 元素个数sorted_list &#x3D; sorted(s)           # 升序sorted_list_desc &#x3D; sorted(s, reverse&#x3D;True)  # 降序nums.sort(key&#x3D;lambda x: (x[0], -x[1]))#第一个升序，第二个降序<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="table-container"><table><thead><tr><th>部分</th><th>说明</th></tr></thead><tbody><tr><td><code>nums.sort()</code></td><td>对列表 <code>nums</code> <strong>原地排序</strong></td></tr><tr><td><code>key=</code></td><td>指定一个函数，告诉 Python <strong>按什么规则排序</strong></td></tr><tr><td><code>lambda x: ...</code></td><td>匿名函数，输入是列表中的每个元素 <code>x</code>，输出是一个“排序键”</td></tr><tr><td><code>(x[0], -x[1])</code></td><td>返回一个元组，作为排序的依据</td></tr></tbody></table></div><h2 id="LIST"><a href="#LIST" class="headerlink" title="LIST"></a>LIST</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">dp &#x3D; [0] * (k + 1)#用list模拟数组stack &#x3D; []stack.append(1)stack.append(2)lst.remove(5)top &#x3D; stack.pop()         # 弹出最后一个元素，LIFOstack[-1] &#x3D; 99            # 修改栈顶元素top &#x3D; stack[-1]           # 查看栈顶（不删除）3 in stack                # 检查元素是否存在（O(n)）stack.sort()              # 原地排序（升序）stack.sort(reverse&#x3D;True)  # 原地降序sorted_stack &#x3D; sorted(stack)  # 返回新列表，不改变原栈lst &#x3D; [1, 2, 3, 2, 4]# 查找索引try:    index &#x3D; lst.index(2)    # 返回第一个 2 的索引：1    lst.pop(index)          # 删除该位置except ValueError:    print(&quot;元素不存在&quot;)lst &#x3D; [1, 2, 3, 4]# 删除最后一个lst.pop()        # 返回 4# 删除指定索引lst.pop(0)       # 删除第一个，返回 1# 或者用 del（不返回值）del lst[1]       # 删除索引 1 的元素nums[k:] &#x3D; nums[k:][::-1]#倒序（reverse）#使用nums[k:].reverse()会创建新数组，不改变原list，并且返回Nonesorted_nums &#x3D; sorted(nums, key&#x3D;lambda x: (x[0], -x[1]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="QUEUE"><a href="#QUEUE" class="headerlink" title="QUEUE"></a>QUEUE</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">from collections import dequeq &#x3D; deque()q.append(1)               # 从右边入队q.appendleft(0)           # 从左边入队（双端队列特性）front &#x3D; q.popleft()       # 从左边出队，FIFO，O(1)# q.pop()                 # 从右边出队，变成栈q[0] &#x3D; 99                 # 修改队首（支持索引访问）q[-1] &#x3D; 88                # 修改队尾orted_list &#x3D; sorted(q)   # 转为排序列表<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="table-container"><table><thead><tr><th>操作</th><th><code>dict</code></th><th><code>set</code></th><th><code>list</code> (栈)</th><th><code>deque</code> (队列)</th></tr></thead><tbody><tr><td><strong>增</strong></td><td><code>d[k]=v</code>, <code>d.update()</code></td><td><code>s.add()</code>, <code>s.update()</code></td><td><code>lst.append()</code></td><td><code>q.append()</code>, <code>q.appendleft()</code></td></tr><tr><td><strong>删</strong></td><td><code>del d[k]</code>, <code>d.pop(k)</code></td><td><code>s.remove()</code>, <code>s.discard()</code></td><td><code>lst.pop()</code></td><td><code>q.popleft()</code></td></tr><tr><td><strong>改</strong></td><td><code>d[k] = new_v</code></td><td>先删后增</td><td><code>lst[-1] = new_val</code></td><td><code>q[0] = new_val</code></td></tr><tr><td><strong>查</strong></td><td><code>k in d</code>, <code>d.get(k)</code></td><td><code>x in s</code></td><td><code>lst[-1]</code>, <code>x in lst</code></td><td><code>q[0]</code>, <code>x in q</code></td></tr><tr><td><strong>排序</strong></td><td><code>dict(sorted(d.items()))</code></td><td><code>sorted(s)</code></td><td><code>lst.sort()</code></td><td><code>sorted(q)</code></td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>方法</th><th>行为</th><th>示例</th></tr></thead><tbody><tr><td><code>append(iterable)</code></td><td>把整个对象当作一个元素添加</td><td><code>q.append([1,2])</code> → <code>deque([[1,2]])</code></td></tr><tr><td><code>extend(iterable)</code></td><td>把可迭代对象的<strong>每个元素</strong>逐个添加</td><td><code>q.extend([1,2])</code> → <code>deque([1, 2])</code></td></tr></tbody></table></div><h2 id="FOR"><a href="#FOR" class="headerlink" title="FOR"></a>FOR</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">for i, num in enumerate(nums):  # 更简洁地遍历索引和for i, char in enumerate(s):s &#x3D; &quot;abc&quot;for char in s:    print(char)  # a, b, c# 带索引遍历for i, char in enumerate(s):    print(f&quot;&#123;i&#125;: &#123;char&#125;&quot;)# 保留索引不在 &#96;indices_to_remove&#96; 中的元素result &#x3D; [value for index, value in enumerate(data) if index not in indices_to_remove]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/10/06/hello-world/"/>
      <url>/2025/10/06/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new &quot;My New Post&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
